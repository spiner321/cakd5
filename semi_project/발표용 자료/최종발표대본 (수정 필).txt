테이블 오른쪽 클릭 데이터 임포트 파일 찾아보기 
1 안녕하세요 CAKD5 광민아 노래 틀어조 세미프로젝트 발표 시작하겠습니다.

2 목차는 다음과 같습니다. 

3 우선 과제 도출 과정에 대해 설명 드리겠습니다. 
음성에서 감정을 인식하는 기술로는 크게 두 가지가 있습니다. 
첫 번째는 사람의 말을 텍스트로 바꾸어 감정 키워드에 기반을 두어 자연어 문장이 가진 의미 정보를 파악하는 것이고
두 번째는 사람 음성의 특징을 분석하여 감성을 인식하는 것입니다.
현재 텍스트 기반의 감정인식은  다양하게 상용화되어 쓰이고 있으나 반어법으로 하는 말에 대해 감정 분석을 하지 못한다는 단점이 있습니다. 
또한 명령이 단순하거나 동일한 텍스트 형태일 때는 감정을 판단하는 정확도가 높지 않다는 불편함을 가지고 있습니다.
따라서 저희는 음성을 기반으로 감정 인식을 시도해보고자 하였습니다. 
음성 기반 감정 인식을 수행하면 명령이 단순하거나 동일한 텍스트 형태일 때도 소리를 통해 감정을 판단할 것을 기대해 볼 수 있습니다.

4 저희는 음성과 더불어 이미지를 함께 인풋 데이터로 받아 감정을 추출하는데 사용하는 멀티 모달 감성 인식을 이번 과제 목표로 선정하였는데,
얼굴로부터 감정을 인식하는 것은 현재 인식률이 80%~90%로 매우 높은 편이기 때문에 음성과 이미지를 함께 고려한다면
모델의 감정 추출 정확도가 보다 높아질 것이라 판단하였기 때문입니다. 

5 다음은 프로젝트 진행 과정에 대해 간단히 설명 드리겠습니다. 우선 AI HUB의 멀티모달 영상에서 음성 데이터를 추출해 사용하여 음성에서 감정을 추출하고자 하였습니다.
다음으론 MS의 Face API를 사용해 이미지에서 감정을 추출해보았습니다. 그리고 기존 논문에 사용되었던 감성수식을 사용해 음악을 8가지 감성으로 분류하였습니다. 
마지막으로 음성과 이미지 데이터에서 추출된 감성과 음악을 매칭해 추천을 제공하려고 했으나 추가적인 의논이 필요한 부분이라 이 부분은 진행하지 못하였습니다. 

6 음성에서 감성을 추출해주는 작업을 수행하기 위해 사용한 데이터셋은 AI HUB의 '멀티모달영상' 입니다. 영상, 음성, 텍스트 등의 데이터를 제공해주고 있고 
대사별 감정을 8가지(기쁨,슬픔, 분노, 놀람,공포, 경멸, 혐오, 중립)로 분류하고, 감정의 강도(arousal)와 감정의 긍부정(valance) 정도도 알려주기 때문에
이 데이터를 활용해 감정인식을 수행할 수 있습니다. 
원래 'AI HUB의 감성 대화 말뭉치'를 사용하려고 했으나 말뭉치 데이터를 직접 들어보니 연극톤으로 매우 어색한 감이 있어 좀 더 자연스러운 AI HUB의 '멀티 모달 영상'
데이터에서 음성만을 추출하여 사용하기로 결정하였습니다. 

7 다음은 음성과 음원 분석에 사용한 라이브러리인 라이브로사에 대해서 설명해드리겠습니다. 
라이브로사 라이브러리는 python에서 음원 데이터를 분석해주는 라이브러리입니다. 
주요 제공 기능으로는 STFT, 멜스펙트로그램, MFCC가 있는데, 
((((Short Time Fourier Transform는 시간(Time) 도메인의 파형을 주파수(Frequency) 도메인으로 변형시키는 푸리에 변환입니다.
Mel Spectrogram은, Mel Scale 변환을 통해 사람의 귀에 맞춰진 스펙트로그램을 생성합니다. 
STFT로 나온 결과는 수치적으로는 객관적이지만, 실제 사람의 귀의 입장에서는 그렇지 않기 때문에 Mel Spectrogram을 사용합니다.
Mel-Frequency Cepstral Coefficient 생성, MFCC는 Mel spectrogram의 피쳐에 대해 행렬을 압축해서 표현해주는 Discrete Cosine Transform(DCT)연산을 거쳐서 나온 결과값입니다. 
스펙트로그램 대비 압축된 정보를 담고 있다고 볼 수 있으며, 압축하는 과정에서 손실이 발생, 노이즈가 제거되는 효과가 있습니다. 
이 때문에 MFCC 값이 고유의 음성 정보를 담고 있다고 보기도 하는 것 같습니다. 주로 음성 데이터 분석을 할 때도 MFCC로 하는 것으로 알고 있습니다.)))))

8 음성에서 감성을 인식하는 과정은 크게 다섯가지로 분류할 수 있습니다. 음성을 분류하고, 특징을 추출해내고, 특징들을 군집화하고, 이를 2차원 스펙트로그램으로 변환한 뒤
3차원 합성곱신경망 CNN을 활용해 감정을 인식합니다. CNN에 대해서 간단히 설명드리자면 딥러닝 모델 중 하나로 데이터의 특징에서 패턴을 파악하는 모델입니다. 
이미지를 인식하는데 많이 사용이 되지만 음성 신호를 이미지화하면 음성 신호 또한 처리 가능합니다. 

9 다음은 수행한 멀티모달영상 데이터셋 전처리 과정입니다. 우선 대사에 해당하는 감정들이 무엇인지 한 눈에 파악하기 위해 제이슨 파일에서 감성과 대사를 추출합니다. 
그리고 음원 파일을 추출해 대사별로 분할합니다. 다음으로는 라이브로사의 멜스펙토그램 함수를 통해 대사별 멜스펙트로그램을 출력합니다. 

10 멜스펙트로그램은 주파수의 단위를 다음 공식에 따라 멜 단위(Mel unit)로 바꾼 스펙트럼을 말합니다. 
스펙트로그램 보통 스펙트럼(spectrum)이라고 부르는 시계열 분석의 정확한 명칭은 파워 스펙트럼(power spectrum) 
펙트럼(spectrum)은 확률론적인 확률과정(random process) 모형을 주파수 영역으로 변환하는 것을 말한다. 
스펙트로그램(Spectrogram)은 소리나 파동을 시각화하여 파악하기 위한 도구로, 파형(waveform)과 스펙트럼(spectrum)의 특징이 조합되어 있다. 


11- 16 멀티 모달 영상에서 음원 추출 후 감성 분석한 과정의 코드와 결과물을 보여드리겠습니다. (이미지 보면서 설명하시면 될 것 같아요)

17 다음은 이미지 감성 인식 과정입니다. 이미지 인풋을 받으면 컨볼루션 레이어를 통해 입력 이미지를 특정 필터를 이용하여 탐색하면서 이미지의 특징들을 추출하고,
추출한 특징들을 Feature Map으로 생성합니다. 그리고 dense layer는 fully connected layer라고도 불리는데, 이전 계층의 모든 뉴런과 결합된 형태의 layer입니다. 이 과정을 통해
이미지에서 감성을 분석해낼 수 있습니다. 

18 중간발표 때는 fer 라이브러리를 사용해 이미지 감성 분석을 해보았지만 ms의 face api와 이미지 감성 분석 결과를 비교해보았을 때
ms api의 정확도가 좀 더 높아 이를 선택하기로 결정했습니다. 

19 fer의 단점으로는 이미지가 작게 나왔을 경우 인식을 못한다는 것과 여러 사람이 담긴 이미지를 분석할 때 정확도가 떨어진다는 것이 있었습니다. 

20 ms face api를 사용할 때 이용한 코드입니다. 

21 다음은 음악에서 감성 인식을 하기 위해 데이터를 전처리 한 과정입니다. 
임의 추출한 337개의 음원을 Librosa를 통해 템포, 잡음, 진폭, 밝기, 역동성 값을 추출합니다. 
그리고 각각 요소에 대한 데이터의 단위와 범위가 다르기 때문에 정규화 과정을 거칩니다. 
그리고 각각 요소에 가중치를 넣어 도출한 값을 x축은 행복도, y축은 흥분도를 뜻하는 감성 좌표계에 대입 후 노래 별 감성을 예측합니다. 
22-27 사진 보면서 설명

28 
이번 프로젝트는 이미지와 음성 데이터로 감정을 추출하여 보았지만 실제 텍스트만으로 이루어진 모델과 음성으로만 만들어진 모델의 정확도를 비교해보았을 땐, 
아직까진 텍스트로만 만들어진 모델의 정확도가 더 높은 것으로 판단이 돼 음성으로만 감정을 분석하기에는 정확도 측면에서 한계가 있어 보입니다. 
따라서 텍스트, 음성 데이터, 그리고 이미지를 함께 사용하는 멀티 모달을 이용해 감성 추출을 하는 모델을 구현하는 것이 궁극적으로 지향해야 할 점이라고 생각하였습니다.  

저희 멀티모달 감성 추출 모델의 의의로는 두 가지 사항을 살펴볼 수 있습니다. 
우선 인간 의사소통의 90%는 발성 억양, 몸짓 언어, 얼굴 표정을 포함하기 때문에 멀티 모달 모델을 사용했을 경우 사용자 감정을 감지하고 반응할 수 있는 
'감정적인' AI는 인간과 AI 간 협력 노력에서 이용자의 만족도를 높일 수 있을 것이라 기대됩니다. 
그리고 사용자들의 신뢰를 얻어 더욱 효과적인 상호작용을 이끄는 것은 물론이고 시스템이 잠재적 문제를 인식하도록 도울 수 있습니다. 
예를 들자면, 사용자가 우울증 등으로 좌절감이 높아졌을 때, AI는 사용자에게 문제가 있다는 신호를 인식하고 솔루션을 제공해 문제를 해결할 수 있습니다.

29-30 소감 31 참고문헌

감사합니다. 이상 광민아노래틀어조의 발표를 마치도록 하겠습니다. 