{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rvHy5GvCe3Xf"},"outputs":[],"source":["import sys\n","sys.path.append(\"/content/drive/MyDrive/workspace/cakd5/3차_project/작업물/김기현/data/Gridworld/\")\n","from Gridworld import Gridworld, GridBoard"]},{"cell_type":"markdown","metadata":{"id":"1-v3siwEQ1Z4"},"source":["# # 지도를 격자로 변환\n","---"]},{"cell_type":"markdown","metadata":{"id":"qfIQetxL5rR2"},"source":["## # 위도, 경도 <-> X, Y 좌표 변환 사용자 함수\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278,"status":"ok","timestamp":1653629352444,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"bp9w2jaw5tii","outputId":"b706dc7a-674f-47ce-fb2e-46194f25d39f"},"outputs":[{"name":"stdout","output_type":"stream","text":["(295001, 630001)\n","(480001, 365001)\n","(260001, 185001)\n","(31.795579194949102, 123.76185529502112)\n","(31.795108580706742, 123.76226532689546)\n","(31.794771415398294, 123.76180722317294)\n"]}],"source":["import math\n","NX = 149            ## X축 격자점 수\n","NY = 253            ## Y축 격자점 수\n","\n","Re = 6371.00877     ##  지도반경\n","grid = 0.001         ##  격자간격 (km)\n","slat1 = 30.0        ##  표준위도 1\n","slat2 = 60.0        ##  표준위도 2\n","olon = 126.0        ##  기준점 경도\n","olat = 38.0         ##  기준점 위도\n","xo = 210 / grid     ##  기준점 X좌표\n","yo = 675 / grid     ##  기준점 Y좌표\n","# xo = 43 \n","# yo = 136\n","first = 0\n","\n","if first == 0 :\n","    PI = math.asin(1.0) * 2.0\n","    DEGRAD = PI/ 180.0\n","    RADDEG = 180.0 / PI\n","\n","    re = Re / grid\n","    slat1 = slat1 * DEGRAD\n","    slat2 = slat2 * DEGRAD\n","    olon = olon * DEGRAD\n","    olat = olat * DEGRAD\n","\n","    sn = math.tan(PI * 0.25 + slat2 * 0.5) / math.tan(PI * 0.25 + slat1 * 0.5)\n","    sn = math.log(math.cos(slat1) / math.cos(slat2)) / math.log(sn)\n","    sf = math.tan(PI * 0.25 + slat1 * 0.5)\n","    sf = math.pow(sf, sn) * math.cos(slat1) / sn\n","    ro = math.tan(PI * 0.25 + olat * 0.5)\n","    ro = re * sf / math.pow(ro, sn)\n","    first = 1\n","\n","def mapToGrid(lat, lon, code = 0 ):\n","    # ln = list_[0]\n","    # lat = list_[1]\n","    ra = math.tan(PI * 0.25 + lat * DEGRAD * 0.5)\n","    ra = re * sf / pow(ra, sn)\n","    theta = lon * DEGRAD - olon\n","    if theta > PI :\n","        theta -= 2.0 * PI\n","    if theta < -PI :\n","        theta += 2.0 * PI\n","    theta *= sn\n","    x = (ra * math.sin(theta)) + xo\n","    y = (ro - ra * math.cos(theta)) + yo\n","    x = int(x + 1.5)\n","    y = int(y + 1.5)\n","    return x, y\n","\n","def gridToMap(x, y, code = 1):\n","    x = x - 1\n","    y = y - 1\n","    xn = x - xo\n","    yn = ro - y + yo\n","    ra = math.sqrt(xn * xn + yn * yn)\n","    if sn < 0.0 :\n","        ra = -ra\n","    alat = math.pow((re * sf / ra), (1.0 / sn))\n","    alat = 2.0 * math.atan(alat) - PI * 0.5\n","    if math.fabs(xn) <= 0.0 :\n","        theta = 0.0\n","    else :\n","        if math.fabs(yn) <= 0.0 :\n","            theta = PI * 0.5\n","            if xn < 0.0 :\n","                theta = -theta\n","        else :\n","            theta = math.atan2(xn, yn)\n","    alon = theta / sn + olon\n","    lat = alat * RADDEG\n","    lon = alon * RADDEG\n","\n","    return lat, lon\n","\n","print(mapToGrid(37.579871128849334, 126.98935225645432))\n","print(mapToGrid(35.101148844565955, 129.02478725562108))\n","print(mapToGrid(33.500946412305076, 126.54663058817043))\n","## result :\n","(60, 127)\n","(97, 74)\n","(53, 38)\n","\n","print(gridToMap(60, 127))\n","print(gridToMap(97, 74))\n","print(gridToMap(53, 38))"]},{"cell_type":"markdown","metadata":{"id":"M9TQ5ZzZfMdM"},"source":["# # DQN (Deep Q-learning Network)\n","---"]},{"cell_type":"markdown","metadata":{"id":"ZB0m5b1WMR7p"},"source":["## # 미로 찾기 1 (사용 안함)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EG3VYZShgg8S"},"outputs":[],"source":["addMask('pit', '-', ())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LNTZe0msWg_N"},"outputs":[],"source":["import numpy as np\n","import random\n","import sys\n","\n","def randPair(s,e):\n","    return np.random.randint(s,e), np.random.randint(s,e)\n","\n","class BoardPiece:\n","\n","    def __init__(self, name, code, pos):\n","        self.name = name #name of the piece\n","        self.code = code #an ASCII character to display on the board\n","        self.pos = pos #2-tuple e.g. (1,4)\n","\n","class BoardMask:\n","\n","    def __init__(self, name, mask, code):\n","        self.name = name\n","        self.mask = mask\n","        self.code = code\n","\n","    def get_positions(self): #returns tuple of arrays\n","        return np.nonzero(self.mask)\n","\n","def zip_positions2d(positions): #positions is tuple of two arrays\n","    x,y = positions\n","    return list(zip(x,y))\n","\n","class GridBoard:\n","\n","    def __init__(self, size=4):\n","        self.size = size #Board dimensions, e.g. 4 x 4\n","        self.components = {} #name : board piece\n","        self.masks = {}\n","\n","    def addPiece(self, name, code, pos=(0,0)):\n","        newPiece = BoardPiece(name, code, pos)\n","        self.components[name] = newPiece\n","\n","    #basically a set of boundary elements\n","    def addMask(self, name, mask, code):\n","        #mask is a 2D-numpy array with 1s where the boundary elements are\n","        newMask = BoardMask(name, mask, code)\n","        self.masks[name] = newMask\n","\n","    def movePiece(self, name, pos):\n","        move = True\n","        for _, mask in self.masks.items():\n","            if pos in zip_positions2d(mask.get_positions()):\n","                move = False\n","        if move:\n","            self.components[name].pos = pos\n","\n","    def delPiece(self, name):\n","        del self.components['name']\n","\n","    def render(self):\n","        dtype = '<U2'\n","        displ_board = np.zeros((self.size, self.size), dtype=dtype)\n","        displ_board[:] = ' '\n","\n","        for name, piece in self.components.items():\n","            displ_board[piece.pos] = piece.code\n","\n","        for name, mask in self.masks.items():\n","            displ_board[mask.get_positions()] = mask.code\n","\n","        return displ_board\n","\n","    def render_np(self):\n","        num_pieces = len(self.components) + len(self.masks)\n","        displ_board = np.zeros((num_pieces, self.size, self.size), dtype=np.uint8)\n","        layer = 0\n","        for name, piece in self.components.items():\n","            pos = (layer,) + piece.pos\n","            displ_board[pos] = 1\n","            layer += 1\n","\n","        for name, mask in self.masks.items():\n","            x,y = self.masks['boundary'].get_positions()\n","            z = np.repeat(layer,len(x))\n","            a = (z,x,y)\n","            displ_board[a] = 1\n","            layer += 1\n","        return displ_board\n","\n","def addTuple(a,b):\n","    return tuple([sum(x) for x in zip(a,b)])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fietCTQQWiSL"},"outputs":[],"source":["class Gridworld:\n","\n","    def __init__(self, size=4, mode='static'):\n","        if size >= 4:\n","            self.board = GridBoard(size=size)\n","        else:\n","            print(\"Minimum board size is 4. Initialized to size 4.\")\n","            self.board = GridBoard(size=4)\n","\n","        #Add pieces, positions will be updated later\n","        self.board.addPiece('Player','P',(0,0))\n","        self.board.addPiece('Goal','+',(1,0))\n","        self.board.addPiece('Pit','-',(2,0))\n","        self.board.addPiece('Wall','W',(3,0))\n","\n","        if mode == 'static':\n","            self.initGridStatic()\n","        elif mode == 'player':\n","            self.initGridPlayer()\n","        else:\n","            self.initGridRand()\n","\n","    #Initialize stationary grid, all items are placed deterministically\n","    def initGridStatic(self):\n","        #Setup static pieces\n","        self.board.components['Player'].pos = (0,3) #Row, Column\n","        self.board.components['Goal'].pos = (0,0)\n","        self.board.components['Pit'].pos = (0,1)\n","        self.board.components['Pit'].pos = (3,1)\n","        self.board.components['Wall'].pos = (1,1)\n","\n","    #Check if board is initialized appropriately (no overlapping pieces)\n","    #also remove impossible-to-win boards\n","    def validateBoard(self):\n","        valid = True\n","\n","        player = self.board.components['Player']\n","        goal = self.board.components['Goal']\n","        wall = self.board.components['Wall']\n","        pit = self.board.components['Pit']\n","\n","        all_positions = [piece for name,piece in self.board.components.items()]\n","        all_positions = [player.pos, goal.pos, wall.pos, pit.pos]\n","        if len(all_positions) > len(set(all_positions)):\n","            return False\n","\n","        corners = [(0,0),(0,self.board.size), (self.board.size,0), (self.board.size,self.board.size)]\n","        #if player is in corner, can it move? if goal is in corner, is it blocked?\n","        if player.pos in corners or goal.pos in corners:\n","            val_move_pl = [self.validateMove('Player', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n","            val_move_go = [self.validateMove('Goal', addpos) for addpos in [(0,1),(1,0),(-1,0),(0,-1)]]\n","            if 0 not in val_move_pl or 0 not in val_move_go:\n","                #print(self.display())\n","                #print(\"Invalid board. Re-initializing...\")\n","                valid = False\n","\n","        return valid\n","\n","\n","    def validateMove(self, piece, addpos=(0,0)):\n","        outcome = 0 #0 is valid, 1 invalid, 2 lost game\n","        pit = self.board.components['Pit'].pos\n","        wall = self.board.components['Wall'].pos\n","        new_pos = addTuple(self.board.components[piece].pos, addpos)\n","        if new_pos == wall:\n","            outcome = 1 #block move, player can't move to wall\n","        elif max(new_pos) > (self.board.size-1):    #if outside bounds of board\n","            outcome = 1\n","        elif min(new_pos) < 0: #if outside bounds\n","            outcome = 1\n","        elif new_pos == pit:\n","            outcome = 2\n","\n","        return outcome\n","\n","    def makeMove(self, action):\n","        #need to determine what object (if any) is in the new grid spot the player is moving to\n","        #actions in {u,d,l,r}\n","        def checkMove(addpos):\n","            if self.validateMove('Player', addpos) in [0,2]:\n","                new_pos = addTuple(self.board.components['Player'].pos, addpos)\n","                self.board.movePiece('Player', new_pos)\n","\n","        if action == 'u': #up\n","            checkMove((-1,0))\n","        elif action == 'd': #down\n","            checkMove((1,0))\n","        elif action == 'l': #left\n","            checkMove((0,-1))\n","        elif action == 'r': #right\n","            checkMove((0,1))\n","        else:\n","            pass\n","\n","    def reward(self):\n","        if (self.board.components['Player'].pos == self.board.components['Pit'].pos):\n","            return -10\n","        elif (self.board.components['Player'].pos == self.board.components['Goal'].pos):\n","            return 10\n","        else:\n","            return -1\n","\n","    def display(self):\n","        return self.board.render()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1653637868635,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"1IfDPST2fkc8","outputId":"f51a11c3-55ca-472d-e526-abf243ab02ae"},"outputs":[{"data":{"text/plain":["array([['+', ' ', ' ', 'P', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', 'W', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', '-', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '],\n","       [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']], dtype='<U2')"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["game = Gridworld(size = 10, mode = 'static')\n","game.display()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9278,"status":"ok","timestamp":1653634758617,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"nLnCHa7Vtr4s","outputId":"7e108ccc-4750-4d8b-e36c-e5f0f17e813c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"name":"stdout","output_type":"stream","text":["0 0.9941202998161316\n","0 0.9970187544822693\n","0 0.7443123459815979\n","0 0.7008640766143799\n","0 1.0097477436065674\n","0 1.0191160440444946\n","0 0.894612729549408\n","0 0.8485819697380066\n","0 0.8280817270278931\n","0 0.9972999691963196\n","0 0.704863429069519\n","0 0.9152095913887024\n","0 0.8118036985397339\n","0 0.9710589051246643\n","0 0.7396509051322937\n","0 0.9850639700889587\n","0 0.7321427464485168\n","0 0.7283651232719421\n","0 0.8998202085494995\n","0 0.9361807703971863\n","0 0.9600702524185181\n","0 0.6846605539321899\n","0 1.025092601776123\n","0 0.6438979506492615\n","0 0.6492166519165039\n","0 0.5940696001052856\n","0 0.592823326587677\n","0 0.6471853256225586\n","0 0.6023712158203125\n","0 0.5402055978775024\n","0 0.8219423890113831\n","0 0.4523422122001648\n","0 0.760164737701416\n","0 0.4160045087337494\n","0 0.302829384803772\n","0 0.6386669278144836\n","0 0.5361697673797607\n","0 0.14393514394760132\n","0 0.14119505882263184\n","0 0.9601105451583862\n","0 0.871856153011322\n","0 0.3042089343070984\n","0 0.21224749088287354\n","0 0.04688192158937454\n","0 0.14622941613197327\n","0 0.27399641275405884\n","0 0.08431320637464523\n","0 0.733677327632904\n","0 0.24603840708732605\n","0 0.01777014695107937\n","0 0.2161831259727478\n","0 0.807293176651001\n","0 0.053438328206539154\n","0 0.3679672181606293\n","0 0.010403124615550041\n","0 0.09765267372131348\n","0 0.5602011680603027\n","0 0.13011911511421204\n","0 0.0012651165015995502\n","0 0.004897454287856817\n","0 0.06383492797613144\n","0 0.008277066051959991\n","0 0.0923444926738739\n","0 0.002270463854074478\n","0 0.5214810967445374\n","0 0.016470666974782944\n","0 0.4699362814426422\n","0 0.8139256834983826\n","0 0.06802777200937271\n","0 45.104087829589844\n","1 0.5709147453308105\n","1 0.0333775170147419\n","1 0.6753035187721252\n","1 0.2705242335796356\n","1 0.301556795835495\n","1 2.3628133931197226e-05\n","1 0.13736042380332947\n","1 0.31070882081985474\n","1 27.377016067504883\n","2 0.26209476590156555\n","2 0.0005810774746350944\n","2 0.08332820236682892\n","2 0.010092892684042454\n","2 0.015754131600260735\n","2 0.25094789266586304\n","2 0.01183472853153944\n","2 0.013420111499726772\n","2 0.4031302332878113\n","2 0.26354146003723145\n","2 0.0754934549331665\n","2 0.13992992043495178\n","2 0.047520436346530914\n","2 0.08063672482967377\n","2 0.29401248693466187\n","2 0.1308317631483078\n","2 0.12839441001415253\n","2 0.010251500643789768\n","2 0.2801274061203003\n","2 0.046862050890922546\n","2 0.0027447224128991365\n","2 6.620262622833252\n","3 0.05436893180012703\n","3 0.13542893528938293\n","3 0.0005643941694870591\n","3 1.4522825949825346e-05\n","3 0.02535214088857174\n","3 0.0007736667175777256\n","3 0.2814023494720459\n","3 6.011478035361506e-07\n","3 0.05000992864370346\n","3 0.001963511109352112\n","3 0.5872905254364014\n","3 0.028556054458022118\n","3 0.11648374795913696\n","3 0.04851222038269043\n","3 0.3178681433200836\n","3 0.0566939041018486\n","3 0.007281861733645201\n","3 0.13441376388072968\n","3 0.00033853197237476707\n","3 0.009158905595541\n","3 0.12944461405277252\n","3 1.2200230360031128\n","3 0.24063560366630554\n","3 0.0004084163228981197\n","3 0.08506017178297043\n","3 0.32975566387176514\n","3 0.349953830242157\n","3 0.044500261545181274\n","3 0.0006182282813824713\n","3 0.12460406869649887\n","3 0.020677829161286354\n","3 0.20060911774635315\n","3 0.014495344832539558\n","3 0.09008825570344925\n","3 0.04495810717344284\n","3 1.5185956954956055\n","3 0.04294648393988609\n","3 0.000944934319704771\n","3 0.20997999608516693\n","3 0.0728134959936142\n","3 0.14548787474632263\n","3 0.13643206655979156\n","3 0.05215403065085411\n","3 0.003209889167919755\n","3 0.025113997980952263\n","3 0.004086256958544254\n","3 0.10186704993247986\n","3 0.05681977421045303\n","3 0.035334933549165726\n","3 0.0015780997928231955\n","3 0.3691304922103882\n","3 0.011372060514986515\n","3 0.03244544565677643\n","3 2.6769943237304688\n","4 0.001619280781596899\n","4 0.05540337786078453\n","4 0.18761339783668518\n","4 0.001244694460183382\n","4 0.11879958212375641\n","4 0.21062113344669342\n","4 0.037455737590789795\n","4 1.1565458407858387e-05\n","4 0.6144787073135376\n","4 0.34190601110458374\n","4 0.18489041924476624\n","4 0.01172150019556284\n","4 0.005824550054967403\n","4 0.005424937233328819\n","4 0.1623612493276596\n","4 0.6296119093894958\n","4 0.09692686051130295\n","4 0.03212842717766762\n","4 1.6673812866210938\n","4 0.029364092275500298\n","4 0.3383946716785431\n","4 0.6730808019638062\n","4 0.05778772756457329\n","4 0.030513349920511246\n","4 0.3781531751155853\n","4 0.8589737415313721\n","4 0.00026194797828793526\n","4 0.1103590875864029\n","4 0.019113028421998024\n","4 0.2217787504196167\n","4 0.0031323954463005066\n","4 0.4814225733280182\n","4 0.0935693234205246\n","4 0.500845730304718\n","4 0.013425414450466633\n","4 0.09645801782608032\n","4 0.5318180322647095\n","4 0.2407549023628235\n","4 0.2809290289878845\n","4 0.6647459268569946\n","4 0.04630506411194801\n","4 0.001699850894510746\n","4 0.0328652523458004\n","4 0.002000490901991725\n","4 0.0016861953772604465\n","4 0.0022035285364836454\n","4 0.013180676847696304\n","4 0.027969904243946075\n","4 0.05437604710459709\n","4 0.0015883073210716248\n","4 0.05569985508918762\n","4 0.1214962974190712\n","4 0.10760656744241714\n","4 0.006097407545894384\n","4 0.03504297509789467\n","4 7.104084943421185e-05\n","4 0.03157544136047363\n","4 0.0034821834415197372\n","4 0.17293968796730042\n","4 0.001839231001213193\n","4 0.12547478079795837\n","4 0.4079839885234833\n","4 0.09488549828529358\n","4 0.6086205244064331\n","4 0.023466486483812332\n","4 0.009614386595785618\n","4 0.18788942694664001\n","4 0.8548448085784912\n","4 0.03225487470626831\n","4 0.04807671532034874\n","4 0.9771409630775452\n","4 0.1303427368402481\n","4 0.4303768575191498\n","4 0.0010660843690857291\n","4 0.5871232151985168\n","4 0.005620751995593309\n","4 0.036395978182554245\n","4 0.5772141218185425\n","4 0.038258254528045654\n","4 292.1434631347656\n","5 0.018533675000071526\n","5 7.702404022216797\n","6 0.5166563987731934\n","6 10.012118339538574\n","7 0.12351842224597931\n","7 0.501415491104126\n","7 1.5548597574234009\n","7 0.6911235451698303\n","7 0.44748592376708984\n","7 0.18058747053146362\n","7 2.187812328338623\n","7 0.5345268249511719\n","7 0.48248055577278137\n","7 0.33775144815444946\n","7 2.150350332260132\n","7 2.213623046875\n","7 0.08179587125778198\n","7 0.18992586433887482\n","7 0.23684167861938477\n","7 0.38688012957572937\n","7 0.007534919306635857\n","7 1.4996705055236816\n","7 1.4222031831741333\n","7 1.072680115699768\n","7 0.8973826169967651\n","7 1.1711539030075073\n","7 0.016011934727430344\n","7 0.16296742856502533\n","7 0.2853367328643799\n","7 0.2903396189212799\n","7 0.08032829314470291\n","7 0.21565301716327667\n","7 0.1368798017501831\n","7 0.1751338243484497\n","7 0.7067995667457581\n","7 0.05177434906363487\n","7 0.4939054250717163\n","7 0.014628610573709011\n","7 0.10691677778959274\n","7 0.10836983472108841\n","7 0.237314373254776\n","7 0.37516993284225464\n","7 7.651594205526635e-05\n","7 0.3594113290309906\n","7 0.31710776686668396\n","7 0.16628719866275787\n","7 0.20435133576393127\n","7 0.3967883884906769\n","7 0.11742646247148514\n","7 0.27000489830970764\n","7 1.0544704309722874e-05\n","7 0.10307122021913528\n","7 0.04726486653089523\n","7 0.5312965512275696\n","7 0.034236714243888855\n","7 0.0037218567449599504\n","7 0.004681841935962439\n","7 0.09309849888086319\n","7 0.5073357224464417\n","7 187.36378479003906\n","8 0.0948810875415802\n","8 0.24527113139629364\n","8 0.19223451614379883\n","8 0.000276721257250756\n","8 0.002018403261899948\n","8 0.6398099660873413\n","8 0.2846435606479645\n","8 0.010013097897171974\n","8 0.5226559638977051\n","8 167.38162231445312\n","9 0.12714217603206635\n","9 0.5890048742294312\n","9 0.2310028225183487\n","9 0.022436415776610374\n","9 0.48313161730766296\n","9 0.7779975533485413\n","9 0.5543131232261658\n","9 0.015108514577150345\n","9 39.924468994140625\n","10 0.7641341090202332\n","10 0.6921228766441345\n","10 0.27551546692848206\n","10 0.10458865016698837\n","10 0.2152891308069229\n","10 0.6787785887718201\n","10 0.6299153566360474\n","10 0.17601335048675537\n","10 0.4968262314796448\n","10 0.7160531878471375\n","10 0.4313715696334839\n","10 0.06285347789525986\n","10 0.6612151265144348\n","10 0.7042474746704102\n","10 0.11596240848302841\n","10 0.1067836657166481\n","10 0.41777992248535156\n","10 0.13456276059150696\n","10 34.174434661865234\n","11 0.23483814299106598\n","11 0.6654704213142395\n","11 0.5744048357009888\n","11 0.5758057236671448\n","11 0.2676100432872772\n","11 0.0007750997901894152\n","11 0.09903256595134735\n","11 0.00043174263555556536\n","11 0.137498140335083\n","11 0.7735158801078796\n","11 0.48497816920280457\n","11 0.44135114550590515\n","11 0.38170158863067627\n","11 1.2535400390625\n","11 0.03955816850066185\n","11 0.7622832655906677\n","11 0.6787102222442627\n","11 1.0479919910430908\n","11 0.19795067608356476\n","11 0.04072665050625801\n","11 0.01658671535551548\n","11 0.02762867510318756\n","11 0.4332338571548462\n","11 0.1127467006444931\n","11 1.0896570682525635\n","11 0.16257093846797943\n","11 0.2403150200843811\n","11 0.23874931037425995\n","11 0.040017854422330856\n","11 0.4495357871055603\n","11 0.04252861812710762\n","11 0.25985321402549744\n","11 0.004983522929251194\n","11 0.1941831260919571\n","11 0.704123854637146\n","11 0.41705501079559326\n","11 0.15903450548648834\n","11 1.1127374172210693\n","11 0.046196263283491135\n","11 0.032645534723997116\n","11 0.5989234447479248\n","11 0.5121509432792664\n","11 0.04470297694206238\n","11 0.0019850372336804867\n","11 0.12379978597164154\n","11 0.5428330898284912\n","11 0.5512953996658325\n","11 0.656561553478241\n","11 0.313560426235199\n","11 0.5926764011383057\n","11 0.04739619791507721\n","11 0.2500753402709961\n","11 0.17999301850795746\n","11 0.4229419231414795\n","11 0.12266655266284943\n","11 0.07050256431102753\n","11 0.12606869637966156\n","11 0.2100820541381836\n","11 0.07223781198263168\n","11 0.7161718606948853\n","11 0.12722142040729523\n","11 0.0015170627739280462\n","11 0.44073015451431274\n","11 0.09904097020626068\n","11 0.4784201681613922\n","11 0.4004661440849304\n","11 0.044993806630373\n","11 0.0189539585262537\n","11 0.11592798680067062\n","11 0.13925541937351227\n","11 0.021569857373833656\n","11 0.00214094715192914\n","11 0.016908708959817886\n","11 0.00264732469804585\n","11 0.11154269427061081\n","11 0.41313496232032776\n","11 0.051435843110084534\n","11 0.0049709752202034\n","11 0.13239210844039917\n","11 0.06497472524642944\n","11 0.206449955701828\n","11 0.01364064123481512\n","11 0.32672759890556335\n","11 0.444961279630661\n","11 0.12395217269659042\n","11 0.12408651411533356\n","11 0.27308401465415955\n","11 0.3054209351539612\n","11 0.5502429604530334\n","11 0.11886369436979294\n","11 0.12528128921985626\n","11 0.13795062899589539\n","11 0.11478734761476517\n","11 0.274895578622818\n","11 0.03912735357880592\n","11 0.43011850118637085\n","11 0.0003026032936759293\n","11 0.14887356758117676\n","11 0.4630640745162964\n","11 0.5988548398017883\n","11 0.5618972182273865\n","11 0.17928041517734528\n","11 0.4940328001976013\n","11 0.012434435077011585\n","11 0.16890160739421844\n","11 0.06080081686377525\n","11 0.13106471300125122\n","11 0.34712743759155273\n","11 0.26190194487571716\n","11 0.12476065009832382\n","11 0.07800434529781342\n","11 0.004933660384267569\n","11 0.14496996998786926\n","11 0.05912366136908531\n","11 0.07800008356571198\n","11 0.036540765315294266\n","11 0.0038315090350806713\n","11 0.5126731991767883\n","11 0.14581580460071564\n","11 0.1278901845216751\n","11 1.1929274797439575\n","11 0.19269432127475739\n","11 0.048020899295806885\n","11 0.0035015693865716457\n","11 0.06297224014997482\n","11 0.37936633825302124\n","11 0.0018271447625011206\n","11 0.045497190207242966\n","11 0.20030510425567627\n","11 0.7286028861999512\n","11 0.0019615255296230316\n","11 0.18042783439159393\n","11 0.2032506763935089\n","11 0.017666149884462357\n","11 0.2492285966873169\n","11 0.07839317619800568\n","11 0.2949429750442505\n","11 0.6288319826126099\n","11 0.001527481246739626\n","11 0.04795759916305542\n","11 0.12324808537960052\n","11 0.005379306152462959\n","11 0.2658514380455017\n","11 0.0017613020027056336\n","11 0.1883365660905838\n","11 0.006197228562086821\n","11 0.09082942456007004\n","11 0.029407087713479996\n","11 0.09037300199270248\n","11 0.05492180585861206\n","11 0.437396764755249\n","11 0.3364873230457306\n","11 0.5879309177398682\n","12 0.007748081348836422\n","12 1.9122389554977417\n","13 0.03668784722685814\n","13 0.19585108757019043\n","13 0.2388201504945755\n","13 0.02171914093196392\n","13 0.03942900896072388\n","13 0.004282791167497635\n","13 0.3352978825569153\n","13 0.15935413539409637\n","13 0.07864999026060104\n","13 0.05351441353559494\n","13 0.36638686060905457\n","13 0.7302334904670715\n","13 0.0048752883449196815\n","13 0.05028585344552994\n","13 0.2431129813194275\n","13 2.347200870513916\n","13 0.2041425108909607\n","13 0.0005728081450797617\n","13 0.1422015279531479\n","13 0.006186047103255987\n","13 0.003108050674200058\n","13 0.29479745030403137\n","13 0.23441870510578156\n","13 0.03392482548952103\n","13 0.0064062452875077724\n","13 0.027487458661198616\n","13 0.1650545597076416\n","13 0.2480611354112625\n","13 0.41258805990219116\n","13 0.06001746654510498\n","13 0.02127380482852459\n","13 0.1558811217546463\n","13 0.14140033721923828\n","13 0.14775118231773376\n","13 0.003982555586844683\n","13 0.006645834539085627\n","13 0.04734555259346962\n","13 0.0004269309574738145\n","13 0.0019148803548887372\n","13 0.08754036575555801\n","13 0.0010529225692152977\n","13 0.0224772896617651\n","13 0.06970302015542984\n","13 0.018785620108246803\n","13 0.04825671389698982\n","13 0.025002887472510338\n","13 0.1876249611377716\n","13 0.054754532873630524\n","13 0.0064329891465604305\n","13 0.05468582361936569\n","13 0.04172540828585625\n","13 0.022125234827399254\n","13 0.01751222275197506\n","13 0.0025483155623078346\n","13 0.17604775726795197\n","13 0.4492100477218628\n","13 0.2283998280763626\n","13 0.22904840111732483\n","13 0.14092521369457245\n","13 0.08103775233030319\n","13 0.0012460406869649887\n","13 0.005180502310395241\n","13 0.06409264355897903\n","13 0.12973986566066742\n","13 0.07389496266841888\n","13 0.02884039469063282\n","13 0.10212106257677078\n","13 0.011471536010503769\n","13 0.0004864927032031119\n","13 0.0009232492884621024\n","13 0.15611805021762848\n","13 0.0038362331688404083\n","13 0.05545007809996605\n","13 0.054353367537260056\n","13 0.06527286022901535\n","13 0.026878653094172478\n","13 0.1339658945798874\n","13 0.2231452763080597\n","13 0.31307944655418396\n","13 0.307210773229599\n","13 0.07925881445407867\n","13 0.028338907286524773\n","13 0.04070837050676346\n","13 0.11368658393621445\n","13 0.10017508268356323\n","14 0.002079441212117672\n","14 0.09730430692434311\n","14 0.07973744720220566\n","14 0.06658338755369186\n","14 0.2779184579849243\n","14 0.15468193590641022\n","14 0.00019773781241383404\n","14 0.03605709224939346\n","14 0.19516712427139282\n","14 0.0007292290683835745\n","14 0.11688182502985\n","14 0.005461524706333876\n","14 0.01374118123203516\n","14 0.0016812646063044667\n","14 0.08263124525547028\n","14 0.13210079073905945\n","14 0.0016177460784092546\n","14 0.08907666802406311\n","14 0.008525000885128975\n","14 0.002271372592076659\n","14 0.2182662934064865\n","14 0.04721905663609505\n","14 0.08804135769605637\n","14 0.00036612991243600845\n","14 0.00999778788536787\n","14 0.13850729167461395\n","14 0.3458789587020874\n","14 0.0016987501876428723\n","14 0.06304046511650085\n","14 0.4044337272644043\n","14 0.20041267573833466\n","14 0.0025358139537274837\n","14 0.03477107360959053\n","14 0.009461640380322933\n","14 0.17299997806549072\n","14 0.004639555234462023\n","14 0.00726364366710186\n","14 0.019284149631857872\n","14 0.05278097093105316\n","14 0.23461821675300598\n","14 0.1808481514453888\n","14 0.04268324375152588\n","14 0.4062175452709198\n","14 0.02420203387737274\n","14 0.10605551302433014\n","14 0.0009556353907100856\n","14 0.02627233788371086\n","14 0.20394089818000793\n","15 0.07848211377859116\n","15 0.05538586899638176\n","15 0.006776303518563509\n","15 0.059541333466768265\n","15 0.01851070113480091\n","15 0.0029290844686329365\n","15 0.3235366642475128\n","15 0.1656075268983841\n","15 8.223695658671204e-06\n","15 0.2672635614871979\n","15 0.17486214637756348\n","15 0.07678789645433426\n","15 0.0512230210006237\n","15 0.0009262653766199946\n","15 0.011792022734880447\n","15 0.2911098897457123\n","15 0.11665306240320206\n","15 0.04058685526251793\n","15 0.022163836285471916\n","15 0.004626313224434853\n","15 0.06502408534288406\n","15 0.16416385769844055\n","15 0.009659886360168457\n","15 0.010958314873278141\n","15 0.005664953496307135\n","15 0.03864629566669464\n","15 0.006853614468127489\n","15 9.590836270945147e-05\n","15 0.004238096997141838\n","15 0.051779668778181076\n","15 0.0047243861481547356\n","15 0.09438207000494003\n","15 0.4149240255355835\n","15 1.0332382917404175\n","15 0.5024073719978333\n","15 0.08759482949972153\n","15 0.014777552336454391\n","15 0.19395646452903748\n","15 0.2887764871120453\n","15 0.23038582503795624\n","15 0.9676578044891357\n","15 0.06566914916038513\n","15 0.2106640338897705\n","15 0.43023234605789185\n","15 0.03811047226190567\n","15 0.45136603713035583\n","15 0.024841494858264923\n","15 0.009835203178226948\n","15 0.047400765120983124\n","15 0.07636142522096634\n","15 0.259224534034729\n","15 0.05001462250947952\n","15 8.96264537004754e-05\n","15 0.028775649145245552\n","15 0.002899225102737546\n","15 0.40913671255111694\n","15 0.42230239510536194\n","15 0.4677373170852661\n","15 0.07919332385063171\n","15 0.013350049033761024\n","15 0.06570825725793839\n","15 0.1946500986814499\n","15 0.14362993836402893\n","15 0.06832508742809296\n","15 0.10894779115915298\n","15 0.16260957717895508\n","15 0.0008107060566544533\n","15 0.06533183157444\n","15 0.11797989904880524\n","15 0.012025975622236729\n","15 0.009480945765972137\n","15 0.18015530705451965\n","15 0.012305986136198044\n","15 0.046135302633047104\n","15 0.03025900200009346\n","15 0.04948453977704048\n","15 0.036472614854574203\n","15 329.6866760253906\n","16 0.05880408361554146\n","16 0.0036675988230854273\n","16 0.001423605252057314\n","16 0.4708569049835205\n","16 0.4111069440841675\n","16 0.6147276759147644\n","16 0.07601816952228546\n","16 0.44107842445373535\n","16 0.6054121851921082\n","16 0.4406605064868927\n","16 0.3639284372329712\n","16 0.21990495920181274\n","16 0.25681644678115845\n","16 0.3528766334056854\n","16 0.29124730825424194\n","16 0.07802166044712067\n","16 0.2111435979604721\n","16 0.6765568256378174\n","16 0.23609966039657593\n","16 0.3974446654319763\n","16 0.6493673920631409\n","16 0.13032621145248413\n","16 0.8249879479408264\n","16 0.12641769647598267\n","16 0.08628194779157639\n","16 0.011803003028035164\n","16 0.535692572593689\n","16 0.018014146015048027\n","16 0.015966713428497314\n","16 0.000461885763797909\n","16 0.026463745161890984\n","16 0.03058169037103653\n","16 0.0008929881732910872\n","16 0.5325387716293335\n","16 0.07980585843324661\n","16 0.4089598059654236\n","16 0.4297108054161072\n","16 0.27275222539901733\n","16 0.2821986973285675\n","16 7.383286720141768e-05\n","16 0.3712954819202423\n","16 0.00015938407159410417\n","16 0.21603937447071075\n","16 0.11935146152973175\n","16 0.6857168078422546\n","16 0.0037320454139262438\n","16 0.07750148326158524\n","16 0.21561980247497559\n","16 17.338003158569336\n","17 0.11976167559623718\n","17 0.058980438858270645\n","17 0.16602343320846558\n","17 0.22357796132564545\n","17 0.5716557502746582\n","17 0.29058581590652466\n","17 2.8981979994568974e-05\n","17 0.5332064032554626\n","17 0.841055691242218\n","17 7.7102484703063965\n","18 0.09630465507507324\n","18 0.27376770973205566\n","18 0.9555294513702393\n","18 0.02262020856142044\n","18 0.28397616744041443\n","18 0.18345877528190613\n","18 0.1480233073234558\n","18 0.38585934042930603\n","18 0.08774138242006302\n","18 0.0405791699886322\n","18 0.1809617280960083\n","18 0.050262972712516785\n","18 0.10100202262401581\n","18 0.014530730433762074\n","18 0.019597426056861877\n","18 0.5478876233100891\n","18 0.0034288144670426846\n","18 0.9114994406700134\n","18 0.006851798854768276\n","18 0.6883886456489563\n","18 0.017909212037920952\n","18 0.13123151659965515\n","18 0.009995594620704651\n","18 0.12440519034862518\n","18 0.3796412944793701\n","18 0.1858697235584259\n","18 0.0010252862703055143\n","18 0.004315369296818972\n","18 0.06667225062847137\n","18 0.04659384489059448\n","18 0.05679522454738617\n","18 0.0011631065281108022\n","18 0.3873981535434723\n","18 0.18017108738422394\n","18 0.039908234030008316\n","18 0.028303759172558784\n","18 0.19991688430309296\n","18 0.04070990905165672\n","18 0.016028352081775665\n","18 0.23477715253829956\n","18 0.05440318211913109\n","18 0.12710732221603394\n","18 0.021870773285627365\n","18 0.023890295997262\n","18 0.020286256447434425\n","18 0.3256644010543823\n","18 0.11399903148412704\n","18 0.014455070719122887\n","18 0.001237336895428598\n","18 0.1504344940185547\n","18 0.11764895915985107\n","18 0.0003167669055983424\n","18 0.16833025217056274\n","18 0.0411892831325531\n","18 0.028644759207963943\n","18 0.6357387900352478\n","18 0.1840110570192337\n","18 0.36591020226478577\n","18 0.05452559143304825\n","18 0.10429231822490692\n","18 0.4865238666534424\n","18 4.8785481452941895\n","19 0.15381596982479095\n","19 0.01459759846329689\n","19 6.0633487009909004e-05\n","19 0.2878879904747009\n","19 0.0020513562485575676\n","19 0.046462394297122955\n","19 0.38876160979270935\n","19 0.20663632452487946\n","19 0.10667570680379868\n","19 0.6538030505180359\n","19 0.07532087713479996\n","19 0.1678473800420761\n","19 0.011718195863068104\n","19 0.055920422077178955\n","19 0.07307364046573639\n","19 0.004865770693868399\n","19 0.42681869864463806\n","19 0.7362225651741028\n","19 0.09923014044761658\n","19 0.00033395030186511576\n","19 0.2017957717180252\n","19 0.23205780982971191\n","19 0.028282102197408676\n","19 0.12205339968204498\n","19 1.065625548362732\n","19 0.0015493633691221476\n","19 0.001888016238808632\n","20 0.2083008885383606\n","20 0.04799352586269379\n","20 0.06934694945812225\n","20 0.10627240687608719\n","20 0.43894341588020325\n","20 0.45366913080215454\n","20 0.04718880355358124\n","20 0.8379458785057068\n","20 0.0004322282620705664\n","20 0.07531668990850449\n","20 0.026704447343945503\n","20 0.01583959348499775\n","20 0.005430417601019144\n","20 0.0009055428672581911\n","20 0.012365725822746754\n","20 5.388192948885262e-05\n","20 0.21868887543678284\n","20 0.14220008254051208\n","20 0.47921040654182434\n","20 0.10915879905223846\n","20 0.09581016004085541\n","20 0.20785237848758698\n","20 0.0645567998290062\n","20 0.17622427642345428\n","20 0.08641141653060913\n","20 0.051152896136045456\n","20 0.0946832001209259\n","20 0.010796389542520046\n","20 0.06536206603050232\n","20 0.07901843637228012\n","20 0.3111879825592041\n","20 0.1404319405555725\n","20 1.3544086868932936e-05\n","20 0.2621460258960724\n","20 0.13866208493709564\n","20 4.752833774546161e-06\n","20 0.11630869656801224\n","20 0.28187811374664307\n","20 0.03089670091867447\n","20 0.0001683685986790806\n","20 0.1294603943824768\n","20 0.0732085332274437\n","20 0.00016109833086375147\n","20 0.07402931153774261\n","20 0.11439123749732971\n","20 0.15865062177181244\n","20 0.02102375030517578\n","20 0.06842384487390518\n","20 0.027549156919121742\n","20 0.6291458606719971\n","21 0.6147807240486145\n","21 0.2245611697435379\n","21 0.26239120960235596\n","21 0.18321867287158966\n","21 0.3297589421272278\n","21 0.5077956914901733\n","21 0.0004475894966162741\n","21 0.11982934176921844\n","21 0.23039406538009644\n","21 0.33056995272636414\n","21 0.0198704544454813\n","21 0.001026294194161892\n","21 0.08758579939603806\n","21 0.005084714386612177\n","21 0.10134844481945038\n","21 0.0025770890060812235\n","21 0.06464429944753647\n","21 0.07647215574979782\n","21 0.10364317893981934\n","21 0.05188605561852455\n","21 0.12406602501869202\n","21 2.0529114408418536e-05\n","21 0.0029606535099446774\n","21 0.09334425628185272\n","21 0.2928299903869629\n","21 0.0022716454695910215\n","21 0.9145293235778809\n","21 0.48583894968032837\n","21 0.1257898211479187\n","21 0.007380337454378605\n","21 0.31770578026771545\n","21 0.1239854171872139\n","21 0.0008835800690576434\n","21 0.30494415760040283\n","21 0.4086707830429077\n","21 0.002951942151412368\n","21 0.4626079499721527\n","22 0.06366649270057678\n","22 0.3759782016277313\n","22 0.2665846049785614\n","22 0.1011020615696907\n","22 0.03249270096421242\n","22 1.5041993856430054\n","22 0.15268327295780182\n","22 0.004701536614447832\n","22 0.2735222578048706\n","22 0.4019908607006073\n","22 0.00012406482710503042\n","22 0.11565198749303818\n","22 0.2720215618610382\n","22 0.36645960807800293\n","22 0.35499686002731323\n","22 0.027912992984056473\n","22 0.08412984758615494\n","22 0.018305229023098946\n","22 0.043659523129463196\n","22 0.008682546205818653\n","22 0.35609039664268494\n","22 0.34727129340171814\n","22 0.047806303948163986\n","22 0.03760908916592598\n","22 0.0005882490077055991\n","22 0.009056152775883675\n","22 0.06999362260103226\n","22 0.03388040140271187\n","22 0.5239170789718628\n","22 0.0481036938726902\n","22 0.12170182168483734\n","22 0.17261859774589539\n","22 0.007608276791870594\n","22 0.02633327804505825\n","22 0.0010488108964636922\n","22 0.345333993434906\n","22 0.0032109159510582685\n","22 0.006543375086039305\n","22 0.18123891949653625\n","22 0.01999945007264614\n","22 0.03747161477804184\n","22 0.07905463129281998\n","22 0.1190992221236229\n","22 0.0065498570911586285\n","22 0.2827187180519104\n","22 0.26139315962791443\n","22 0.006270643323659897\n","22 0.00533372862264514\n","22 0.006622997112572193\n","22 3.253477188991383e-05\n","22 0.23409005999565125\n","22 0.16804435849189758\n","22 0.006494787987321615\n","22 0.2313724160194397\n","22 0.2794121503829956\n","22 0.032926831394433975\n","22 0.4441835880279541\n","22 0.018765626475214958\n","22 0.0001295739784836769\n","22 0.1687197983264923\n","22 0.00033527612686157227\n","22 0.04313800856471062\n","22 0.13650217652320862\n","22 0.0715465173125267\n","22 0.11119674891233444\n","22 0.060586076229810715\n","22 0.1279195249080658\n","22 0.04814867302775383\n","22 0.1496937870979309\n","22 0.012358727864921093\n","22 3.0711562430951744e-05\n","22 0.024815047159790993\n","22 0.1697358936071396\n","22 0.06082339212298393\n","22 0.025371277704834938\n","22 0.028900999575853348\n","22 0.08649301528930664\n","22 0.07414767891168594\n","22 0.14630675315856934\n","22 0.4885241687297821\n","22 0.0022977194748818874\n","22 0.12348691374063492\n","22 0.010207517072558403\n","22 0.0007693754159845412\n","22 0.0016406881622970104\n","22 0.666654646396637\n","22 0.6785750985145569\n","22 0.042097728699445724\n","22 0.018801439553499222\n","22 0.0048189847730100155\n","22 0.03376166522502899\n","22 0.10514222830533981\n","22 0.08488114178180695\n","22 0.25494804978370667\n","22 0.7914760112762451\n","22 0.00015257165068760514\n","22 0.0765940397977829\n","22 0.38623738288879395\n","22 0.18872621655464172\n","22 0.4052565395832062\n","22 0.003382454626262188\n","22 0.0019215632928535342\n","22 0.1071840301156044\n","22 0.043854426592588425\n","22 0.02139708586037159\n","22 0.027997342869639397\n","22 8.436123607680202e-05\n","22 0.28880414366722107\n","22 0.01479494757950306\n","22 0.007466448936611414\n","22 0.2931676208972931\n","22 0.04498763754963875\n","22 1.5441482901223935e-06\n","22 0.0012061699526384473\n","22 0.058297332376241684\n","22 0.08471895754337311\n","22 0.004737242590636015\n","22 0.04852566495537758\n","22 0.0457889549434185\n","22 0.004901159089058638\n","22 0.13639579713344574\n","22 0.10798731446266174\n","22 0.09373042732477188\n","22 0.0028556399047374725\n","22 0.5130529403686523\n","22 0.1387949287891388\n","22 0.006120514590293169\n","22 0.4590744376182556\n","22 0.007057540584355593\n","22 0.09669838100671768\n","22 0.017773929983377457\n","22 0.4446280002593994\n","22 0.9249979853630066\n","22 0.015090584754943848\n","22 0.1121036559343338\n","22 0.00012418170808814466\n","22 0.107560895383358\n","22 0.18246996402740479\n","22 0.1190679594874382\n","22 0.01704390160739422\n","22 0.0012352244229987264\n","22 0.006879851687699556\n","22 0.0014175307005643845\n","22 0.006960135884582996\n","22 0.008089902810752392\n","22 0.1616005152463913\n","22 0.0011741911293938756\n","22 0.3342461585998535\n","22 0.1525193601846695\n","22 0.1774912178516388\n","22 0.09354657679796219\n","22 0.06141753867268562\n","22 0.04245932027697563\n","22 0.3327305316925049\n","22 0.2102999985218048\n","22 0.13895770907402039\n","22 0.004464931786060333\n","22 0.31063175201416016\n","22 0.2009108066558838\n","22 0.018309101462364197\n","22 0.01231614500284195\n","22 0.4397929906845093\n","22 0.4038989841938019\n","22 0.018356360495090485\n","22 0.0025847440119832754\n","22 0.20551331341266632\n","22 0.03678874671459198\n","22 0.17787553369998932\n","22 0.17481906712055206\n","22 0.0930100604891777\n","22 0.6195179224014282\n","22 0.3717692196369171\n","22 0.009458486922085285\n","22 0.1477453112602234\n","22 0.1419074982404709\n","22 0.033996179699897766\n","22 0.007405757438391447\n","22 0.0001226983149535954\n","22 0.0018676836043596268\n","22 0.1224595457315445\n","22 0.9341283440589905\n","22 0.05002827197313309\n","22 0.005157464649528265\n","22 0.015957435593008995\n","22 0.5271934866905212\n","22 0.2124611884355545\n","22 0.07167156785726547\n","22 3.670794285426382e-06\n","22 0.14011476933956146\n","22 0.025276273488998413\n","22 0.42805197834968567\n","22 0.0012784994905814528\n","22 0.04268481954932213\n","22 0.0006467679631896317\n","22 0.005733781959861517\n","22 0.004067501984536648\n","22 0.022905096411705017\n","22 0.0005850152228958905\n","22 0.052261676639318466\n","22 0.005759519059211016\n","22 0.05860329046845436\n","22 0.000711949251126498\n","22 0.1211780533194542\n","22 0.07315358519554138\n","22 0.03196589648723602\n","22 0.008576679043471813\n","22 0.004662970080971718\n","22 0.006916762329638004\n","22 0.013571782037615776\n","22 0.002323206514120102\n","22 0.009472126141190529\n","22 0.27186140418052673\n","22 0.0006944744382053614\n","22 0.06881605833768845\n","22 0.047738559544086456\n","22 0.0384209007024765\n","22 6.522608600789681e-06\n","22 0.3730390965938568\n","22 1.1617408745223656e-05\n","22 0.014893711544573307\n","22 0.036450762301683426\n","22 0.04900118708610535\n","22 0.06651204079389572\n","22 0.05242881178855896\n","22 0.20830349624156952\n","22 0.12389879673719406\n","22 0.05069643631577492\n","22 0.03077010065317154\n","22 0.014452205039560795\n","22 0.011764698661863804\n","22 0.0007382705807685852\n","22 0.023356756195425987\n","22 0.41675421595573425\n","22 0.08552195131778717\n","22 0.11624626070261002\n","22 0.07800088822841644\n","22 0.20422179996967316\n","22 0.0049261609092354774\n","22 0.036991700530052185\n","22 0.04367566481232643\n","22 0.23181714117527008\n","22 0.03799699246883392\n","22 0.18272262811660767\n","22 0.3903198838233948\n","22 0.12260309606790543\n","22 0.11126162856817245\n","22 0.0018046712502837181\n","22 0.03861330449581146\n","22 0.4998217225074768\n","22 0.013799822889268398\n","22 0.1243409514427185\n","22 0.024909481406211853\n","22 0.007404115982353687\n","22 0.1079515889286995\n","22 0.033198386430740356\n","22 0.11797989904880524\n","22 0.04744894802570343\n","22 0.2594080865383148\n","22 0.07629556208848953\n","22 0.04109720513224602\n","22 0.018021441996097565\n","22 0.00030524679459631443\n","22 0.036830101162195206\n","22 0.3107008635997772\n","22 0.0015378231182694435\n","22 0.007589239627122879\n","22 0.027948854491114616\n","22 0.05872178450226784\n","22 0.05059213191270828\n","22 0.013947424478828907\n","22 0.02984272502362728\n","22 0.004113736096769571\n","22 0.03176739439368248\n","22 7.252756040543318e-05\n","22 0.00022546830587089062\n","22 0.004978777840733528\n","22 0.04494840279221535\n","22 0.12324105203151703\n","22 0.013347184285521507\n","22 0.10325546562671661\n","22 0.011767388321459293\n","22 0.3693089783191681\n","22 0.7405872344970703\n","22 0.5900388360023499\n","22 0.36221370100975037\n","22 0.0129728177562356\n","22 0.11846520006656647\n","22 0.032783009111881256\n","22 0.005526557564735413\n","22 0.00039898898103274405\n","22 0.0004363222687970847\n","22 0.00040776128298603\n","22 0.062117211520671844\n","22 0.0004350084927864373\n","22 0.0001226771855726838\n","22 0.20618917047977448\n","22 0.01701602339744568\n","22 0.004212309140712023\n","22 0.04018132761120796\n","22 0.38470974564552307\n","22 0.06863205134868622\n","22 0.3307805359363556\n","22 0.12501442432403564\n","22 0.19852326810359955\n","22 0.27365046739578247\n","22 0.006784784607589245\n","22 0.00460014445707202\n","22 341.2002868652344\n","23 0.07350092381238937\n","23 0.027470067143440247\n","23 0.1778445690870285\n","23 0.23745284974575043\n","23 0.48616671562194824\n","23 0.5631174445152283\n","23 0.21009188890457153\n","23 0.06341047585010529\n","23 0.22751648724079132\n","23 0.04932153597474098\n","23 0.12789838016033173\n","23 0.33159884810447693\n","23 0.11741061508655548\n","23 0.49468857049942017\n","23 0.49304190278053284\n","23 1.4005025625228882\n","23 0.6427093148231506\n","23 0.6987181901931763\n","23 0.004968621768057346\n","23 0.4355991780757904\n","23 0.2020447552204132\n","23 0.177852600812912\n","23 0.1225406602025032\n","23 0.13758496940135956\n","23 0.12041934579610825\n","23 0.16124340891838074\n","23 0.023695824667811394\n","23 0.205082505941391\n","23 0.35395723581314087\n","23 0.13775764405727386\n","23 0.06401709467172623\n","23 0.3936474025249481\n","23 0.0011913444614037871\n","23 0.015129739418625832\n","23 0.002381532220169902\n","23 0.15820840001106262\n","23 0.7719851136207581\n","23 0.5398313403129578\n","23 0.01526800449937582\n","23 0.3332962989807129\n","23 0.28465908765792847\n","23 0.05196189880371094\n","23 0.4833202362060547\n","23 0.06565912812948227\n","23 2.0206318367854692e-05\n","23 0.4075844883918762\n","23 0.4231996536254883\n","23 0.41361966729164124\n","23 18.51566505432129\n","24 0.022202329710125923\n","24 0.31070563197135925\n","24 0.06728261709213257\n","24 13.946126937866211\n","25 0.021602783352136612\n","25 0.2840559482574463\n","25 0.05977030098438263\n","25 0.45346295833587646\n","25 0.6785531044006348\n","25 4.543567657470703\n","26 0.16863088309764862\n","26 0.8367974162101746\n","26 0.01322736032307148\n","26 0.06512918323278427\n","26 0.16599157452583313\n","26 0.13742370903491974\n","26 0.04172872006893158\n","26 0.0017486372962594032\n","26 0.40099015831947327\n","26 0.03415761515498161\n","26 0.0028329556807875633\n","26 0.01607777178287506\n","26 0.1114395260810852\n","26 0.024482358247041702\n","26 3.481889009475708\n","26 0.09210743755102158\n","26 0.14032797515392303\n","26 0.0023513310588896275\n","26 0.6579574942588806\n","26 0.2356078028678894\n","26 0.0007926150574348867\n","26 0.5305300951004028\n","26 0.03077210858464241\n","26 0.0359264612197876\n","26 0.350421667098999\n","26 4.583277702331543\n","26 0.48689112067222595\n","26 0.34589800238609314\n","26 0.10256955027580261\n","26 0.0012553154956549406\n","26 1.2351996898651123\n","26 0.30465561151504517\n","26 1.4132969226920977e-05\n","26 0.28411492705345154\n","26 0.008776728995144367\n","26 0.06840413808822632\n","26 0.04169521853327751\n","26 0.2285347580909729\n","26 0.009438278153538704\n","26 0.12993745505809784\n","26 0.0013765394687652588\n","26 0.20629355311393738\n","26 0.3950577974319458\n","26 0.8206530809402466\n","26 0.027927972376346588\n","26 0.246427983045578\n","26 0.06776734441518784\n","26 0.03654605150222778\n","26 0.29048043489456177\n","26 0.08963655680418015\n","26 0.44762054085731506\n","26 0.07011958211660385\n","26 0.12930534780025482\n","26 0.0005694123101420701\n","26 3.3759130019461736e-05\n","26 0.08326544612646103\n","26 0.13669568300247192\n","26 0.147670179605484\n","26 0.17761419713497162\n","26 0.0013030658010393381\n","26 0.20120029151439667\n","26 0.11546071618795395\n","26 0.08264879137277603\n","26 0.018719667568802834\n","26 0.06886360049247742\n","26 0.012639347463846207\n","26 0.05994459614157677\n","26 0.1686704456806183\n","26 0.06228560581803322\n","26 0.15702824294567108\n","26 0.00036649496178142726\n","26 0.0367627777159214\n","26 0.005709976423531771\n","26 0.02045981027185917\n","26 0.3840368986129761\n","26 0.11794190108776093\n","26 0.09863021969795227\n","26 0.26193806529045105\n","26 0.3036026954650879\n","26 0.3094295561313629\n","26 0.0300146397203207\n","26 0.030713584274053574\n","26 0.0453321635723114\n","26 0.029335172846913338\n","26 0.029297616332769394\n","26 0.03935972973704338\n","26 0.06312813609838486\n","26 0.21899403631687164\n","26 0.20863616466522217\n","26 0.007846777327358723\n","26 0.07503324747085571\n","26 0.12126637995243073\n","26 0.012416045181453228\n","26 0.11624040454626083\n","26 0.21768034994602203\n","26 0.006515556015074253\n","26 0.09374911338090897\n","26 0.5378509163856506\n","26 0.457223117351532\n","26 0.06357027590274811\n","26 0.19849267601966858\n","26 0.05847153812646866\n","26 0.19776678085327148\n","26 0.016299458220601082\n","26 0.05511686950922012\n","26 0.04469360411167145\n","26 0.01078113541007042\n","26 0.0025437921285629272\n","26 0.07420066744089127\n","26 0.05175623297691345\n","26 0.014025019481778145\n","26 0.0403723381459713\n","26 0.09878602623939514\n","26 0.283467173576355\n","26 0.34880104660987854\n","26 0.7856926918029785\n","26 1.015962839126587\n","26 0.06504572927951813\n","26 0.03078683279454708\n","26 0.1151103600859642\n","26 0.036542221903800964\n","26 0.017326191067695618\n","26 0.11908277124166489\n","26 0.060443438589572906\n","26 0.1170540452003479\n","26 0.008982700295746326\n","26 0.0170761626213789\n","26 0.185843825340271\n","26 0.03871644288301468\n","26 320.8157958984375\n","27 0.011743606068193913\n","27 0.19019028544425964\n","27 0.016310418024659157\n","27 0.025549622252583504\n","27 0.6298828125\n","27 0.328328937292099\n","27 0.007149008568376303\n","27 0.00023004505783319473\n","27 3.93959903717041\n","28 0.034859154373407364\n","28 0.063941590487957\n","28 3.6449196338653564\n","28 0.2936376929283142\n","28 0.14530858397483826\n","28 0.9827165603637695\n","28 5.610383033752441\n","29 0.906268835067749\n","29 0.05989043787121773\n","29 1.173546314239502\n","29 2.0771255493164062\n","29 0.15567748248577118\n","29 0.3767259120941162\n","29 0.2449045181274414\n","29 0.33987587690353394\n","29 0.2020871937274933\n","29 0.40781405568122864\n","29 7.172411918640137\n","30 0.05626079812645912\n","30 0.1370389759540558\n","30 0.284102201461792\n","30 1.1739575862884521\n","30 0.23776523768901825\n","30 6.765592098236084\n","31 0.08975452184677124\n","31 2.0022168159484863\n","31 0.47831496596336365\n","31 4.754324436187744\n","32 0.6365838646888733\n","32 0.22198988497257233\n","32 0.6741750836372375\n","32 2.6035995483398438\n","33 0.0160160381346941\n","33 0.10005498677492142\n","33 0.23423127830028534\n","33 0.07694680243730545\n","33 0.29685306549072266\n","33 0.06819427758455276\n","33 0.0662064254283905\n","33 0.01430833712220192\n","33 1.635096549987793\n","33 0.16756774485111237\n","34 1.9179786443710327\n","34 0.023194381967186928\n","35 0.22908490896224976\n","35 0.015071963891386986\n","35 0.1752675473690033\n","35 0.007111321669071913\n","35 0.2911618649959564\n","35 0.09403987973928452\n","35 0.0758221372961998\n","35 0.12128996104001999\n","35 4.1009440422058105\n","35 4.788447404280305e-05\n","35 0.025637654587626457\n","35 0.1114264726638794\n","35 0.607502818107605\n","35 0.6047289371490479\n","36 0.10546500235795975\n","36 1.2394195795059204\n","36 0.0001528780849184841\n","36 2.6693038307712413e-05\n","36 2.8041834831237793\n","36 0.01005537062883377\n","36 0.007757402025163174\n","36 0.5041657090187073\n","36 0.14983366429805756\n","36 0.05704163387417793\n","36 0.07792126387357712\n","36 0.5302008986473083\n","36 0.09930436313152313\n","36 0.10235525667667389\n","36 0.6977977156639099\n","36 0.0008714324794709682\n","36 0.7434632778167725\n","36 0.05120057612657547\n","36 0.013968606479465961\n","36 0.04032463952898979\n","36 0.18242678046226501\n","36 0.3427111506462097\n","36 0.1391497403383255\n","36 1.1635444164276123\n","36 0.03172559291124344\n","36 0.06673234701156616\n","36 0.4322282373905182\n","36 1.0724509954452515\n","36 0.1799125224351883\n","36 1.2119570970535278\n","36 1.6096097230911255\n","36 0.4683225452899933\n","36 0.06880255043506622\n","36 0.14894533157348633\n","36 0.061172693967819214\n","36 0.20533911883831024\n","36 0.14220979809761047\n","36 0.08741258829832077\n","36 0.1728215217590332\n","36 0.39214521646499634\n","36 0.1561327427625656\n","36 0.0023567909374833107\n","36 0.05675341561436653\n","36 0.28676438331604004\n","36 0.42495596408843994\n","36 0.09462539851665497\n","36 0.3770766258239746\n","36 0.016917763277888298\n","36 0.6464856266975403\n","36 0.07308781892061234\n","36 0.9324929714202881\n","36 0.02021690458059311\n","36 0.015984192490577698\n","36 0.5728034973144531\n","36 0.09490577131509781\n","36 0.8857160806655884\n","36 1.6091632843017578\n","36 0.19257168471813202\n","36 0.2802642285823822\n","36 1.2525877952575684\n","36 0.09217691421508789\n","36 1.8400318622589111\n","36 0.11297032982110977\n","36 0.15792402625083923\n","36 0.08241263031959534\n","36 0.0003946385986637324\n","36 0.0007280706195160747\n","36 0.04170729219913483\n","36 0.004971042275428772\n","36 0.01962907984852791\n","36 0.30478301644325256\n","36 0.40512967109680176\n","36 0.2602568566799164\n","36 0.01630920171737671\n","36 0.2518956661224365\n","36 0.0906076729297638\n","36 0.13791094720363617\n","36 0.2286587804555893\n","36 0.04566129297018051\n","36 0.04890602082014084\n","36 0.1642148643732071\n","36 0.0836925357580185\n","36 0.06462053954601288\n","36 0.2975929379463196\n","36 0.103342205286026\n","36 0.282478928565979\n","36 0.10413438081741333\n","36 0.004715868271887302\n","36 0.32128992676734924\n","36 0.03501138091087341\n","36 0.020492427051067352\n","36 0.5550404787063599\n","36 0.009610740467905998\n","36 0.000308990478515625\n","36 0.17631155252456665\n","36 0.021611755713820457\n","36 0.01671864278614521\n","36 0.003028548788279295\n","36 0.11639034748077393\n","36 0.13373981416225433\n","36 0.25025373697280884\n","36 0.02841489389538765\n","36 0.4836166501045227\n","36 0.4281655550003052\n","36 0.16809479892253876\n","36 0.13662764430046082\n","36 5.6732827943051234e-05\n","36 0.4347391724586487\n","36 0.11952713876962662\n","36 0.0029013820458203554\n","36 0.15131130814552307\n","36 0.020668230950832367\n","36 0.007488219533115625\n","36 0.00237701996229589\n","36 6.988542736507952e-06\n","36 0.08774562180042267\n","36 1.0844800472259521\n","36 0.00014379608910530806\n","36 0.20600301027297974\n","36 0.841754674911499\n","36 0.04540732502937317\n","36 0.6351815462112427\n","36 0.1405184417963028\n","36 0.09086737036705017\n","36 0.0001098888460546732\n","36 0.09231971204280853\n","36 0.18280743062496185\n","36 0.05100826919078827\n","36 0.040252089500427246\n","36 0.00288425013422966\n","36 0.038919370621442795\n","36 0.013613143935799599\n","36 0.03458034247159958\n","36 0.07743936777114868\n","36 0.010833085514605045\n","36 0.008057168684899807\n","36 0.02618800662457943\n","36 0.004918131977319717\n","36 0.024506239220499992\n","36 0.0552624948322773\n","36 0.06527773290872574\n","36 0.2000516653060913\n","36 0.09710212051868439\n","36 7.564682164229453e-06\n","36 0.002232723170891404\n","36 0.09724541008472443\n","36 0.02255198545753956\n","36 0.0070388056337833405\n","36 0.01996682584285736\n","36 0.048825278878211975\n","36 0.007186795584857464\n","36 0.10432034730911255\n","36 0.31882914900779724\n","36 0.06568576395511627\n","36 0.08099133521318436\n","36 0.007417251355946064\n","36 0.014008309692144394\n","36 0.03134218230843544\n","36 0.002244093455374241\n","36 0.013162288814783096\n","36 0.006863407790660858\n","36 0.5218889117240906\n","36 0.09424500167369843\n","36 0.21888694167137146\n","36 0.046433620154857635\n","36 0.0674038827419281\n","36 0.41482943296432495\n","36 0.17866313457489014\n","36 0.05529702827334404\n","36 0.019650062546133995\n","36 0.009687275625765324\n","36 1.400250792503357\n","36 0.20817120373249054\n","36 0.06577084958553314\n","36 0.1748940497636795\n","36 1.3135955333709717\n","36 0.011706636287271976\n","36 0.11777590960264206\n","36 0.2054087072610855\n","36 0.14512942731380463\n","36 0.009736334905028343\n","36 0.001101434463635087\n","36 0.027136625722050667\n","36 0.027428671717643738\n","36 0.021981628611683846\n","36 0.001393433311022818\n","36 0.014864396303892136\n","36 0.0469554103910923\n","36 0.015381339937448502\n","36 0.6054233312606812\n","36 0.00010551451850915328\n","36 0.11467009037733078\n","36 1.4772626161575317\n","36 0.3109869062900543\n","36 0.03922022134065628\n","36 0.08087792992591858\n","36 0.06886209547519684\n","36 304.9999694824219\n","37 0.0033323904499411583\n","37 0.0006206255638971925\n","37 0.03395592421293259\n","37 0.05588705092668533\n","37 0.14521990716457367\n","37 0.3923662006855011\n","37 0.07762100547552109\n","37 0.05717701092362404\n","37 0.06919384002685547\n","37 0.30831703543663025\n","37 0.024532372131943703\n","37 3.2200586795806885\n","37 1.6739416122436523\n","37 0.2838221788406372\n","37 0.550687313079834\n","37 0.20075908303260803\n","37 0.10592667013406754\n","37 1.8993473052978516\n","37 0.45670285820961\n","37 0.4593335688114166\n","37 0.37139543890953064\n","37 0.23153667151927948\n","37 0.12772244215011597\n","37 1.438801646232605\n","37 0.26082542538642883\n","37 0.08217652887105942\n","37 0.2625158131122589\n","37 0.07570742815732956\n","37 0.07512574642896652\n","37 0.14518356323242188\n","37 0.002175015164539218\n","37 0.05509336292743683\n","37 0.26518115401268005\n","37 0.08090315014123917\n","37 0.02497047744691372\n","37 0.009271877817809582\n","37 0.41668710112571716\n","37 0.11962804943323135\n","37 0.1724482625722885\n","37 0.028603777289390564\n","37 0.27262571454048157\n","37 0.2379838526248932\n","37 0.1293746381998062\n","37 0.14753571152687073\n","37 0.3444876968860626\n","37 8.359437942504883\n","38 0.08943566679954529\n","38 0.4462217390537262\n","38 0.23406283557415009\n","38 0.15370042622089386\n","38 0.09545625746250153\n","38 0.06537571549415588\n","38 0.17273114621639252\n","38 0.3393090069293976\n","38 0.3193737864494324\n","38 0.32721784710884094\n","38 0.21908017992973328\n","38 0.03478085249662399\n","38 0.09346083551645279\n","38 0.06336821615695953\n","38 0.31898587942123413\n","38 0.03582657128572464\n","38 0.3604142665863037\n","38 0.06779391318559647\n","38 0.029848657548427582\n","38 0.22493506968021393\n","38 0.12125475704669952\n","38 0.023865832015872\n","38 0.006249515805393457\n","38 0.023340143263339996\n","38 0.19154146313667297\n","39 0.0001278967974940315\n","39 0.023374540731310844\n","39 0.2871266007423401\n","39 0.006980518810451031\n","39 0.22087335586547852\n","39 0.08265893906354904\n","39 4.8699628678150475e-05\n","39 0.5952013731002808\n","39 0.006525104865431786\n","39 0.07877279818058014\n","39 0.19125273823738098\n","39 1.4793012269365136e-05\n","39 0.1412314772605896\n","39 0.08430033177137375\n","39 0.0005223857006058097\n","39 0.11405731737613678\n","39 0.2225838452577591\n","39 0.035804372280836105\n","39 0.0019217305816709995\n","39 0.06587067246437073\n","39 0.019490767270326614\n","39 1.058066487312317\n","39 0.15211811661720276\n","39 0.015140533447265625\n","39 0.14011333882808685\n","39 0.004645273555070162\n","39 0.06357123702764511\n","39 0.5270688533782959\n","39 0.02459469996392727\n","39 0.07417001575231552\n","39 2.417831274215132e-05\n","39 0.20967288315296173\n","39 0.1808907389640808\n","39 0.511187732219696\n","39 1.5479950904846191\n","39 0.5554753541946411\n","39 0.11185983568429947\n","39 0.1406114101409912\n","39 0.08964113146066666\n","39 0.02615961804986\n","39 0.5173887610435486\n","39 0.046995922923088074\n","39 0.02608686313033104\n","39 5.448564479593188e-07\n","39 0.0024840228725224733\n","39 9.590836270945147e-05\n","39 0.21304666996002197\n","39 0.06141210347414017\n","39 0.24615584313869476\n","39 0.0056878020986914635\n","39 0.00381829752586782\n","39 0.2628520727157593\n","39 0.0398608073592186\n","39 0.07818744331598282\n","39 0.034789927303791046\n","39 0.14453637599945068\n","39 0.07553616911172867\n","39 0.006235049106180668\n","39 0.006533119361847639\n","39 0.1270906627178192\n","39 0.005381055176258087\n","39 0.0011237012222409248\n","39 0.10063259303569794\n","39 0.006887922063469887\n","39 0.0008056091610342264\n","39 0.020458174869418144\n","39 0.0035987915471196175\n","39 0.0035756013821810484\n","39 0.031231693923473358\n","39 0.043199434876441956\n","39 0.15317481756210327\n","39 0.06172635778784752\n","39 0.2845553159713745\n","39 0.13807249069213867\n","39 0.2218371480703354\n","39 0.0029305298812687397\n","39 0.022059746086597443\n","39 0.08024290949106216\n","39 0.14588899910449982\n","39 0.017879869788885117\n","39 0.019511675462126732\n","39 0.01640384830534458\n","39 0.1366068422794342\n","39 0.7248427867889404\n","39 0.2776374816894531\n","39 0.19240514934062958\n","39 0.19260181486606598\n","39 0.5125386714935303\n","39 1.136242151260376\n","39 273.56903076171875\n","40 1.015786051750183\n","40 0.06994140893220901\n","40 0.03644603118300438\n","40 1.413857340812683\n","41 0.004662970080971718\n","41 0.16492323577404022\n","41 0.019895870238542557\n","41 0.206069678068161\n","41 0.26702550053596497\n","41 0.620176374912262\n","41 0.20869629085063934\n","41 1.6627198457717896\n","42 0.9331976175308228\n","42 0.008016216568648815\n","42 0.104296013712883\n","42 0.09229885041713715\n","42 0.48502832651138306\n","42 0.04686266928911209\n","42 0.9601084589958191\n","42 0.07426068931818008\n","42 0.1122499480843544\n","42 1.2787469625473022\n","42 1.1999791860580444\n","42 0.49595174193382263\n","42 0.3658767640590668\n","42 0.22362124919891357\n","42 0.09448376297950745\n","42 0.11251242458820343\n","42 0.15285176038742065\n","42 0.008556906133890152\n","42 0.4342067241668701\n","42 0.0029791556298732758\n","42 0.41620829701423645\n","42 0.9098384976387024\n","42 0.37140706181526184\n","42 0.2044615000486374\n","42 0.05142243579030037\n","42 0.24357213079929352\n","42 0.1319604516029358\n","42 0.3070923686027527\n","42 0.07907608151435852\n","42 0.04318675026297569\n","42 0.09682802110910416\n","42 0.43110352754592896\n","42 0.0011528838658705354\n","42 0.07355031371116638\n","42 0.3134920597076416\n","42 0.597728431224823\n","42 0.0036775972694158554\n","42 0.11054164916276932\n","42 0.0009640856296755373\n","42 0.06772564351558685\n","42 0.1651998907327652\n","42 0.6961639523506165\n","42 0.06866978108882904\n","42 0.06322281807661057\n","42 0.02478230744600296\n","42 0.3672989308834076\n","42 0.24175545573234558\n","42 0.05369966849684715\n","42 0.005562489852309227\n","42 0.009029671549797058\n","42 0.22779496014118195\n","42 0.030977047979831696\n","42 0.055624932050704956\n","42 0.14355947077274323\n","42 0.04650763049721718\n","42 0.4611470699310303\n","42 0.04360354691743851\n","42 0.13778667151927948\n","42 0.006080589257180691\n","42 0.0013522335793823004\n","42 0.5909460783004761\n","42 0.0012396862730383873\n","42 0.35533902049064636\n","42 0.003418881678953767\n","42 0.040673933923244476\n","42 0.11689617484807968\n","42 1.1388337952666916e-06\n","42 0.10107477754354477\n","42 0.04645252972841263\n","42 0.020281773060560226\n","42 0.024562852457165718\n","42 0.27080926299095154\n","42 0.009326227940618992\n","42 0.7780484557151794\n","42 0.19628603756427765\n","42 0.11064662784337997\n","42 0.09555469453334808\n","42 0.15741129219532013\n","42 0.15017826855182648\n","42 0.00411642761901021\n","42 0.6141976118087769\n","42 0.5476561188697815\n","42 0.1301269382238388\n","42 0.3882753551006317\n","42 0.15754716098308563\n","42 0.006934699136763811\n","42 0.039278414100408554\n","42 0.009638714604079723\n","42 0.009152335114777088\n","42 0.006478811614215374\n","42 0.5863233208656311\n","42 0.0419011116027832\n","42 0.14043408632278442\n","42 0.022207871079444885\n","42 0.06151684373617172\n","42 0.018442774191498756\n","42 0.0040250374004244804\n","42 0.009824613109230995\n","42 0.5009901523590088\n","42 0.10135997831821442\n","42 0.1600729525089264\n","42 0.016011934727430344\n","42 0.020274711772799492\n","42 0.006016507279127836\n","42 0.024371761828660965\n","42 0.024706698954105377\n","42 0.07453043013811111\n","42 0.06925255060195923\n","42 0.14900679886341095\n","42 0.03964138776063919\n","42 0.15289276838302612\n","42 0.387891560792923\n","42 0.005734070669859648\n","42 0.03239564597606659\n","42 0.03860168904066086\n","42 0.13286446034908295\n","42 0.007022013422101736\n","42 0.05849967896938324\n","42 0.0001358578447252512\n","42 0.18562845885753632\n","42 0.12386590242385864\n","42 0.01752939075231552\n","42 0.006600353866815567\n","42 0.03557232394814491\n","42 0.17216560244560242\n","42 0.03447650000452995\n","42 0.16373291611671448\n","42 1.988847255706787\n","42 0.11738316714763641\n","42 261.42413330078125\n","43 0.49574288725852966\n","43 0.11350337415933609\n","43 1.196487307548523\n","43 0.38288119435310364\n","43 0.5339879989624023\n","43 0.039061736315488815\n","43 2.9929676055908203\n","44 0.020872056484222412\n","44 0.2367604523897171\n","44 0.01021532341837883\n","44 0.26841849088668823\n","44 0.06277233362197876\n","44 1.8823702335357666\n","45 0.01359868235886097\n","45 0.09632951766252518\n","45 0.08833108097314835\n","45 0.142410546541214\n","45 0.12204207479953766\n","45 0.07981367409229279\n","45 0.9424034357070923\n","45 0.6857673525810242\n","46 2.0251810550689697\n","46 0.023183055222034454\n","46 0.9904404282569885\n","46 0.2442074716091156\n","46 0.709380030632019\n","46 0.00011055967479478568\n","46 0.4045562446117401\n","46 0.5502507090568542\n","47 0.16921451687812805\n","47 0.0005077333771623671\n","47 0.3763391077518463\n","47 0.5331938862800598\n","47 0.03582548722624779\n","47 0.08210109174251556\n","47 0.009663823992013931\n","47 0.3795837163925171\n","47 0.36699268221855164\n","47 0.010129237547516823\n","47 0.000225310810492374\n","47 0.19932377338409424\n","47 0.002720543881878257\n","47 0.17508114874362946\n","47 0.4277849793434143\n","47 0.24897632002830505\n","47 1.1708401441574097\n","47 2.7886836528778076\n","47 0.20717552304267883\n","47 0.9509363174438477\n","47 0.03471649810671806\n","47 1.1847285032272339\n","47 0.042357590049505234\n","47 0.21626637876033783\n","47 0.15353931486606598\n","47 0.31980618834495544\n","47 0.03428198769688606\n","47 0.20815640687942505\n","47 0.00016369909280911088\n","47 0.01989869587123394\n","47 0.32144996523857117\n","47 0.03136852756142616\n","47 5.506135494215414e-06\n","47 0.005146786104887724\n","47 0.37506651878356934\n","47 0.03108977898955345\n","47 0.12818844616413116\n","47 0.28131890296936035\n","47 0.05265747383236885\n","47 0.10422918945550919\n","47 0.19354592263698578\n","47 0.22729364037513733\n","47 0.0013457884779199958\n","47 1.2995224096812308e-07\n","47 0.22245654463768005\n","47 0.245200052857399\n","47 0.18321377038955688\n","47 0.010629966855049133\n","47 0.010402589105069637\n","47 0.6803572177886963\n","47 0.001434240024536848\n","47 0.0044870078563690186\n","47 0.03912358358502388\n","47 0.131308913230896\n","47 0.19192229211330414\n","47 0.13767872750759125\n","47 0.07809466868638992\n","47 0.003132876008749008\n","47 0.03866992145776749\n","47 0.002854620572179556\n","47 0.007233601529151201\n","47 0.2707844376564026\n","47 0.10169301927089691\n","47 0.08380265533924103\n","47 0.008963187225162983\n","47 0.02809380739927292\n","47 0.20784150063991547\n","47 0.04048355296254158\n","47 0.356001615524292\n","47 0.10624349862337112\n","47 0.36396467685699463\n","47 0.00207622442394495\n","47 0.0008365143439732492\n","47 0.16272766888141632\n","47 0.5063817501068115\n","47 0.03214894235134125\n","47 0.00863560102880001\n","47 0.203405499458313\n","47 0.0005723061040043831\n","47 0.002580479020252824\n","47 0.3708324730396271\n","47 0.01169137004762888\n","47 0.05606168508529663\n","47 0.0008181087323464453\n","47 0.03243548050522804\n","47 0.00011915373033843935\n","47 1.0167839527130127\n","47 0.04429369047284126\n","47 0.005005326122045517\n","48 0.00019386789062991738\n","48 0.14290077984333038\n","48 0.04554114118218422\n","48 0.05810912698507309\n","49 0.476034939289093\n","49 0.43178629875183105\n","49 0.025409268215298653\n","49 0.29309841990470886\n","49 0.1862831711769104\n","49 0.0024819320533424616\n","49 0.016224300488829613\n","49 0.036573950201272964\n","49 3.6307064874563366e-06\n","49 0.004601696971803904\n","49 0.002751621650531888\n","49 0.10794281959533691\n","49 0.02280244790017605\n","49 0.0314263217151165\n","49 0.2533624470233917\n","49 0.28494563698768616\n","49 0.09911661595106125\n","49 0.055657774209976196\n","49 0.11821389943361282\n","49 0.1808157116174698\n","49 0.08364040404558182\n","49 7.19116214895621e-05\n","49 0.010854337364435196\n","49 0.00010101804946316406\n","49 0.14836767315864563\n","49 0.2641028165817261\n","49 0.015103474259376526\n","49 0.16483920812606812\n","49 0.18908682465553284\n","49 0.17549680173397064\n","49 0.18700748682022095\n","49 0.12452126294374466\n","49 0.02629491128027439\n","49 0.030700214207172394\n","49 0.23904576897621155\n","49 0.006233392283320427\n","49 0.2691027522087097\n","49 0.356437623500824\n","49 0.0006625305977649987\n","49 0.22439850866794586\n","49 0.06591278314590454\n","49 0.05753536522388458\n","49 1.5871055438765325e-06\n","49 0.3156203031539917\n","49 0.002908166730776429\n","49 0.025822294875979424\n","49 0.031595271080732346\n","49 0.04037731885910034\n","49 0.0944746732711792\n","49 0.004712594207376242\n","49 0.029406432062387466\n","49 0.004375784192234278\n","49 0.11748218536376953\n","49 0.6855865120887756\n","49 0.03085162490606308\n","49 0.12720559537410736\n","49 0.0051993271335959435\n","49 0.22953839600086212\n","49 0.11567534506320953\n","49 0.3614971935749054\n","49 0.08673550933599472\n","49 0.11473081260919571\n","49 0.4850907623767853\n","49 0.06262928992509842\n","49 0.04519176110625267\n","49 0.022655794396996498\n","49 0.14859183132648468\n","49 0.003962599206715822\n","49 0.4150210916996002\n","49 0.06278117001056671\n","49 1.9576444625854492\n","49 0.1343899965286255\n","49 287.9251403808594\n","50 2.4195804595947266\n","50 0.12990480661392212\n","50 0.6801888942718506\n","50 0.0027875567320734262\n","50 0.05192473158240318\n","50 0.3141176402568817\n","50 0.0007718109991401434\n","50 0.5508055090904236\n","50 1.0175774097442627\n","50 0.033583864569664\n","50 0.32408422231674194\n","50 0.15890713036060333\n","50 0.46315038204193115\n","50 1.1397560834884644\n","50 0.19846676290035248\n","50 0.13431483507156372\n","50 0.8457369804382324\n","50 0.4629829525947571\n","50 0.02496158704161644\n","50 5.46265172958374\n","51 0.039167359471321106\n","51 0.002616648096591234\n","51 0.4044349491596222\n","51 0.025097528472542763\n","51 0.30994221568107605\n","51 0.05149880424141884\n","51 0.43350446224212646\n","51 0.07264581322669983\n","51 0.3705224096775055\n","51 0.006197228562086821\n","51 3.27697491645813\n","52 0.029430150985717773\n","52 0.34801971912384033\n","52 0.059983596205711365\n","52 0.003241738071665168\n","52 0.4454251527786255\n","52 0.09377831220626831\n","52 0.050220221281051636\n","52 0.3047308921813965\n","52 0.027163024991750717\n","52 0.28676488995552063\n","52 0.01138019748032093\n","52 0.04215880110859871\n","52 0.09505771845579147\n","52 0.012680659070611\n","52 0.22291918098926544\n","52 0.05207282677292824\n","52 0.02863265573978424\n","52 0.02461414597928524\n","52 0.13231126964092255\n","52 0.003670833772048354\n","52 0.09557592123746872\n","52 0.10117879509925842\n","52 0.026662852615118027\n","52 0.28398582339286804\n","52 0.044201210141181946\n","52 0.05064362660050392\n","52 0.07772599160671234\n","52 0.14745622873306274\n","52 0.03893912956118584\n","52 1.651432991027832\n","52 0.00029888213612139225\n","52 0.006977013312280178\n","52 2.1922225952148438\n","52 0.012299745343625546\n","52 0.07114174962043762\n","52 0.3539265990257263\n","52 0.0023157200776040554\n","52 0.2020168900489807\n","52 1.0102620124816895\n","52 0.0100533626973629\n","52 0.4487141966819763\n","52 0.3728003203868866\n","52 0.016475379467010498\n","52 1.241382360458374\n","52 0.06942231208086014\n","52 0.01326028537005186\n","52 0.07667271792888641\n","52 1.2377479076385498\n","52 0.2820816934108734\n","52 0.01960957609117031\n","52 0.0003642709634732455\n","52 0.0006265077390708029\n","52 0.17074637115001678\n","52 0.06040124222636223\n","52 0.025276880711317062\n","52 0.011371043510735035\n","52 0.3308968245983124\n","52 0.00046700332313776016\n","52 0.0006153151043690741\n","52 0.1464136391878128\n","52 3.95455899706576e-05\n","52 0.011760457418859005\n","52 0.04821126535534859\n","52 1.579991340637207\n","52 234.78590393066406\n","53 0.6001499891281128\n","53 1.0038775205612183\n","54 0.005475629586726427\n","54 0.05750288441777229\n","54 0.08938005566596985\n","54 0.9517409205436707\n","54 0.23516269028186798\n","54 0.5523247122764587\n","54 0.14702917635440826\n","54 1.11762535572052\n","54 0.815954864025116\n","54 0.6278877258300781\n","54 0.05845955014228821\n","54 0.9687566161155701\n","54 0.18345102667808533\n","54 0.4036377966403961\n","54 0.09868413954973221\n","54 0.3822152316570282\n","54 0.8315355777740479\n","54 0.0011342114303261042\n","54 0.2925008535385132\n","54 0.8070322871208191\n","54 0.35826820135116577\n","54 0.017940621823072433\n","54 0.4883928596973419\n","54 0.010151037015020847\n","54 187.9873504638672\n","55 0.17638644576072693\n","55 0.008238717913627625\n","55 0.6957041025161743\n","55 0.04590759426355362\n","55 0.10880114883184433\n","55 0.16355660557746887\n","55 0.20505227148532867\n","55 0.26648712158203125\n","55 0.08882807195186615\n","55 0.005032012704759836\n","55 10.576315879821777\n","56 0.20294424891471863\n","56 0.24316422641277313\n","56 0.1796238124370575\n","56 0.41968557238578796\n","56 0.056063491851091385\n","56 0.7042911052703857\n","56 0.11921016126871109\n","56 0.0945344790816307\n","56 0.10867252945899963\n","56 0.20653748512268066\n","56 0.008785039186477661\n","56 0.07787388563156128\n","56 0.7370296120643616\n","56 0.0491943284869194\n","56 0.016306886449456215\n","56 0.05318378284573555\n","56 0.15716998279094696\n","56 0.20248137414455414\n","56 0.16290083527565002\n","56 0.09116774052381516\n","56 0.24616625905036926\n","56 0.4095601439476013\n","56 0.07063189893960953\n","56 0.018381694331765175\n","56 0.5559225082397461\n","56 0.3230242431163788\n","56 0.4890282452106476\n","56 0.0681375116109848\n","56 0.06435341387987137\n","56 0.04980156943202019\n","56 0.0817694142460823\n","56 0.002045960631221533\n","56 0.12248958647251129\n","56 0.024618783965706825\n","56 0.033353041857481\n","56 0.8633872866630554\n","56 1.0145983695983887\n","56 0.035057615488767624\n","56 0.11288219690322876\n","56 0.028576685115695\n","56 6.055925041437149e-07\n","56 0.08358028531074524\n","56 0.0027285581454634666\n","56 0.014110986143350601\n","56 0.1579236537218094\n","56 0.03275538980960846\n","56 0.09478446841239929\n","56 0.05996304377913475\n","56 0.5760554075241089\n","56 0.28584128618240356\n","56 0.36556071043014526\n","56 0.003973472863435745\n","56 0.12816999852657318\n","56 0.002125486731529236\n","56 0.03661390393972397\n","56 0.04885963350534439\n","56 0.47354114055633545\n","56 0.06909177452325821\n","56 0.23614415526390076\n","56 1.1256201105425134e-05\n","56 0.03634141758084297\n","56 0.14099645614624023\n","56 0.3761916756629944\n","56 0.24265049397945404\n","56 0.025106744840741158\n","56 2.6370742321014404\n","56 0.35504117608070374\n","56 224.633544921875\n","57 0.50986647605896\n","57 0.43400755524635315\n","57 0.2651016116142273\n","57 0.06354647129774094\n","57 2.1697866916656494\n","57 0.02907327190041542\n","57 1.0713342428207397\n","57 0.005159793421626091\n","57 0.004764653742313385\n","57 2.315117835998535\n","58 0.018385056406259537\n","58 0.0431085005402565\n","58 0.04742942377924919\n","58 0.36153215169906616\n","58 0.03854399919509888\n","58 0.02801106870174408\n","58 0.872196614742279\n","58 0.12224938720464706\n","58 0.5954316854476929\n","58 2.431283974146936e-06\n","58 0.29149335622787476\n","58 0.09097232669591904\n","58 0.21648508310317993\n","58 0.18352168798446655\n","58 0.03437546268105507\n","58 0.6464710235595703\n","58 0.5881847143173218\n","58 0.5719773769378662\n","58 0.008482260629534721\n","58 0.02973918989300728\n","58 0.7230779528617859\n","58 0.071132592856884\n","58 0.03342745453119278\n","58 0.15805670619010925\n","58 0.2508088946342468\n","58 0.00021295927581377327\n","58 0.01318330504000187\n","58 1.4125977754592896\n","58 0.091915063560009\n","58 1.3502178192138672\n","58 0.30566078424453735\n","58 0.04544086009263992\n","58 0.408976286649704\n","58 0.038566093891859055\n","58 0.18104246258735657\n","58 0.2491467148065567\n","58 0.009612703695893288\n","58 0.00245090969838202\n","58 0.2689672112464905\n","58 0.08871611952781677\n","58 0.2130735218524933\n","58 0.1728096306324005\n","58 0.42168599367141724\n","58 0.020594533532857895\n","58 0.01293960027396679\n","58 0.051751893013715744\n","58 0.01266487780958414\n","58 0.02866283990442753\n","58 0.052242495119571686\n","58 0.002556024119257927\n","58 0.006532502360641956\n","58 0.15242886543273926\n","58 0.05072392523288727\n","58 0.06426224112510681\n","58 0.055354002863168716\n","58 0.032678280025720596\n","58 0.13465967774391174\n","58 0.04827766865491867\n","58 0.26494941115379333\n","58 0.12831686437129974\n","58 0.06408081203699112\n","58 0.21287062764167786\n","58 0.670143723487854\n","58 0.02774578519165516\n","58 0.03564862906932831\n","58 0.2840310335159302\n","58 0.21892844140529633\n","58 0.03961670771241188\n","58 0.9499340653419495\n","58 0.3101227581501007\n","58 0.04950406029820442\n","58 0.5627217292785645\n","58 0.2621069848537445\n","58 0.19888971745967865\n","58 0.19578735530376434\n","58 0.2251259833574295\n","58 1.1075670719146729\n","58 0.6584294438362122\n","58 0.0012791474582627416\n","58 0.13382072746753693\n","58 0.02354602888226509\n","58 0.018198935315012932\n","58 0.027824632823467255\n","58 0.008065388537943363\n","58 0.00019025977235287428\n","58 0.10290702432394028\n","58 0.00581727409735322\n","58 0.10628857463598251\n","58 0.0033241375349462032\n","58 0.0007197314989753067\n","58 0.19688434898853302\n","58 0.30778613686561584\n","58 0.03113502822816372\n","58 0.09968187659978867\n","58 0.2012760192155838\n","58 0.06068775802850723\n","58 0.8342955112457275\n","58 0.08906812965869904\n","58 0.17281994223594666\n","58 0.7957570552825928\n","58 0.31715127825737\n","58 0.31693699955940247\n","58 0.146881103515625\n","58 0.017647139728069305\n","58 0.10489436239004135\n","58 0.13327565789222717\n","58 0.022766171023249626\n","58 0.007845594547688961\n","58 0.002961380174383521\n","58 0.16545504331588745\n","58 1.2782552242279053\n","58 0.10412361472845078\n","58 0.3217019736766815\n","58 0.19468586146831512\n","58 2.758228947641328e-05\n","58 0.0404994823038578\n","58 0.0455268956720829\n","58 0.4300546944141388\n","58 0.47139298915863037\n","58 0.014366346411406994\n","58 0.14438632130622864\n","58 0.6945543885231018\n","58 0.013350049033761024\n","58 0.007903649471700191\n","58 3.450011718086898e-05\n","58 0.00384580809623003\n","58 7.906927108764648\n","58 0.24588149785995483\n","58 0.0771816298365593\n","58 223.49105834960938\n","59 0.006935334764420986\n","59 0.814477264881134\n","59 0.11958055198192596\n","59 0.31880977749824524\n","59 0.016919376328587532\n","59 4.529440402984619\n","59 1.0987175703048706\n","59 2.705151081085205\n","59 0.21866969764232635\n","59 0.1083524078130722\n","59 0.18834194540977478\n","59 1.4164689779281616\n","60 0.03867311030626297\n","60 0.12153187394142151\n","60 0.13461384177207947\n","60 0.04814930260181427\n","60 0.25088196992874146\n","60 0.6206225752830505\n","60 1.1348580121994019\n","60 0.0021647976245731115\n","60 0.5856502056121826\n","60 1.0903854370117188\n","60 0.197267085313797\n","60 0.03787996619939804\n","60 0.09273889660835266\n","60 0.07037917524576187\n","60 0.12263815850019455\n","60 0.3462812006473541\n","60 1.466145634651184\n","60 0.4615311920642853\n","60 0.14984621107578278\n","60 0.5041528940200806\n","60 0.46230119466781616\n","60 0.1567034125328064\n","60 0.4033766984939575\n","60 0.08073343336582184\n","60 0.7144872546195984\n","60 1.1171172857284546\n","60 0.15935033559799194\n","60 0.3972643315792084\n","60 0.41395461559295654\n","60 0.5799822807312012\n","60 0.16925807297229767\n","60 0.3799322247505188\n","60 0.07444896548986435\n","60 0.5371460914611816\n","60 0.021883046254515648\n","60 0.6899205446243286\n","60 0.005917498376220465\n","60 0.2084663212299347\n","60 0.19707313179969788\n","60 0.07218386977910995\n","60 0.01387577224522829\n","60 0.20886535942554474\n","60 2.0089244842529297\n","60 175.7730255126953\n","61 0.03558437526226044\n","61 0.04964590445160866\n","61 0.40803638100624084\n","61 0.0131629453971982\n","61 0.0022442289628088474\n","61 0.4868691563606262\n","61 0.01132400706410408\n","61 0.19384728372097015\n","61 0.0016488877590745687\n","61 0.21317698061466217\n","61 0.42555174231529236\n","61 0.007285198662430048\n","61 0.4477290213108063\n","61 0.07860773801803589\n","61 5.403165340423584\n","62 0.07326170057058334\n","62 0.06931506097316742\n","62 3.449009895324707\n","63 0.10369814187288284\n","63 0.029105477035045624\n","63 0.4754481911659241\n","63 0.004151132423430681\n","63 0.2377801239490509\n","63 0.7508791089057922\n","63 7.291793008334935e-05\n","63 0.049614883959293365\n","63 0.10662836581468582\n","63 0.1268775761127472\n","63 0.02787158265709877\n","63 0.1344899982213974\n","63 0.054347362369298935\n","63 0.09313138574361801\n","63 0.019191687926650047\n","63 0.25031957030296326\n","63 0.054469045251607895\n","63 0.00954978633671999\n","63 0.008757798001170158\n","63 0.09781426936388016\n","63 0.3295869827270508\n","63 0.09439847618341446\n","63 0.0304853692650795\n","63 0.10457801073789597\n","63 0.19586458802223206\n","63 1.3838186264038086\n","63 0.7178107500076294\n","63 0.5730424523353577\n","63 0.16265574097633362\n","63 1.9723390340805054\n","63 0.010126933455467224\n","63 0.512367308139801\n","63 0.025368239730596542\n","63 0.12644483149051666\n","63 0.02177511528134346\n","63 0.10302973538637161\n","63 0.10538759082555771\n","63 0.031009452417492867\n","63 0.026923075318336487\n","63 0.0021431981585919857\n","63 0.026927614584565163\n","63 0.20159019529819489\n","63 0.018840819597244263\n","63 0.029752841219305992\n","63 0.0328664630651474\n","63 0.018592404201626778\n","63 0.15525558590888977\n","63 0.012037168256938457\n","63 0.26345235109329224\n","63 0.0008102173451334238\n","63 0.11533922702074051\n","63 0.03611578792333603\n","63 0.13132378458976746\n","63 0.8979744911193848\n","63 0.7200546264648438\n","63 0.13039197027683258\n","63 0.020520968362689018\n","63 0.6210388541221619\n","64 0.016292884945869446\n","64 0.017393289133906364\n","64 0.3829655647277832\n","64 0.35184744000434875\n","64 0.0103139728307724\n","64 0.007925879210233688\n","64 0.0883268266916275\n","64 0.3605751693248749\n","64 0.023615149781107903\n","64 0.16940680146217346\n","64 0.13701355457305908\n","64 0.12076343595981598\n","64 0.02596808597445488\n","64 0.058129359036684036\n","64 0.04552526772022247\n","64 0.00018403682042844594\n","64 0.17894703149795532\n","64 0.0001256312389159575\n","64 0.015253867022693157\n","64 0.17850999534130096\n","64 0.8371551036834717\n","64 0.2649395763874054\n","64 0.0998409241437912\n","64 0.00029225836624391377\n","64 0.3541887700557709\n","64 0.03321785107254982\n","64 0.008897758089005947\n","64 0.018652139231562614\n","64 0.028630880638957024\n","64 0.0019162159878760576\n","64 0.17844633758068085\n","64 2.2943766117095947\n","64 6.625197887420654\n","64 189.71719360351562\n","65 0.008214757777750492\n","65 0.4457784593105316\n","65 0.0013504105154424906\n","65 0.1569828987121582\n","65 0.3177530765533447\n","65 0.2996326684951782\n","65 0.3204650282859802\n","66 0.62828528881073\n","66 0.05948828533291817\n","66 0.24444741010665894\n","67 0.12920042872428894\n","67 0.44114112854003906\n","67 0.021384533494710922\n","67 0.001317460904829204\n","67 0.3036142587661743\n","67 0.6126768589019775\n","67 0.05400175228714943\n","67 0.002938278950750828\n","67 0.5348915457725525\n","67 0.020400650799274445\n","67 0.006377424579113722\n","67 1.5726109743118286\n","67 0.5282929539680481\n","67 1.597846508026123\n","67 2.598900556564331\n","67 0.015789702534675598\n","67 0.018173985183238983\n","67 0.7791070342063904\n","67 1.577172040939331\n","67 0.15315204858779907\n","67 0.03660423308610916\n","67 0.16538095474243164\n","67 0.0518094003200531\n","67 0.10171643644571304\n","67 0.0004801609320566058\n","67 0.5116924047470093\n","67 0.5091496706008911\n","67 0.45633751153945923\n","67 0.01889216899871826\n","67 0.17380772531032562\n","67 0.37655383348464966\n","67 2.6027348041534424\n","67 0.0027560757007449865\n","67 0.7168099880218506\n","67 0.1156957745552063\n","67 0.5359048247337341\n","67 0.02906579151749611\n","67 0.4596458077430725\n","67 0.5539801716804504\n","67 0.053577970713377\n","67 0.011908816173672676\n","67 0.28725436329841614\n","67 0.32069236040115356\n","67 0.07941246777772903\n","67 2.039167642593384\n","67 0.13057765364646912\n","67 3.7571403980255127\n","67 148.01687622070312\n","68 1.4333080053329468\n","68 0.0003666775592137128\n","68 0.07165522873401642\n","68 0.32836392521858215\n","68 0.9729824066162109\n","68 0.05834776908159256\n","68 0.13256636261940002\n","68 0.10929086059331894\n","68 0.4110996127128601\n","68 0.7311090230941772\n","68 0.2791999578475952\n","68 0.1734524667263031\n","68 0.3901066184043884\n","68 0.046564411371946335\n","68 0.30525705218315125\n","68 0.06825356930494308\n","68 0.016202565282583237\n","68 0.03789574280381203\n","68 0.00017824822862166911\n","68 0.32934942841529846\n","68 0.00265700020827353\n","68 0.009005130268633366\n","68 0.5486912727355957\n","68 0.6549023389816284\n","68 0.0835452750325203\n","68 0.14793305099010468\n","68 0.012574777938425541\n","68 0.0031941854394972324\n","68 0.03522297739982605\n","68 0.009218692779541016\n","68 0.08499426394701004\n","68 0.10330787301063538\n","68 0.007531360257416964\n","68 0.2560138404369354\n","68 0.38147035241127014\n","68 0.44195228815078735\n","68 0.059565071016550064\n","68 0.003956838045269251\n","68 0.06991467624902725\n","68 0.01631285436451435\n","68 1.0500670671463013\n","68 0.4884521961212158\n","68 0.12457578629255295\n","68 0.008985412307083607\n","68 0.0033930011559277773\n","68 0.12974810600280762\n","68 0.35795944929122925\n","68 1.064107060432434\n","68 0.1599321812391281\n","68 0.059539005160331726\n","68 0.11084561794996262\n","68 0.5256932973861694\n","68 0.0358802005648613\n","68 0.28603506088256836\n","68 0.13888874650001526\n","68 0.013692817650735378\n","68 0.0018151794793084264\n","68 0.3981766998767853\n","68 0.2817312777042389\n","68 0.015878746286034584\n","68 0.09372254461050034\n","68 0.06301915645599365\n","68 0.026000522077083588\n","68 0.4469827115535736\n","68 0.03041214868426323\n","68 0.01311277225613594\n","68 0.03254567086696625\n","68 0.055200859904289246\n","68 0.09038562327623367\n","68 0.02439231239259243\n","68 0.9644136428833008\n","68 0.2593333125114441\n","68 0.7387056946754456\n","68 0.37646254897117615\n","68 0.4004709720611572\n","68 1.0009558200836182\n","68 0.5532131195068359\n","68 0.4235030710697174\n","68 0.008653334341943264\n","68 0.3094751834869385\n","68 0.17264395952224731\n","68 0.08533965796232224\n","68 0.09589696675539017\n","68 0.031318552792072296\n","68 0.13852077722549438\n","68 0.001844265148974955\n","68 5.775742465630174e-05\n","68 0.13231994211673737\n","68 0.078065887093544\n","68 0.15370677411556244\n","68 1.5729649066925049\n","68 0.0005245895008556545\n","68 0.34114858508110046\n","68 0.03848261013627052\n","68 0.0013044432271271944\n","68 0.8791691064834595\n","68 1.4559450149536133\n","68 1.2628413438796997\n","68 0.5960544347763062\n","68 0.32887837290763855\n","68 0.05289474502205849\n","68 0.07417287677526474\n","68 0.09768038988113403\n","68 0.3331080377101898\n","68 0.5276498794555664\n","68 0.31873708963394165\n","68 0.02867850288748741\n","68 0.09997235238552094\n","68 0.04258577153086662\n","68 0.10320276021957397\n","68 0.1377211958169937\n","68 0.17770664393901825\n","68 8.712661743164062\n","68 11.4453706741333\n","68 0.029478762298822403\n","68 0.5653201937675476\n","68 0.30031222105026245\n","68 0.13557568192481995\n","68 0.5859779715538025\n","68 0.060472045093774796\n","68 1.134939193725586\n","68 0.3617156744003296\n","68 0.4194372594356537\n","68 0.0019298915285617113\n","68 1.587154746055603\n","68 4.566615581512451\n","68 165.25262451171875\n","69 0.5744315385818481\n","69 0.23926310241222382\n","69 0.01919393427670002\n","69 5.889718055725098\n","69 0.007791541982442141\n","69 1.113832712173462\n","69 0.057260047644376755\n","69 0.5217462778091431\n","69 0.19194276630878448\n","69 1.4375766515731812\n","69 0.2980431020259857\n","69 0.30109402537345886\n","69 0.29518023133277893\n","69 0.0019378598080947995\n","69 0.22663849592208862\n","69 0.022379456087946892\n","69 0.10587576776742935\n","69 0.2811560332775116\n","69 0.112700916826725\n","69 0.21122512221336365\n","69 0.018820011988282204\n","69 0.13489285111427307\n","69 0.17276720702648163\n","69 0.32895493507385254\n","69 0.015223493799567223\n","69 0.19562071561813354\n","69 0.28974178433418274\n","69 1.5072829723358154\n","69 0.04878862202167511\n","69 0.08852817863225937\n","69 0.01981685310602188\n","69 0.39938417077064514\n","69 0.07988643646240234\n","69 0.19024643301963806\n","69 0.007044167257845402\n","69 0.2028450071811676\n","69 0.1276433914899826\n","69 0.20521511137485504\n","69 0.053010836243629456\n","69 0.3685872256755829\n","69 0.02085704170167446\n","69 0.2117803692817688\n","69 6.939464947208762e-05\n","69 0.9029572010040283\n","69 0.2672625780105591\n","69 1.0070695877075195\n","69 0.47290804982185364\n","69 0.5387752056121826\n","69 0.27717387676239014\n","69 0.007501594722270966\n","69 0.3678227663040161\n","69 0.28792843222618103\n","69 3.0978240966796875\n","69 0.08667120337486267\n","69 3.5122382640838623\n","69 130.783447265625\n","70 0.048761241137981415\n","70 0.20725670456886292\n","70 0.3610294461250305\n","70 0.2858484089374542\n","70 0.013775299303233624\n","70 0.25684061646461487\n","70 0.6594156622886658\n","70 0.10120367258787155\n","70 0.014235193841159344\n","70 0.024820003658533096\n","70 0.3343525826931\n","70 0.11969897896051407\n","70 0.1919841319322586\n","70 0.7161359190940857\n","70 0.11089420318603516\n","70 0.005527053959667683\n","70 0.0012185557279735804\n","70 0.4685927629470825\n","70 0.12806111574172974\n","70 1.4455265998840332\n","70 0.12158773094415665\n","70 0.012562802992761135\n","70 1.3366361856460571\n","70 0.04279562458395958\n","70 1.4983230829238892\n","70 0.5086333155632019\n","70 0.8988775014877319\n","70 2.5869531631469727\n","70 3.0635673999786377\n","70 123.3232192993164\n","71 0.2559347152709961\n","71 0.05297878384590149\n","71 0.03887235000729561\n","71 1.1874371767044067\n","71 0.061621200293302536\n","71 0.5009759664535522\n","71 0.2943507730960846\n","71 0.02165973000228405\n","71 0.12211304903030396\n","71 1.757412314414978\n","71 0.6801676154136658\n","71 0.3944193720817566\n","71 1.8329740762710571\n","71 0.5667659640312195\n","71 2.911351442337036\n","71 106.43191528320312\n","72 0.02670164220035076\n","72 1.7538508176803589\n","72 0.6326901912689209\n","72 0.6643409132957458\n","72 0.34019342064857483\n","72 0.0011599212884902954\n","72 0.48208916187286377\n","72 0.20111346244812012\n","72 0.10041700303554535\n","72 0.09032398462295532\n","72 0.06442819535732269\n","72 0.1670193076133728\n","72 0.016148105263710022\n","72 0.10238149762153625\n","72 6.902223110198975\n","73 0.10131686925888062\n","73 0.0726427286863327\n","73 0.2221849411725998\n","73 0.05440584942698479\n","73 0.0051463753916323185\n","73 0.3922598659992218\n","73 0.12365621328353882\n","73 0.008230582810938358\n","73 0.4635879397392273\n","73 0.014194488525390625\n","73 0.012126795016229153\n","73 0.006677280645817518\n","73 2.7561092376708984\n","73 1.7964848279953003\n","73 0.30451035499572754\n","73 0.5497047305107117\n","73 0.16418471932411194\n","73 0.08344800025224686\n","73 0.3125908374786377\n","73 0.5967150330543518\n","73 0.2002231627702713\n","73 0.4190821945667267\n","73 0.015012661926448345\n","73 0.31319737434387207\n","73 0.008398675359785557\n","73 0.0417289137840271\n","73 0.10810235887765884\n","73 0.00046603521332144737\n","73 2.3507760488428175e-05\n","73 1.1313738822937012\n","73 0.033981937915086746\n","73 0.06344770640134811\n","73 0.13346268236637115\n","73 0.12313227355480194\n","73 0.10217013955116272\n","73 0.004998176824301481\n","73 0.4762652516365051\n","73 0.019077181816101074\n","73 0.10269664973020554\n","73 0.18139728903770447\n","73 0.4318809509277344\n","73 0.1205434799194336\n","73 0.5363112092018127\n","73 0.053111668676137924\n","73 0.6417425274848938\n","73 3.61326265335083\n","73 0.3644717335700989\n","73 7.393848419189453\n","73 110.29962921142578\n","74 3.1739304065704346\n","74 1.6459568738937378\n","74 1.0505841970443726\n","74 0.2903221547603607\n","74 0.7764358520507812\n","74 0.17940521240234375\n","74 0.08311416208744049\n","74 0.0556642971932888\n","74 0.0295780710875988\n","74 0.24375243484973907\n","74 0.9882027506828308\n","74 2.2298401745501906e-05\n","74 0.04744645580649376\n","74 1.6444852352142334\n","74 0.10058359056711197\n","74 0.10370950400829315\n","74 0.2141079604625702\n","74 0.23359200358390808\n","74 0.8054019212722778\n","74 0.004646378569304943\n","74 0.00012138139572925866\n","74 0.05172152444720268\n","74 0.15881779789924622\n","74 0.05202430859208107\n","74 0.8435580730438232\n","74 8.256744384765625\n","74 1.13612699508667\n","74 88.54226684570312\n","75 0.25936633348464966\n","75 0.7300721406936646\n","75 0.07368849217891693\n","75 0.00014617308625020087\n","75 0.4271520972251892\n","75 5.789435386657715\n","75 3.145639657974243\n","75 6.107502460479736\n","75 0.8062050938606262\n","75 77.09581756591797\n","76 0.4552210867404938\n","76 0.24057245254516602\n","76 1.7377647161483765\n","76 0.4016468822956085\n","76 0.0881848856806755\n","76 0.01668647490441799\n","76 0.197470024228096\n","76 0.14562976360321045\n","76 0.23720800876617432\n","76 0.5469562411308289\n","76 0.4272063374519348\n","76 0.27521318197250366\n","76 2.29364275932312\n","76 0.8296569585800171\n","76 0.4420996904373169\n","76 0.5472200512886047\n","76 0.921038031578064\n","76 0.8522025346755981\n","76 4.258589744567871\n","76 0.7307002544403076\n","76 0.019447851926088333\n","76 0.0936754122376442\n","76 0.20230428874492645\n","76 0.7477141618728638\n","76 0.010145008563995361\n","76 2.1054487228393555\n","76 0.7931657433509827\n","76 1.2917463779449463\n","76 1.145544409751892\n","76 0.12203241139650345\n","76 3.946040153503418\n","76 0.12978358566761017\n","76 0.15157809853553772\n","76 0.9000259637832642\n","76 64.28834533691406\n","77 0.6821912527084351\n","77 0.24162089824676514\n","77 0.6475710868835449\n","77 0.16552060842514038\n","77 0.3609076738357544\n","77 5.533679485321045\n","77 0.05018042400479317\n","77 55.690792083740234\n","78 1.3965585231781006\n","78 0.1204577386379242\n","78 0.5569213032722473\n","78 0.4762363135814667\n","78 0.7134844064712524\n","78 0.9646627902984619\n","78 1.4553711414337158\n","78 0.01836075447499752\n","78 0.6296470761299133\n","78 0.8970450162887573\n","78 0.9142033457756042\n","78 0.765682578086853\n","78 0.3412097096443176\n","78 0.8539831638336182\n","78 8.260619163513184\n","78 0.17619885504245758\n","78 45.71275329589844\n","79 0.002017674967646599\n","79 0.3687519431114197\n","79 0.42817023396492004\n","79 0.27045997977256775\n","79 0.31854408979415894\n","79 0.8609020709991455\n","79 0.05965331569314003\n","79 0.0965021550655365\n","79 1.4191296100616455\n","79 4.784774303436279\n","79 1.619171380996704\n","79 1.5393205881118774\n","79 0.13792866468429565\n","79 0.00456067593768239\n","79 17.380084991455078\n","79 1.0382236242294312\n","79 9.361939430236816\n","79 1.1456952095031738\n","79 36.64580535888672\n","80 0.002363230800256133\n","80 0.6457703709602356\n","80 1.893568754196167\n","80 2.3426759243011475\n","80 0.21678248047828674\n","80 0.4691426157951355\n","80 0.30128297209739685\n","80 0.38441285490989685\n","80 0.29938632249832153\n","80 0.13262678682804108\n","80 0.6003886461257935\n","80 0.35821282863616943\n","80 3.249161958694458\n","80 6.807900905609131\n","80 0.6196560263633728\n","80 0.8281552791595459\n","80 0.6879655718803406\n","80 18.769332885742188\n","80 0.11580155044794083\n","80 25.105329513549805\n","81 0.013290832750499249\n","81 0.3113555908203125\n","81 0.24608606100082397\n","81 0.45519277453422546\n","81 1.1782097816467285\n","81 0.5534085631370544\n","81 13.848316192626953\n","81 0.07859690487384796\n","81 20.19070053100586\n","82 1.4082379341125488\n","82 0.016376376152038574\n","82 0.5154728889465332\n","82 0.2518109679222107\n","82 0.09894345700740814\n","82 0.18344612419605255\n","82 0.20547613501548767\n","82 1.4603585004806519\n","82 0.14475835859775543\n","82 0.7732584476470947\n","82 0.45815345644950867\n","82 0.3624444603919983\n","82 4.024478912353516\n","82 9.186905860900879\n","82 0.08341136574745178\n","82 2.177194118499756\n","82 0.14006729423999786\n","82 0.028618374839425087\n","82 7.7527055740356445\n","82 4.451862335205078\n","82 0.34802308678627014\n","82 12.97782039642334\n","83 0.2251087874174118\n","83 0.09812769293785095\n","83 0.5743509531021118\n","83 0.09315932542085648\n","83 0.5051392912864685\n","83 1.2227301597595215\n","83 0.9539288282394409\n","83 32.839900970458984\n","83 0.030598202720284462\n","83 5.699324131011963\n","84 0.21215051412582397\n","84 1.2407890558242798\n","84 0.2690451145172119\n","84 2.7372374534606934\n","84 2.760810375213623\n","84 22.409557342529297\n","84 0.20135988295078278\n","84 2.563722610473633\n","85 2.397127389907837\n","85 40.542362213134766\n","86 0.6889821887016296\n","86 0.09532371163368225\n","86 0.26017269492149353\n","86 1.553418755531311\n","86 0.41999486088752747\n","86 38.81597137451172\n","86 0.08494812250137329\n","86 0.7686905264854431\n","87 1.7796447277069092\n","87 4.552718162536621\n","87 3.634465456008911\n","87 0.1572408825159073\n","87 0.05143357440829277\n","87 7.789840221405029\n","87 2.5140163898468018\n","87 1.2840713262557983\n","87 0.0063347709365189075\n","87 5.424436569213867\n","87 0.1827886700630188\n","87 0.5915313959121704\n","87 1.370882511138916\n","87 28.52003288269043\n","87 0.3836894631385803\n","87 1.3577048778533936\n","88 1.4243324995040894\n","88 0.1577993631362915\n","88 0.8424193263053894\n","88 0.6933578252792358\n","88 20.829448699951172\n","88 0.010584491305053234\n","88 0.8345621228218079\n","89 6.585113525390625\n","89 1.216499924659729\n","89 0.11705975234508514\n","89 0.8562381267547607\n","89 0.28970685601234436\n","89 0.7622520327568054\n","89 0.8346918821334839\n","89 0.34290212392807007\n","89 0.24806421995162964\n","89 0.9855027198791504\n","89 0.16559238731861115\n","89 3.2523140907287598\n","89 0.5455626249313354\n","89 1.7697474956512451\n","89 21.317276000976562\n","89 0.7327032685279846\n","89 0.7438621520996094\n","90 0.07860412448644638\n","90 0.6697140336036682\n","90 0.8307691812515259\n","90 1.0118374824523926\n","90 12.247818946838379\n","90 0.00025957636535167694\n","90 0.582245409488678\n","91 1.7367974519729614\n","91 0.31588825583457947\n","91 5.203244209289551\n","91 8.906574249267578\n","91 0.5043326616287231\n","91 0.06847124546766281\n","91 9.114453315734863\n","91 0.37857142090797424\n","91 0.5040079951286316\n","92 1.3516812324523926\n","92 0.5521838665008545\n","92 3.183759927749634\n","92 0.48816078901290894\n","92 4.769402027130127\n","92 0.47149431705474854\n","92 5.182341575622559\n","92 0.021948130801320076\n","92 7.142975807189941\n","92 0.34932899475097656\n","92 0.07103521376848221\n","93 1.8596326112747192\n","93 0.7649349570274353\n","93 1.6145741939544678\n","93 0.022579707205295563\n","93 3.5155856609344482\n","93 0.0003278050571680069\n","93 0.21004074811935425\n","93 5.20458984375\n","93 0.1499241143465042\n","93 1.808387041091919\n","93 0.004810514394193888\n","93 0.18730123341083527\n","94 0.006733938120305538\n","94 2.3504698276519775\n","94 5.9104323387146\n","94 0.07640175521373749\n","94 1.6150590181350708\n","94 0.06636307388544083\n","94 0.24103248119354248\n","95 0.5436667799949646\n","95 0.0881618931889534\n","95 0.20359058678150177\n","95 0.467535138130188\n","95 2.110609292984009\n","95 0.011367382481694221\n","95 0.0728461816906929\n","96 0.7738550305366516\n","96 0.02057611383497715\n","96 2.1562206745147705\n","96 0.03830462321639061\n","96 1.5485397577285767\n","96 0.09176131337881088\n","96 0.0644649937748909\n","97 0.9482491612434387\n","97 2.957289218902588\n","97 0.2790122628211975\n","97 0.06142793968319893\n","97 0.011847804300487041\n","97 0.020334232598543167\n","97 0.1369563788175583\n","98 0.24172627925872803\n","98 0.9489516019821167\n","98 2.793151378631592\n","98 0.3963373899459839\n","98 0.39645686745643616\n","98 0.5134902000427246\n","98 0.0022495181765407324\n","99 0.8015115857124329\n","99 1.4456294775009155\n","99 0.02841819077730179\n","99 0.0041067046113312244\n","99 0.05558355152606964\n","99 6.077448233554605e-06\n","99 22.661701202392578\n","99 0.019004805013537407\n","99 0.0028396600391715765\n","Initial State:\n","[['+' '-' ' ' 'P']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 0; Taking action: d\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' 'P']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 1; Taking action: d\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' ' ' 'P']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 2; Taking action: l\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' 'P' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 3; Taking action: l\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' 'P' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 4; Taking action: l\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," ['P' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 5; Taking action: u\n","[['+' '-' ' ' ' ']\n"," ['P' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Move #: 6; Taking action: u\n","[['+' '-' ' ' ' ']\n"," [' ' 'W' ' ' ' ']\n"," [' ' ' ' ' ' ' ']\n"," [' ' ' ' ' ' ' ']]\n","Game won! Reward: 10\n"]},{"data":{"text/plain":["True"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["\n","import numpy as np\n","\n","import torch\n","\n","from Gridworld import Gridworld\n","\n","import random\n","\n","from matplotlib import pylab as plt\n","\n"," \n","\n","l1= 64 # 4X4X4\n","\n","l2 = 150\n","\n","l3 = 100\n","\n","l4 = 4 #action\n","\n"," \n","\n","model = torch.nn.Sequential(\n","\n","    torch.nn.Linear(l1,l2),\n","\n","    torch.nn.ReLU(),\n","\n","    torch.nn.Linear(l2,l3),\n","\n","    torch.nn.ReLU(),\n","\n","    torch.nn.Linear(l3,l4)\n","\n",")\n","\n"," \n","\n","loss_fn = torch.nn.MSELoss()\n","\n","learning_rate = 1e-3\n","\n","optimizer  = torch.optim.Adam(model.parameters(),lr = learning_rate)\n","\n"," \n","\n","gamma = 0.9\n","\n","epsilon = 1.0\n","\n"," \n","\n","action_set = {\n","\n","    0: 'u',\n","\n","    1: 'd',\n","\n","    2: 'l',\n","\n","    3: 'r',\n","\n","}\n","\n"," \n","\n","epochs = 100\n","\n","losses = [] #A\n","\n","for i in range(epochs): #B\n","\n","    game = Gridworld(size=4, mode='static') #C\n","\n","    state_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0 #D\n","\n","    state1 = torch.from_numpy(state_).float() #E\n","\n","    status = 1 #F\n","\n","    while(status == 1): #G\n","\n","        qval = model(state1) #H\n","\n","        qval_ = qval.data.numpy()\n","\n","        if (random.random() < epsilon): #I\n","\n","            action_ = np.random.randint(0,4)\n","\n","        else:\n","\n","            action_ = np.argmax(qval_)\n","\n","        \n","\n","        action = action_set[action_] #J\n","\n","        game.makeMove(action) #K\n","\n","        state2_ = game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","\n","        state2 = torch.from_numpy(state2_).float() #L\n","\n","        reward = game.reward()\n","\n","        with torch.no_grad():\n","\n","            newQ = model(state2.reshape(1,64))\n","\n","        maxQ = torch.max(newQ) #M\n","\n","        if reward == -1: #N\n","\n","            Y = reward + (gamma * maxQ)\n","\n","        else:\n","\n","            Y = reward\n","\n","        Y = torch.Tensor([Y]).detach()\n","\n","        X = qval.squeeze()[action_] #O\n","\n","        loss = loss_fn(X, Y) #P\n","\n","        print(i, loss.item())\n","\n","       #clear_output(wait=True)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        losses.append(loss.item())\n","\n","        optimizer.step()\n","\n","        state1 = state2\n","\n","        if reward != -1: #Q\n","\n","            status = 0\n","\n","    if epsilon > 0.1: #R\n","\n","        epsilon -= (1/epochs)\n","\n"," \n","\n","def test_model(model, mode='static', display=True):\n","\n","    i = 0\n","\n","    test_game = Gridworld(mode=mode)\n","\n","    state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","\n","    state = torch.from_numpy(state_).float()\n","\n","    if display:\n","\n","        print(\"Initial State:\")\n","\n","        print(test_game.display())\n","\n","    status = 1\n","\n","    while(status == 1): #A\n","\n","        qval = model(state)\n","\n","        qval_ = qval.data.numpy()\n","\n","        action_ = np.argmax(qval_) #B\n","\n","        action = action_set[action_]\n","\n","        if display:\n","\n","            print('Move #: %s; Taking action: %s' % (i, action))\n","\n","        test_game.makeMove(action)\n","\n","        state_ = test_game.board.render_np().reshape(1,64) + np.random.rand(1,64)/10.0\n","\n","        state = torch.from_numpy(state_).float()\n","\n","        if display:\n","\n","            print(test_game.display())\n","\n","        reward = test_game.reward()\n","\n","        if reward != -1:\n","\n","            if reward > 0:\n","\n","                status = 2\n","\n","                if display:\n","\n","                    print(\"Game won! Reward: %s\" % (reward,))\n","\n","            else:\n","\n","                status = 0\n","\n","                if display:\n","\n","                    print(\"Game LOST. Reward: %s\" % (reward,))\n","\n","        i += 1\n","\n","        if (i > 15):\n","\n","            if display:\n","\n","                print(\"Game lost; too many moves.\")\n","\n","            break\n","\n","    \n","\n","    win = True if status == 2 else False\n","\n","    return win\n","\n"," \n","\n","test_model(model)"]},{"cell_type":"code","source":[""],"metadata":{"id":"2eTgG-hL-6Ta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9w3KuuW7m0r"},"source":["## # 미로 찾기 2\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydbrBn9k7oUi"},"outputs":[],"source":["from __future__ import print_function\n","import os, sys, time, datetime, json, random\n","import numpy as np\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Activation, PReLU, Conv2D, Input, Flatten\n","from tensorflow.keras.optimizers import SGD , Adam, RMSprop\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpVaa2TN8MV5"},"outputs":[],"source":["visited_mark = 0.8  # Cells visited by the rat will be painted by gray 0.8\n","rat_mark = 0.5      # The current rat cell will be painteg by gray 0.5\n","LEFT = 0\n","UP = 1\n","RIGHT = 2\n","DOWN = 3\n","\n","# Actions dictionary\n","actions_dict = {\n","    LEFT: 'left',\n","    UP: 'up',\n","    RIGHT: 'right',\n","    DOWN: 'down',\n","}\n","\n","num_actions = len(actions_dict)\n","\n","# Exploration factor\n","epsilon = 0.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"foAzFNQ18Y2Q"},"outputs":[],"source":["# maze is a 2d Numpy array of floats between 0.0 to 1.0\n","# 1.0 corresponds to a free cell, and 0.0 an occupied cell\n","# rat = (row, col) initial rat position (defaults to (0,0))\n","\n","class Qmaze(object):\n","    def __init__(self, maze, rat=(0,0)):\n","        self._maze = np.array(maze)\n","        nrows, ncols = self._maze.shape\n","        self.target = (nrows-1, ncols-1)   # target cell where the \"cheese\" is\n","        self.free_cells = [(r,c) for r in range(nrows) for c in range(ncols) if self._maze[r,c] == 1.0]\n","        self.free_cells.remove(self.target)\n","        if self._maze[self.target] == 0.0:\n","            raise Exception(\"Invalid maze: target cell cannot be blocked!\")\n","        if not rat in self.free_cells:\n","            raise Exception(\"Invalid Rat Location: must sit on a free cell\")\n","        self.reset(rat)\n","\n","    def reset(self, rat):\n","        self.rat = rat\n","        self.maze = np.copy(self._maze)\n","        nrows, ncols = self.maze.shape\n","        row, col = rat\n","        self.maze[row, col] = rat_mark\n","        self.state = (row, col, 'start')\n","        self.min_reward = -0.5 * self.maze.size\n","        self.total_reward = 0\n","        self.visited = set()\n","\n","    def update_state(self, action):\n","        nrows, ncols = self.maze.shape\n","        nrow, ncol, nmode = rat_row, rat_col, mode = self.state\n","\n","        if self.maze[rat_row, rat_col] > 0.0:\n","            self.visited.add((rat_row, rat_col))  # mark visited cell\n","\n","        valid_actions = self.valid_actions()\n","                \n","        if not valid_actions:\n","            nmode = 'blocked'\n","        elif action in valid_actions:\n","            nmode = 'valid'\n","            if action == LEFT:\n","                ncol -= 1\n","            elif action == UP:\n","                nrow -= 1\n","            if action == RIGHT:\n","                ncol += 1\n","            elif action == DOWN:\n","                nrow += 1\n","        else:                  # invalid action, no change in rat position\n","            mode = 'invalid'\n","\n","        # new state\n","        self.state = (nrow, ncol, nmode)\n","\n","    def get_reward(self):\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 1.0\n","        if mode == 'blocked':\n","            return self.min_reward - 1\n","        if (rat_row, rat_col) in self.visited:\n","            return -0.25\n","        if mode == 'invalid':\n","            return -0.75\n","        if mode == 'valid':\n","            return -0.04\n","\n","    def act(self, action):\n","        self.update_state(action)\n","        reward = self.get_reward()\n","        self.total_reward += reward\n","        status = self.game_status()\n","        envstate = self.observe()\n","        return envstate, reward, status\n","\n","    def observe(self):\n","        canvas = self.draw_env()\n","        envstate = canvas.reshape((1, -1))\n","        return envstate\n","\n","    def draw_env(self):\n","        canvas = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        # clear all visual marks\n","        for r in range(nrows):\n","            for c in range(ncols):\n","                if canvas[r,c] > 0.0:\n","                    canvas[r,c] = 1.0\n","        # draw the rat\n","        row, col, valid = self.state\n","        canvas[row, col] = rat_mark\n","        return canvas\n","\n","    def game_status(self):\n","        if self.total_reward < self.min_reward:\n","            return 'lose'\n","        rat_row, rat_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if rat_row == nrows-1 and rat_col == ncols-1:\n","            return 'win'\n","\n","        return 'not_over'\n","\n","    def valid_actions(self, cell=None):\n","        if cell is None:\n","            row, col, mode = self.state\n","        else:\n","            row, col = cell\n","        actions = [0, 1, 2, 3]\n","        nrows, ncols = self.maze.shape\n","        if row == 0:\n","            actions.remove(1)\n","        elif row == nrows-1:\n","            actions.remove(3)\n","\n","        if col == 0:\n","            actions.remove(0)\n","        elif col == ncols-1:\n","            actions.remove(2)\n","\n","        if row>0 and self.maze[row-1,col] == 0.0:\n","            actions.remove(1)\n","        if row<nrows-1 and self.maze[row+1,col] == 0.0:\n","            actions.remove(3)\n","\n","        if col>0 and self.maze[row,col-1] == 0.0:\n","            actions.remove(0)\n","        if col<ncols-1 and self.maze[row,col+1] == 0.0:\n","            actions.remove(2)\n","\n","        return actions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xw-5hADHA4zn"},"outputs":[],"source":["def show(qmaze):\n","    plt.grid('on')\n","    nrows, ncols = qmaze.maze.shape\n","    ax = plt.gca()\n","    ax.set_xticks(np.arange(0.5, nrows, 1))\n","    ax.set_yticks(np.arange(0.5, ncols, 1))\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    canvas = np.copy(qmaze.maze)\n","    for row,col in qmaze.visited:\n","        canvas[row,col] = 0.6\n","    rat_row, rat_col, _ = qmaze.state\n","    canvas[rat_row, rat_col] = 0.3   # rat cell\n","    canvas[nrows-1, ncols-1] = 0.9 # cheese cell\n","    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cq0HeZVhA8Ay"},"outputs":[],"source":["maze = [\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","]\n","maze = np.array(maze)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1654068617824,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"RUKN6bZGA_yy","outputId":"66f60b2d-4618-45fa-a5dd-d27877a8baa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["reward= -0.04\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f541ab5f410>"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["qmaze = Qmaze(maze)\n","canvas, reward, game_over = qmaze.act(DOWN)\n","\n","print(\"reward=\", reward)\n","show(qmaze)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8X9tA4F5CT_O"},"outputs":[],"source":["def play_game(model, qmaze, rat_cell):\n","    qmaze.reset(rat_cell)\n","    envstate = qmaze.observe()\n","    while True:\n","        prev_envstate = envstate\n","        # get next action\n","        q = model.predict(prev_envstate)\n","        action = np.argmax(q[0])\n","        # action_word = {0: 'left', 1: 'up', 2: 'right', 3: 'down'}\n","        # print(action_word[action])\n","\n","        # apply action, get rewards and new state\n","        envstate, reward, game_status = qmaze.act(action)\n","        if game_status == 'win':\n","            return True\n","        elif game_status == 'lose':\n","            return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4FY6fuRYDhBG"},"outputs":[],"source":["def completion_check(model, qmaze):\n","    for cell in qmaze.free_cells:\n","        if not qmaze.valid_actions(cell):\n","            return False\n","        if not play_game(model, qmaze, cell):\n","            return False\n","    return True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p7iXYLFiDi1B"},"outputs":[],"source":["class Experience(object):\n","    def __init__(self, model, max_memory=100, discount=0.95):\n","        self.model = model\n","        self.max_memory = max_memory\n","        self.discount = discount\n","        self.memory = list()\n","        self.num_actions = model.output_shape[-1]\n","\n","    def remember(self, episode):\n","        # episode = [envstate, action, reward, envstate_next, game_over]\n","        # memory[i] = episode\n","        # envstate == flattened 1d maze cells info, including rat cell (see method: observe)\n","        self.memory.append(episode)\n","        if len(self.memory) > self.max_memory:\n","            del self.memory[0]\n","\n","    def predict(self, envstate):\n","        return self.model.predict(envstate)[0]\n","\n","    def get_data(self, data_size=10):\n","        env_size = self.memory[0][0].shape[1]   # envstate 1d size (1st element of episode)\n","        mem_size = len(self.memory)\n","        data_size = min(mem_size, data_size)\n","        inputs = np.zeros((data_size, env_size))\n","        targets = np.zeros((data_size, self.num_actions))\n","        for i, j in enumerate(np.random.choice(range(mem_size), data_size, replace=False)):\n","            envstate, action, reward, envstate_next, game_over = self.memory[j]\n","            inputs[i] = envstate\n","            # There should be no target values for actions not taken.\n","            targets[i] = self.predict(envstate)\n","            # Q_sa = derived policy = max quality env/action = max_a' Q(s', a')\n","            Q_sa = np.max(self.predict(envstate_next))\n","            if game_over:\n","                targets[i, action] = reward\n","            else:\n","                # reward + gamma * max_a' Q(s', a')\n","                targets[i, action] = reward + self.discount * Q_sa\n","        return inputs, targets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WroQDCLDk7i"},"outputs":[],"source":["def qtrain(model, maze, **kwargs):\n","    global epsilon\n","    n_epoch = kwargs.get('epochs', 1000)\n","    max_memory = kwargs.get('max_memory', 1000)\n","    data_size = kwargs.get('data_size', 50)\n","    weights_file = kwargs.get('weights_file', \"\")\n","    name = kwargs.get('name', 'model')\n","    start_time = datetime.datetime.now()\n","\n","    # If you want to continue training from a previous model,\n","    # just supply the h5 file name to weights_file option\n","    if weights_file:\n","        print(\"loading weights from file: %s\" % (weights_file,))\n","        model.load_weights(weights_file)\n","\n","    # Construct environment/game from numpy array: maze (see above)\n","    qmaze = Qmaze(maze)\n","\n","    # Initialize experience replay object\n","    experience = Experience(model, max_memory=max_memory)\n","\n","    win_history = []   # history of win/lose game\n","    n_free_cells = len(qmaze.free_cells)\n","    hsize = qmaze.maze.size//2   # history window size\n","    win_rate = 0.0\n","    imctr = 1\n","\n","    for epoch in range(0, n_epoch):\n","        loss = 0.0\n","        rat_cell = random.choice(qmaze.free_cells)\n","        qmaze.reset(rat_cell)\n","        game_over = False\n","\n","        # get initial envstate (1d flattened canvas)\n","        envstate = qmaze.observe()\n","\n","        n_episodes = 0\n","        while not game_over:\n","            valid_actions = qmaze.valid_actions()\n","            if not valid_actions: break\n","            prev_envstate = envstate\n","            # Get next action\n","            if np.random.rand() < epsilon:\n","                action = random.choice(valid_actions)\n","            else:\n","                action = np.argmax(experience.predict(prev_envstate))\n","\n","            # Apply action, get reward and new envstate\n","            envstate, reward, game_status = qmaze.act(action)\n","            if game_status == 'win':\n","                win_history.append(1)\n","                game_over = True\n","            elif game_status == 'lose':\n","                win_history.append(0)\n","                game_over = True\n","            else:\n","                game_over = False\n","\n","            # Store episode (experience)\n","            episode = [prev_envstate, action, reward, envstate, game_over]\n","            experience.remember(episode)\n","            n_episodes += 1\n","\n","            # Train neural network model\n","            inputs, targets = experience.get_data(data_size=data_size)\n","            h = model.fit(\n","                inputs,\n","                targets,\n","                epochs=4,\n","                # epochs=8, #기본\n","                batch_size=16, #기본\n","                # batch_size = 1024,\n","                verbose=0,\n","            )\n","            loss = model.evaluate(inputs, targets, verbose=0)\n","\n","        if len(win_history) > hsize:\n","            win_rate = sum(win_history[-hsize:]) / hsize\n","    \n","        dt = datetime.datetime.now() - start_time\n","        t = format_time(dt.total_seconds())\n","        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | time: {}\"\n","        print(template.format(epoch+1, n_epoch, loss, n_episodes, sum(win_history), win_rate, t))\n","        # we simply check if training has exhausted all free cells and if in all\n","        # cases the agent won\n","        if win_rate > 0.9 : epsilon = 0.05\n","        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n","            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n","            break\n","\n","    # Save trained model weights and architecture, this will be used by the visualization code\n","    h5file = name + \".h5\"\n","    json_file = name + \".json\"\n","    model.save_weights(h5file, overwrite=True)\n","    with open(json_file, \"w\") as outfile:\n","        json.dump(model.to_json(), outfile)\n","    end_time = datetime.datetime.now()\n","    dt = datetime.datetime.now() - start_time\n","    seconds = dt.total_seconds()\n","    t = format_time(seconds)\n","    print('files: %s, %s' % (h5file, json_file))\n","    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" % (epoch, max_memory, data_size, t))\n","    return seconds\n","\n","# This is a small utility for printing readable time strings:\n","def format_time(seconds):\n","    if seconds < 400:\n","        s = float(seconds)\n","        return \"%.1f seconds\" % (s,)\n","    elif seconds < 4000:\n","        m = seconds / 60.0\n","        return \"%.2f minutes\" % (m,)\n","    else:\n","        h = seconds / 3600.0\n","        return \"%.2f hours\" % (h,)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3szW77VDlRX"},"outputs":[],"source":["def build_model(maze, lr=0.001):\n","    model = Sequential()\n","    model.add(Dense(maze.size, input_shape=(maze.size,)))\n","    model.add(PReLU())\n","    model.add(Dense(maze.size))\n","    model.add(PReLU())\n","    model.add(Dense(num_actions))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlgKEJqzGg5D"},"outputs":[],"source":["# def dqn_model(maze, lr = 0.001):\n","#     inputs = Input(shape=(maze.shape[0], maze.shape[1],1))\n","#     layer1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding='same')(inputs)\n","#     layer2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer1)\n","#     layer3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer2)\n","#     layer4 = Flatten()(layer3)\n","#     predictions = Dense(num_actions, activation = PReLU())(layer4)\n","#     model = Model(inputs=inputs, outputs=predictions)\n","#     model.compile(optimizer='sgd',\n","#                   loss='mse',\n","#                   )\n","#     return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KQGbikNOTwd"},"outputs":[],"source":["maze =  np.array([\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  0.,  1.,  0.],\n","    [ 0.,  0.,  0.,  1.,  1.,  1.,  0.],\n","    [ 1.,  1.,  1.,  1.,  0.,  0.,  1.],\n","    [ 1.,  0.,  0.,  0.,  1.,  1.,  1.],\n","    [ 1.,  0.,  1.,  1.,  1.,  1.,  1.],\n","    [ 1.,  1.,  1.,  0.,  1.,  1.,  1.]\n","])\n","qmaze = Qmaze(maze)\n","# show(qmaze)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1653924401866,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"PDDf-_NyhDEH","outputId":"b6fc7901-fd02-47c3-9fcb-46774ccb0ce7"},"outputs":[{"data":{"text/plain":["array([[1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 1., 1., 1.]])"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["maze_ = np.where(maze==0, 1, maze)\n","maze_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1654068669553,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"taTFggWESafg","outputId":"3419f741-b53b-4814-932b-3ca13c597f8f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f541a58aad0>"]},"metadata":{},"execution_count":17},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["qmaze = Qmaze(maze)\n","# plt.figure(figsize = (20, 10))\n","show(qmaze)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FoP5cMbtDmdL"},"outputs":[],"source":["model = build_model(maze)\n","# qtrain(model, maze_, epochs=1000, max_memory = 1*maze.size, data_size = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-UtcjrdTXzW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654068696207,"user_tz":-540,"elapsed":5426,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}},"outputId":"b1e1bc19-f1ac-4685-b724-8450db530a58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":20}],"source":["play_game(model, qmaze, (0, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xp-fJKiPUU6c"},"outputs":[],"source":["show(qmaze)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBgA4ezLUqaa"},"outputs":[],"source":["qmaze.visited"]},{"cell_type":"code","source":[""],"metadata":{"id":"-u5C24IH-uOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IKYYHBmzj5x_"},"source":["## # 미로 찾기 3 (사용 불가)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mTEl2lXJj7NJ"},"outputs":[],"source":["'''\n","Maze Generation and Solving\n","Here we will generate and solve mazes. Mazes are generated as png images\n","using the Python Imaging Library (PIL), and similarly solved by reading in\n","a png image, and outputing a new one with the solution marked out in green.\n","*Note*************************************************************************\n","All coordinates of our maze are initialized as \"0\" to signify \"Black\". As\n","a new coordinate enters the positions stack, it will be come \"1\" to signify\n","\"White\".\n","******************************************************************************\n","*METHOD***********************************************************************\n","Visualization:\n","    https://en.wikipedia.org/wiki/File:Depth-First_Search_Animation.ogv\n","The approach taken in this lab is to use a \"Depth First Search\" approach at\n","maze generation and solving. This method starts with a \"stack\", let's call\n","this stack \"positions\". It will be initialized at some coordinate to signify\n","the start of the maze. As such, we may begin at:\n","    positions = [\n","        (0, 0)\n","    ]\n","We then will look for a valid position to take, and randomly select it.  Two\n","possibilities now exist:\n","    1. We take a random step.\n","    2. No valid options exist.\n","If (1), then we simply append the new coordinate to the positions stack,\n","adjust variables accordingly, and continue. If (2), then we \"pop\" the last\n","position out of the stack, and continue from where we previously were (seeking\n","out a new step to take). Note, this backtracking is represented in the\n","wikipedia example as the maze changing to blue.\n","Once the entire space of possible choices has been explored, it should be\n","evident that the backtracking will continue until the positions stack is\n","empty. It is at this point that the maze generation should end.\n","When solving, the same approach can be taken. Care needs to be made in\n","regards to assessing if a step is \"valid\" or not. Further, a new end criteria\n","needs making.\n","******************************************************************************\n","'''\n","\n","class generate():\n","    import random\n","    from PIL import Image\n","    import os\n","\n","\n","    def get_colors():\n","        '''\n","        Colors map that the maze will use:\n","            0 - Black - A wall\n","            1 - White - A space to travel in the maze\n","            2 - Green - A valid solution of the maze\n","            3 - Red - A backtracked position during maze solving\n","            4 - Blue - Start and Endpoints of the maze\n","        **Returns**\n","            color_map: *dict, int, tuple*\n","                A dictionary that will correlate the integer key to\n","                a color.\n","        '''\n","        return {\n","            0: (0, 0, 0),\n","            1: (255, 255, 255),\n","            2: (0, 255, 0),\n","            3: (255, 0, 0),\n","            4: (0, 0, 255),\n","        }\n","\n","\n","    def save_maze(maze, blockSize, name, directory=os.getcwd()):\n","        '''\n","        This will save a maze object to a file.\n","        **Parameters**\n","            maze: *list, list, int*\n","                A list of lists, holding integers specifying the different aspects\n","                of the maze:\n","                    0 - Black - A wall\n","                    1 - White - A space to travel in the maze\n","                    2 - Green - A valid solution of the maze\n","                    3 - Red - A backtracked position during maze solving\n","                    4 - Blue - Start and Endpoints of the maze\n","            blockSize: *int, optional*\n","                How many pixels each block is comprised of.\n","            name: *str, optional*\n","                The name of the maze.png file to save.\n","            directory: *string*\n","                The location where the output file will be saved.\n","        **Returns**\n","            None\n","        '''\n","        nBlocks = len(maze)\n","        dims = nBlocks * blockSize\n","        colors = get_colors()\n","        # Verify that all values in the maze are valid colors.\n","        ERR_MSG = \"Error, invalid maze value found!\"\n","        assert all([x in colors.keys() for row in maze for x in row]), ERR_MSG\n","        img = Image.new(\"RGB\", (dims, dims), color=0)\n","        # Parse \"maze\" into pixels\n","        for jx in range(nBlocks):\n","            for jy in range(nBlocks):\n","                x = jx * blockSize\n","                y = jy * blockSize\n","                for i in range(blockSize):\n","                    for j in range(blockSize):\n","                        img.putpixel((x + i, y + j), colors[maze[jx][jy]])\n","        if not name.endswith(\".png\"):\n","            name += \".png\"\n","        # Create directory if it doesn't exist\n","        if not os.path.exists(directory):\n","            os.mkdir(directory)\n","        # Save the image in the proper directory\n","        output_string = directory + \"/\" + name\n","        img.save(output_string)\n","\n","\n","    def load_maze(filename, blockSize=10, directory=os.getcwd()):\n","        '''\n","        This will read a maze from a png file into a 2d list with values\n","        corresponding to the known color dictionary.\n","        **Parameters**\n","            filename: *str*\n","                The name of the maze.png file to load.\n","            blockSize: *int, optional*\n","                How many pixels each block is comprised of.\n","            directory: *string*\n","                The location where the output file will be saved.\n","        **Returns**\n","            maze: *list, list, int*\n","                A 2D array holding integers specifying each block's color.\n","        '''\n","        if \".png\" in filename:\n","            filename = filename.split(\".png\")[0]\n","        img = Image.open(directory + \"/\" + filename + \".png\")\n","        dims, _ = img.size\n","        nBlocks = int(dims / blockSize)\n","        colors = get_colors()\n","        color_map = {v: k for k, v in colors.items()}\n","        maze = [[0 for x in range(nBlocks)] for y in range(nBlocks)]\n","        for i, x in enumerate(range(0, dims, dims // nBlocks)):\n","            for j, y in enumerate(range(0, dims, dims // nBlocks)):\n","                px = x\n","                py = y\n","                maze[i][j] = color_map[img.getpixel((px, py))]\n","        return maze\n","\n","\n","    def pos_chk(x, y, nBlocks):\n","        '''\n","        Validate if the coordinates specified (x and y) are within the maze.\n","        **Parameters**\n","            x: *int*\n","                An x coordinate to check if it resides within the maze.\n","            y: *int*\n","                A y coordinate to check if it resides within the maze.\n","            nBlocks: *int*\n","                How many blocks wide the maze is.  Should be equivalent to\n","                the length of the maze (ie. len(maze)).\n","        **Returns**\n","            valid: *bool*\n","                Whether the coordiantes are valid (True) or not (False).\n","        '''\n","        return x >= 0 and x < nBlocks and y >= 0 and y < nBlocks\n","\n","\n","    def generate_maze(nBlocks, name, start, blockSize, slow,\n","                    directory=os.getcwd()):\n","        '''\n","        Generate a maze using the Depth First Search method.\n","        **Parameters**\n","            nBlocks: *int*\n","                The number of blocks in the maze (x and y dims are the same).\n","            name: *str, optional*\n","                The name of the output maze.png file.\n","            start: *tuple, int, optional*\n","                Where the maze will start from, and the initial direction.\n","            blockSize: *int, optional*\n","                How many pixels each block will be.\n","            slow: *bool, optional*\n","                Whether to save and lag on generation so as to view the mazegen.\n","            directory: *string*\n","                The location where the output file will be saved.\n","        **Returns**\n","            None\n","        '''\n","        # Initialize maze as an array of black cells\n","        maze = [[0 for i in range(nBlocks)] for j in range(nBlocks)]\n","        # Initialize stack of positions and directions\n","        positions = [start]\n","        list_of_directions = [0]\n","        # Define the four directions in which we can move\n","        directions = [(0, 1), (0, -1), (-1, 0), (1, 0)]\n","        # Define the starting cell of the maze as white\n","        maze[start[0]][start[1]] = 1\n","        # Generate the maze\n","        while len(positions) > 0:\n","            # Retrieve the end values of the stacks\n","            current_x, current_y = positions[-1]\n","            current_d = list_of_directions[-1]\n","            # Prevent zigzags when generating the map\n","            if len(list_of_directions) > 2 and current_d != list_of_directions[-2]:\n","                d_range = [current_d]\n","            else:\n","                d_range = range(len(directions))\n","            # Initialize empty list for neighboring cells\n","            neighbors = []\n","            # Check neighboring cells for possible paths to take\n","            for i in d_range:\n","                # Define coordinates for next step\n","                next_x = current_x + directions[i][0]\n","                next_y = current_y + directions[i][1]\n","                # Check if specified coordinates are in the maze and if they\n","                # represent a wall\n","                if pos_chk(next_x, next_y, nBlocks) and maze[next_x][next_y] == 0:\n","                    # At this point, the number of occupied neighbors must be 1\n","                    count = 0\n","                    # Check if neighboring cells have adjacent paths and determine\n","                    # the possible paths to take\n","                    for j in range(len(directions)):\n","                        px = next_x + directions[j][0]\n","                        py = next_y + directions[j][1]\n","                        if pos_chk(px, py, nBlocks) and maze[px][py] == 1:\n","                            count += 1\n","                    if count == 1:\n","                        neighbors.append(i)\n","            # If 1 or more neighbors are available, then randomly select one and\n","            # move to it\n","            if len(neighbors) > 0:\n","                current_d = neighbors[random.randint(0, len(neighbors) - 1)]\n","                current_x += directions[current_d][0]\n","                current_y += directions[current_d][1]\n","                maze[current_x][current_y] = 1\n","                positions.append((current_x, current_y))\n","                list_of_directions.append(current_d)\n","            else:\n","                # If there are no possible neighboring cells to move to, remove\n","                # the current position from the stack\n","                positions.pop()\n","                list_of_directions.pop()\n","            if slow:\n","                save_maze(maze, blockSize=blockSize, name=name,\n","                        directory=directory)\n","        # Save the generated maze and set start/end points\n","        maze[0][0] = 1\n","        maze[nBlocks - 1][nBlocks - 1] = 1\n","        save_maze(maze, blockSize=blockSize, name=name, directory=directory)\n","\n","\n","    def solve_maze(filename, start, end, blockSize, slow, directory=os.getcwd()):\n","        '''\n","        Solve a maze using the Depth First Search method.\n","        **Parameters**\n","            filename: *str*\n","                The name of the maze.png file to be solved.\n","            start: *tuple, int, optional*\n","                Where the maze will start from.\n","            end: *tuple, int, optional*\n","                Where the maze will end.\n","            blockSize: *int, optional*\n","                How many pixels each block will be.\n","            slow: *bool, optional*\n","                Whether to save and lag on generation so as to view the mazegen.\n","            directory: *string*\n","                The location where the output file will be saved.\n","        **Returns**\n","            None\n","        '''\n","        # Remove file extension\n","        if \".png\" in filename:\n","            filename = filename.split(\".png\")[0]\n","        # Load the maze\n","        maze = load_maze(filename, blockSize=blockSize, directory=directory)\n","        nBlocks = len(maze)\n","        # Initialize stack of positions\n","        positions = [start]\n","        # Define the four directions in which we can move\n","        directions = [(0, 1), (0, -1), (-1, 0), (1, 0)]\n","        # Ensure that the start and end points are colored appropriately. If end\n","        # is not valid, this solver will fail!\n","        maze[start[0]][start[1]] = 4\n","        maze[end[0]][end[1]] = 4\n","        # Solve the maze\n","        while len(positions) > 0:\n","            # Retrieve the end values of the stack\n","            current_x, current_y = positions[-1]\n","            # Initialize empty list for neighboring cells\n","            neighbors = []\n","            # Determine which neighboring cells are possible to move to\n","            for i in range(len(directions)):\n","                # Define coordinates for next step\n","                next_x = current_x + directions[i][0]\n","                next_y = current_y + directions[i][1]\n","                # Check if specified coordinates are in the maze and if they\n","                # represent an available path to take\n","                if pos_chk(next_x, next_y, nBlocks) and (next_x, next_y) != start:\n","                    if maze[next_x][next_y] == 1 or maze[next_x][next_y] == 4:\n","                        neighbors.append(i)\n","            # If 1 or more neighbors are available, then randomly select one and\n","            # move to it\n","            if len(neighbors) > 0:\n","                current_d = neighbors[random.randint(0, len(neighbors) - 1)]\n","                current_x += directions[current_d][0]\n","                current_y += directions[current_d][1]\n","                # If we have reached the end of the maze, break out of the while\n","                # loop\n","                if (current_x, current_y) == end:\n","                    break\n","                # Set path to be green\n","                maze[current_x][current_y] = 2\n","                positions.append((current_x, current_y))\n","            else:\n","                # If there are no possible neighboring cells to move to, remove\n","                # the current position from the stack and backtrack\n","                maze[current_x][current_y] = 3\n","                positions.pop()\n","            if slow:\n","                save_maze(maze, blockSize=blockSize,\n","                        name=\"%s_solved.png\" % filename, directory=directory)\n","        # Check if a solution has been found\n","        if not any([m == 2 for row in maze for m in row]):\n","            print(\"NO VALID SOLUTION FOR THE CHOSEN ENDPOINT!\")\n","        # Save the solved maze\n","        save_maze(maze, blockSize=blockSize, name=\"%ss.png\" % filename,\n","                directory=directory)\n","\n","\n","    if __name__ == \"__main__\":\n","        generate_maze(10, name=\"maze\", start=(0, 0), blockSize=10, slow=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":348},"executionInfo":{"elapsed":737228,"status":"ok","timestamp":1653641067160,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"4VCStCTlj-co","outputId":"860726e9-6b46-41d9-c6b3-53f7b2a4df4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["loading weights from file: model.h5\n","Epoch: 000/1 | Loss: 0.2082 | Episodes: 1 | Win count: 1 | Win rate: 0.000 | Time: 0.8 seconds\n","Epoch: 001/1 | Loss: 0.0018 | Episodes: 211 | Win count: 1 | Win rate: 0.000 | Time: 12.14 minutes\n","files: model.h5, model.json\n","n_epoch: 1, max_mem: 1000, data: 50, time: 12.14 minutes\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["'''\n","Train a neural network to solve a maze\n","Code and explanations adapted from https://samyzaf.com/ML/rl/qmaze.html\n","Introduction\n","------------------------------------------------------------------------------\n","This code uses deep reinforcement learning to solve a maze. Reinforcement\n","learning is a machine learning technique for solving problems by a feedback\n","system (rewards and penalties) applied on an agent which operates in an\n","environment and needs to move through a series of states in order to reach a\n","pre-defined final state. For example, an agent is trying to find the shortest\n","route from a starting cell to a target cell in a maze (environment). The agent\n","is experimenting and exploiting past experiences (episodes) in order to\n","achieve its goal. It may fail again and again, but hopefully, after lots of\n","trial and error (rewards and penalties) it will arrive to the solution of the\n","problem.\n","The solution will be reached if the agent finds the optimal sequence of states\n","in which the accumulated sum of rewards is maximal (in short, we lure the\n","agent to accumulate a maximal reward, and while doing so, it actually solves\n","our problem). Note that it may happen that in order to reach the goal, the\n","agent will have to endure many penalties (negative rewards) on its way. For\n","example, the agent in a maze gets a small penalty for every legal move. The\n","reason for that is that we want it to get to the target cell in the shortest\n","possible path. However, the shortest path to the target cell is sometimes long\n","and winding, and our agent may have to endure many penalties until it gets to\n","the target (sometimes called \"delayed reward\").\n","For this code, the target cell will always be the bottom-right corner of the\n","maze. The deep learning libraries used involve keras and TensorFlow. Matplotlb\n","is used to generate images.\n","Rewarding Scheme\n","------------------------------------------------------------------------------\n","Our rewards will be floats ranging from -1.0 to 1.0.\n","Each move from one state to the next state will be rewarded (the agent gets\n","points) by a positive or a negative (penalty) amount.\n","Each move from one cell to an adjacent cell will cost the agent -0.04 points.\n","This should discourage the agent from wandering around and get to the target\n","in the shortest route possible.\n","The maximal reward of 1.0 points is given when the agent reaches the target.\n","An attempt to enter a blocked cell will cost the agent -0.75 points! This is a\n","severe penalty, so hopefully the agent will learn to avoid it completely. Note\n","that an attempt to move to a blocked cell is invalid and will not be executed,\n","but it will incur a -0.75 penalty if attempted.\n","The same rule holds for an attempt to move outside the maze boundaries, with a\n","slightly higher penalty of -0.8 points.\n","The agent will be penalized by -0.25 points for any move to a cell which has\n","already been visited.\n","To avoid infinite loops and senseless wandering, the game is ended once the\n","total reward of the agent is below a negative threshold.\n","Q-learning\n","------------------------------------------------------------------------------\n","The main objective of Q-learning is to develop a policy for navigating the\n","maze successfully. Presumably, after playing hundreds of games, the agent\n","should attain a clear deterministic policy for how to act in every possible\n","situation.\n","The policy is a function that takes a maze snapshot (envstate) as input and\n","returns the action to be taken by the agent. The input consists of the full\n","maze state and the location of the agent.\n","At the start, we simply choose a completely random policy. Then we use it to\n","play thousands of games from which we learn how to perfect it. Surely, at the\n","early training stages, our policy will yield lots of errors and cause us to\n","lose many games, but our rewarding policy should provide feedback for it on\n","how to improve itself. The learning engine is going to be a simple\n","feed-forward neural network which takes an environment state as input and\n","yields a reward per action vector.\n","There are two types of moves in regard to Q-learning:\n","    Exploitation: these are moves that our policy dictates based on previous\n","                  experiences. The policy function is used in about 90% of the\n","                  moves before it is completed.\n","    Exploration: in about 10% of the cases, we take a completely random action\n","                 in order to acquire new experiences (and possibly meet bigger\n","                 rewards) which our strategy function may not allow us to make\n","                 due to its restrictive nature.\n","The exploration factor, epsilon, is the the frequency level of how much\n","exploration to do. It is usually set to 0.1, which roughly means that in one\n","of every 10 moves the agent takes a completely random action.\n","The policy function can be very difficult to find, especially for larger\n","environments. A common technique was to start with a different kind of\n","function, Q(s,a), called the best utility/quality function:\n","Q(s,a) = the maximum total reward we can get by choosing action a in state s\n","For maze solving, it is easy to be convinced that such function exists,\n","although we have no idea how to compute it efficiently (except for going\n","through all possible Markov chains that start at state s, which is very\n","inefficient). But it can also be proved mathematically for all similar Markov\n","systems. Our policy function will be:\n","pi(s) = argmax(Q(s,a_i))(i = 0,1,...,n-1)\n","We calculate Q(s,a_i) for all actions a_i, where i = 0,1,...,n−1 (where n is\n","the number of actions), and select the action a_i for which Q(s,a_i) is\n","maximal. We define Q(s,a) using Bellman's Equation, as shown below:\n","Q(s,a) = R(s,a) + max(Q(s',a_i))(i = 0,1,...,n-1), where s' is the transition\n","function and R is the reward function.\n","Training the Neural Network\n","------------------------------------------------------------------------------\n","The usual arrangement for training a neural network is to generate a\n","sufficiently large dataset of (e,q) pairs, where e is an environment state and\n","q = (q_0,q_1,...,q_n−1) are the correct actions (q-values). To do this, we\n","will have to simulate thousands of games and make sure that all our moves are\n","optimal (or else our q-values may not be correct). However, this approach is\n","impractical.\n","Here, we try a more practical and surprisingly elegant scheme for tackling\n","this problem. The scheme is as follows:\n","1. We will generate our training samples from using the neural network itself,\n","   by simulating hundreds or thousands of games. We will exploit the derived\n","   policy, pi, to make 90% of our game moves (the other 10% of the moves are\n","   reserved for exploration). However, we will set the target function of our\n","   neural network to be the function in the right side of Bellman's equation.\n","   Assuming that our neural network converges, it will define a function\n","   Q(s,a) which satisfies Bellman's equation, and therefore it must be the\n","   best utility function which we seek.\n","2. The training of the network, N, will be done after each game move by\n","   injecting a random selection of the most recent training samples to N.\n","   Assuming that our game skill will get better in time, we will use only a\n","   small number of the most recent training samples. We will forget old\n","   samples (which are probably bad) and will delete them from memory.\n","3. After each game move we will generate an episode and save it to a short\n","   term memory sequence. An episode is a tuple of 5 elements that we need for\n","   one training:\n","    episode = [envstate, action, reward, envstate_next, game_over]:\n","        envstate - environment state. This is a full picture of the maze cells\n","                   (the state of each cell including agent and target\n","                   location).To make it easier for our neural network, we\n","                   squash the maze to a 1-dimensional vector that fits the\n","                   network input.\n","        action - one of the four actions that the agent can move.\n","        reward - the reward received from the action.\n","        envstate_next - the new maze environment state which resulted from the\n","                        last action.\n","        game_over - a boolean value which indicates if the game is over or\n","                    not. The game is over if the agent has reached the target,\n","                    or if the agent has reached the negative reward limit\n","                    (lose).\n","After each move in the game, we form the episode and insert it into our memory\n","sequence. In case our memory sequence size grows beyond a fixed bound we\n","delete elements from its tail to keep it below this bound.\n","The weights of network N are initialized with random values, so in the\n","beginning N will produce awful results, but if our model parameters are chosen\n","properly, it should converge to a solution of the Bellman Equation, and\n","therefore later experiments are expected to be more truthful. Currently,\n","building a model that converges quickly seems to be very difficult and there is\n","still lots of room for improvement.\n","'''\n","import datetime\n","import json\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# import generate\n","# from keras.models import Sequential\n","# from keras.layers.core import Dense\n","# from keras.layers.advanced_activations import PReLU\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, PReLU\n","from tensorflow.keras.optimizers import SGD , Adam, RMSprop\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","\n","def get_actions():\n","    '''\n","    Dictionary reprenting possible actions to take in the maze.\n","    **Returns**\n","        action_map: *dict, int, str*\n","            A dictionary that will correlate the integer key to\n","            a possible action.\n","    '''\n","    # Define actions\n","    LEFT = 0\n","    UP = 1\n","    RIGHT = 2\n","    DOWN = 3\n","    # Return the dictionary of possible actions\n","    return {\n","        LEFT: 'left',\n","        UP: 'up',\n","        RIGHT: 'right',\n","        DOWN: 'down',\n","    }\n","\n","\n","class Qmaze(object):\n","    '''\n","    Class object for representing the maze in the context of Q-learning.\n","    **Parameters**\n","        maze: *list, list, floats* or *numpy array*\n","            A data structure that represents valid paths, walls, and current\n","            positions.\n","        pos: *tuple, int*\n","            The current position of the pointer.\n","    '''\n","\n","    def __init__(self, maze, pos=(0, 0)):\n","        # Save maze as a NumPy array if it is not already a NumPy array\n","        self.maze = np.array(maze)\n","        # Define the target position\n","        nrows, ncols = self.maze.shape\n","        self.target = (nrows - 1, ncols - 1)\n","        # Define valid paths\n","        self.paths = [(r, c) for r in range(nrows)\n","                      for c in range(ncols) if self.maze[r, c] == 1.0]\n","        # Checks for if a maze is valid or not\n","        if self.maze[self.target] == 0.0:\n","            raise Exception(\"Invalid Maze: target cell cannot be blocked!\")\n","        if pos not in self.paths:\n","            raise Exception(\"Invalid Location\")\n","        # Remove the target position from the list of valid paths\n","        self.paths.remove(self.target)\n","        # Call reset function during initialization\n","        self.reset(pos)\n","\n","    def reset(self, pos):\n","        '''\n","        Reset the pointer to a given position and update appropriate\n","        variables.\n","        '''\n","        self.pos = pos\n","        self.maze = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        row, col = pos\n","        # Set maze position\n","        self.maze[row, col] = 0.5\n","        self.state = (row, col, 'start')\n","        # Define the minimum reward and initialize total reward\n","        self.min_reward = -0.5 * self.maze.size\n","        self.total_reward = 0\n","        # Initialize set of visited spaces\n","        self.visited = set()\n","\n","    def update_state(self, action):\n","        '''\n","        Update the state of the maze given a specified action to take.\n","        '''\n","        nrows, ncols = self.maze.shape\n","        nrow, ncol, nmode = pos_row, pos_col, mode = self.state\n","        # Mark a visited space by adding it to the appropriate set\n","        if self.maze[pos_row, pos_col] > 0.0:\n","            self.visited.add((pos_row, pos_col))\n","        # Obtain list of valid actions\n","        valid_actions = self.valid_actions()\n","        # Check if there are any valid actions and adjust position accordingly\n","        if not valid_actions:\n","            nmode = 'blocked'\n","        elif action in valid_actions:\n","            nmode = 'valid'\n","            if action == 0:\n","                ncol -= 1\n","            elif action == 1:\n","                nrow -= 1\n","            if action == 2:\n","                ncol += 1\n","            elif action == 3:\n","                nrow += 1\n","        # If we reach this point, there is an invalid action and we keep the\n","        # same position\n","        else:\n","            nmode = 'invalid'\n","        # Define the new state\n","        self.state = (nrow, ncol, nmode)\n","\n","    def get_reward(self):\n","        '''\n","        Retrieve the appropriate reward value as described in the rewarding\n","        scheme above.\n","        '''\n","        # Obtain position\n","        pos_row, pos_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        # Check if we reached the target\n","        if pos_row == nrows - 1 and pos_col == ncols - 1:\n","            return 1.0\n","        # Check if our action is blocked\n","        if mode == 'blocked':\n","            return self.min_reward - 1\n","        # Check if we visited this position before\n","        if (pos_row, pos_col) in self.visited:\n","            return -0.25\n","        # Check if our action is invalid\n","        if mode == 'invalid':\n","            return -0.75\n","        # Check if our action is valid\n","        if mode == 'valid':\n","            return -0.04\n","\n","    def act(self, action):\n","        '''\n","        Given a specific action, update the state of the maze and obtain the\n","        appropriate reward value.\n","        '''\n","        # Update state\n","        self.update_state(action)\n","        # Get reward and update the total reward\n","        reward = self.get_reward()\n","        self.total_reward += reward\n","        # Obtain win or loss status\n","        status = self.game_status()\n","        # Get the current environment\n","        envstate = self.observe()\n","        return envstate, reward, status\n","\n","    def observe(self):\n","        '''\n","        Obtain the current environment of the maze.\n","        '''\n","        canvas = self.draw_env()\n","        envstate = canvas.reshape((1, -1))\n","        return envstate\n","\n","    def draw_env(self):\n","        '''\n","        Draw the maze environment.\n","        '''\n","        canvas = np.copy(self.maze)\n","        nrows, ncols = self.maze.shape\n","        # Clear all visual marks\n","        for r in range(nrows):\n","            for c in range(ncols):\n","                if canvas[r, c] > 0.0:\n","                    canvas[r, c] = 1.0\n","        # Draw the current pointer\n","        row, col, valid = self.state\n","        canvas[row, col] = 0.5\n","        return canvas\n","\n","    def game_status(self):\n","        '''\n","        Check the status of the game.\n","        '''\n","        if self.total_reward < self.min_reward:\n","            return 'lose'\n","        pos_row, pos_col, mode = self.state\n","        nrows, ncols = self.maze.shape\n","        if pos_row == nrows - 1 and pos_col == ncols - 1:\n","            return 'win'\n","        # If we reach this point, the game is still in progress\n","        return 'not_over'\n","\n","    def valid_actions(self, cell=None):\n","        '''\n","        Get a list of valid actions based on the current position and nearby\n","        environment.\n","        '''\n","        if cell is None:\n","            row, col, mode = self.state\n","        else:\n","            row, col = cell\n","        # Define the list of possible actions:\n","        #   LEFT = 0\n","        #   UP = 1\n","        #   RIGHT = 2\n","        #   DOWN = 3\n","        actions = [0, 1, 2, 3]\n","        nrows, ncols = self.maze.shape\n","        # Remove UP or DOWN\n","        if row == 0:\n","            actions.remove(1)\n","        elif row == nrows - 1:\n","            actions.remove(3)\n","        # Remove LEFT or RIGHT\n","        if col == 0:\n","            actions.remove(0)\n","        elif col == ncols - 1:\n","            actions.remove(2)\n","        # Remove UP or DOWN\n","        if row > 0 and self.maze[row - 1, col] == 0.0:\n","            actions.remove(1)\n","        if row < nrows - 1 and self.maze[row + 1, col] == 0.0:\n","            actions.remove(3)\n","        # Remove LEFT or RIGHT\n","        if col > 0 and self.maze[row, col - 1] == 0:\n","            actions.remove(0)\n","        if col < ncols - 1 and self.maze[row, col + 1] == 0.0:\n","            actions.remove(2)\n","        return actions\n","\n","\n","def show(qmaze):\n","    '''\n","    Show the current state of the qmaze object.\n","    '''\n","    plt.grid('on')\n","    nrows, ncols = qmaze.maze.shape\n","    ax = plt.gca()\n","    ax.set_xticks(np.arange(0.5, nrows, 1))\n","    ax.set_yticks(np.arange(0.5, ncols, 1))\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    canvas = np.copy(qmaze.maze)\n","    for row, col in qmaze.visited:\n","        canvas[row, col] = 0.6\n","    current_row, current_column, _ = qmaze.state\n","    canvas[current_row, current_column] = 0.3\n","    canvas[nrows - 1, ncols - 1] = 0.9\n","    img = plt.imshow(canvas, interpolation='none', cmap='gray')\n","    plt.show()\n","    return img\n","\n","\n","def play_game(model, qmaze, pos, show_maze=False):\n","    '''\n","    Play the game given a neural network, a maze, and the starting position.\n","    '''\n","    # Reset to the initial position if not there already\n","    qmaze.reset(pos)\n","    envstate = qmaze.observe()\n","    while True:\n","        prev_envstate = envstate\n","        # Get the next action\n","        q = model.predict(prev_envstate)\n","        action = np.argmax(q[0])\n","        # Apply action, get rewards and new state\n","        envstate, reward, game_status = qmaze.act(action)\n","        if game_status == 'win':\n","            if show_maze:\n","                show(qmaze)\n","            return True\n","        elif game_status == 'lose':\n","            if show_maze:\n","                show(qmaze)\n","            return False\n","\n","\n","def completion_check(model, qmaze):\n","    '''\n","    Check if the maze is completed or not.\n","    '''\n","    for cell in qmaze.paths:\n","        if not qmaze.valid_actions(cell):\n","            return False\n","        if not play_game(model, qmaze, cell):\n","            return False\n","    return True\n","\n","\n","class Experience(object):\n","    '''\n","    Class object for collecting game episodes/experiences in a list.\n","    **Parameters**\n","        model:\n","            The neural network model to be used.\n","        max_memory: *int*\n","            The maximum number of episodes to keep. When the maximum is\n","            reached, the oldest episode is to be removed.\n","        discount: *float*\n","             A special coefficient required for the Bellman equation for\n","             stochastic environments.\n","    '''\n","\n","    def __init__(self, model, max_memory=100, discount=0.95):\n","        self.model = model\n","        self.max_memory = max_memory\n","        self.discount = discount\n","        self.memory = list()\n","        self.num_actions = model.output_shape[-1]\n","\n","    def remember(self, episode):\n","        '''\n","        Add the latest episode to the memory and remove the oldest if\n","        necessary.\n","        '''\n","        self.memory.append(episode)\n","        if len(self.memory) > self.max_memory:\n","            del self.memory[0]\n","\n","    def predict(self, envstate):\n","        '''\n","        Call the predict function from the model.\n","        '''\n","        return self.model.predict(envstate)[0]\n","\n","    def get_data(self, data_size=10):\n","        '''\n","        Retrieve relevant data\n","        '''\n","        env_size = self.memory[0][0].shape[1]\n","        mem_size = len(self.memory)\n","        data_size = min(mem_size, data_size)\n","        inputs = np.zeros((data_size, env_size))\n","        targets = np.zeros((data_size, self.num_actions))\n","        for i, j in enumerate(np.random.choice(range(mem_size), data_size,\n","                                               replace=False)):\n","            envstate, action, reward, envstate_next, game_over = self.memory[j]\n","            inputs[i] = envstate\n","            # There should be no target values for actions not taken\n","            targets[i] = self.predict(envstate)\n","            Q_sa = np.max(self.predict(envstate_next))\n","            if game_over:\n","                targets[i, action] = reward\n","            else:\n","                targets[i, action] = reward + self.discount * Q_sa\n","        return inputs, targets\n","\n","\n","def qtrain(model, maze, epsilon=0.1, **opt):\n","    '''\n","    Train the neural network model needed to solve the maze.\n","    '''\n","    # Define the number of training epochs\n","    n_epoch = opt.get('n_epoch', 1000)\n","    # Define the maximum number of game experiences kept in memory\n","    max_memory = opt.get('max_memory', 1000)\n","    # Define the number of samples used in each training epoch\n","    data_size = opt.get('data_size', 50)\n","    weights_file = opt.get('weights_file', \"model.h5\")\n","    name = opt.get('name', 'model')\n","    start_time = datetime.datetime.now()\n","    # If you want to continue training from a previous model, make sure the h5\n","    # file is located in the same directory\n","    if weights_file:\n","        try:\n","            print(\"loading weights from file: %s\" % (weights_file,))\n","            model.load_weights(weights_file)\n","        except ValueError:\n","            print(\"Incompatible model - starting from new model.\")\n","            pass\n","        except OSError:\n","            print(\"Model does not exist - starting from new model.\")\n","            pass\n","    h5file = name + \".h5\"\n","    json_file = name + \".json\"\n","    # Construct environment/game from the maze\n","    qmaze = Qmaze(maze)\n","    # Initialize experience replay object\n","    experience = Experience(model, max_memory=max_memory)\n","    # Initialize the history of winning/losing games\n","    win_history = []\n","    # Define the window size of the history\n","    hsize = qmaze.maze.size // 2\n","    # Initialize win rate\n","    win_rate = 0.0\n","    for epoch in range(n_epoch):\n","        # Initialize values for the beginning of each epoch\n","        loss = 0.0\n","        pos = random.choice(qmaze.paths)\n","        qmaze.reset(pos)\n","        game_over = False\n","        # Get initial envstate\n","        envstate = qmaze.observe()\n","        n_episodes = 0\n","        # Play the game\n","        while not game_over:\n","            valid_actions = qmaze.valid_actions()\n","            if not valid_actions:\n","                break\n","            prev_envstate = envstate\n","            # Get next action\n","            if np.random.rand() < epsilon:\n","                action = random.choice(valid_actions)\n","            else:\n","                action = np.argmax(experience.predict(prev_envstate))\n","            # Apply action, get reward and new envstate\n","            envstate, reward, game_status = qmaze.act(action)\n","            if game_status == 'win':\n","                win_history.append(1)\n","                game_over = True\n","            elif game_status == 'lose':\n","                win_history.append(0)\n","                game_over = True\n","            else:\n","                game_over = False\n","            # Store the episode in memory\n","            episode = [prev_envstate, action, reward, envstate, game_over]\n","            experience.remember(episode)\n","            n_episodes += 1\n","            # Train neural network model\n","            inputs, targets = experience.get_data(data_size=data_size)\n","            model.fit(inputs, targets, epochs=8, batch_size=16, verbose=0)\n","            loss = model.evaluate(inputs, targets, verbose=0)\n","        # Save the trained model weights and architecture\n","        model.save_weights(h5file, overwrite=True)\n","        with open(json_file, \"w\") as outfile:\n","            json.dump(model.to_json(), outfile)\n","        if len(win_history) > hsize:\n","            win_rate = sum(win_history[-hsize:]) / hsize\n","        # Calculate current time\n","        dt = datetime.datetime.now() - start_time\n","        t = format_time(dt.total_seconds())\n","        # Print results to terminal\n","        template = \"Epoch: {:03d}/{:d} | Loss: {:.4f} | Episodes: {:d} | Win count: {:d} | Win rate: {:.3f} | Time: {}\"\n","        print(template.format(epoch, n_epoch - 1, loss,\n","                              n_episodes, sum(win_history), win_rate, t))\n","        # Check if training has exhausted all free cells and if in all cases\n","        # the agent won\n","        if win_rate > 0.9:\n","            epsilon = 0.05\n","        if sum(win_history[-hsize:]) == hsize and completion_check(model,\n","                                                                   qmaze):\n","            print(\"Reached 100%% win rate at epoch: %d\" % (epoch,))\n","            break\n","    # Save the trained model weights and architecture\n","    model.save_weights(h5file, overwrite=True)\n","    with open(json_file, \"w\") as outfile:\n","        json.dump(model.to_json(), outfile)\n","    # Print final results\n","    dt = datetime.datetime.now() - start_time\n","    seconds = dt.total_seconds()\n","    t = format_time(seconds)\n","    print('files: %s, %s' % (h5file, json_file))\n","    print(\"n_epoch: %d, max_mem: %d, data: %d, time: %s\" %\n","          (epoch, max_memory, data_size, t))\n","    return seconds\n","\n","\n","def format_time(seconds):\n","    '''\n","    Format the time output so that it prints nicely.\n","    '''\n","    if seconds < 400:\n","        s = float(seconds)\n","        return \"%.1f seconds\" % (s,)\n","    elif seconds < 4000:\n","        m = seconds / 60.0\n","        return \"%.2f minutes\" % (m,)\n","    else:\n","        h = seconds / 3600.0\n","        return \"%.2f hours\" % (h,)\n","\n","\n","def build_model(maze):\n","    '''\n","    Build the neural network model\n","    '''\n","    model = Sequential()\n","    model.add(Dense(maze.size, input_shape=(maze.size,)))\n","    model.add(PReLU())\n","    model.add(Dense(64))\n","    model.add(PReLU())\n","    model.add(Dense(16))\n","    model.add(PReLU())\n","    model.add(Dense(4))\n","    model.compile(optimizer='adam', loss='mse')\n","    return model\n","\n","\n","if __name__ == '__main__':\n","    # Generate the maze\n","    maze = generate.load_maze(\"maze\")\n","    maze = np.array([[float(j) for j in i] for i in maze])\n","    # Build the model\n","    model = build_model(maze)\n","    # Train the model\n","    qtrain(model, maze, epsilon=0.1, n_epoch = 2)\n","    # Test the model and show the solution\n","    play_game(model, Qmaze(maze), (0, 0), show_maze=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"elapsed":7879,"status":"ok","timestamp":1653642140789,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"qeWsNilFuTPf","outputId":"1c4478bb-fb67-425f-b2ed-b27c1378f8fd"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["False"]},"execution_count":142,"metadata":{},"output_type":"execute_result"}],"source":["play_game(model, Qmaze(maze), (0, 0), show_maze=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1653642228666,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"bvBsUm4Du7fX","outputId":"40360b2c-294e-4589-aa24-242c9c4496b8"},"outputs":[{"data":{"text/plain":["array([[1., 1., 1., 0., 1., 0., 0., 1., 0., 1.],\n","       [0., 1., 0., 0., 1., 1., 1., 1., 1., 1.],\n","       [0., 1., 1., 1., 0., 0., 0., 0., 0., 1.],\n","       [1., 0., 0., 1., 0., 1., 1., 1., 1., 1.],\n","       [1., 1., 1., 1., 0., 1., 0., 0., 1., 0.],\n","       [0., 1., 0., 0., 0., 1., 0., 0., 1., 1.],\n","       [0., 1., 1., 1., 0., 1., 1., 1., 0., 0.],\n","       [1., 0., 0., 1., 0., 1., 0., 1., 1., 1.],\n","       [1., 0., 0., 1., 0., 0., 0., 1., 0., 1.],\n","       [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.]])"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["maze = generate.load_maze(\"maze\")\n","maze\n","maze\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gKcIG1vmvt08"},"outputs":[],"source":["def play_game(model, qmaze, pos, show_maze=False):\n","    '''\n","    Play the game given a neural network, a maze, and the starting position.\n","    '''\n","    # Reset to the initial position if not there already\n","    qmaze.reset(pos)\n","    envstate = qmaze.observe()\n","    while True:\n","        prev_envstate = envstate\n","        # Get the next action\n","        q = model.predict(prev_envstate)\n","        action = np.argmax(q[0])\n","        # Apply action, get rewards and new state\n","        envstate, reward, game_status = qmaze.act(action)\n","        if game_status == 'win':\n","            if show_maze:\n","                show(qmaze)\n","            return True\n","        elif game_status == 'lose':\n","            if show_maze:\n","                show(qmaze)\n","            return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-DpCSYiwD_h"},"outputs":[],"source":["qmaze.reset((0, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1653642241835,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"brqCQnpvvDga","outputId":"4600378b-2802-401d-d098-dcc7140c2359"},"outputs":[{"data":{"text/plain":["array([[0.5, 0. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 0. , 0. , 1. ,\n","        0. , 0. , 0. , 0. , 1. , 1. , 1. , 0. , 1. , 1. , 1. , 1. , 0. ,\n","        0. , 1. , 1. , 0. , 0. , 0. , 1. , 1. , 1. , 1. , 0. , 1. , 1. ,\n","        1. , 1. , 1. , 1. , 1. , 1. , 0. , 1. , 1. , 1. ]])"]},"execution_count":156,"metadata":{},"output_type":"execute_result"}],"source":["envstate = qmaze.observe()\n","envstate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":624},"executionInfo":{"elapsed":3,"status":"error","timestamp":1653642242787,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"RNKk6dQfv3ne","outputId":"9447479c-51b5-4481-c834-0e6aae7b52f2"},"outputs":[{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-157-7ef5dc150d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_19\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 49)\n"]}],"source":["model.predict(envstate)"]},{"cell_type":"markdown","metadata":{"id":"EIZ-5bU6h5Fs"},"source":["## # 미로 찾기 4 (사용 불가)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8053,"status":"ok","timestamp":1653734490054,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"drBYHIFCiDhW","outputId":"18f9f7d1-e6ea-431a-e2f0-f184ab76bd8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gym_minigrid\n","  Downloading gym_minigrid-1.0.3-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from gym_minigrid) (1.21.6)\n","Requirement already satisfied: gym>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from gym_minigrid) (0.17.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.4.1)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.5.0)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.9.6->gym_minigrid) (1.3.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.9.6->gym_minigrid) (0.16.0)\n","Installing collected packages: gym-minigrid\n","Successfully installed gym-minigrid-1.0.3\n"]}],"source":["!pip install gym\n","!pip install gym_minigrid"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"elapsed":278,"status":"error","timestamp":1653706719098,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"2wls_nwlmfU7","outputId":"e64ff64a-27f9-4ef8-dff0-1d4410d261dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dict(image:Box(0, 255, (7, 7, 3), uint8))\n","Discrete(3)\n"]},{"ename":"FileNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4cf7487aec76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './logs/test_1'"]}],"source":["import gym\n","import gym_minigrid\n","from itertools import count\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","env = gym.make('MiniGrid-Dynamic-Obstacles-8x8-v0')#'MiniGrid-Empty-5x5-v0')\n","Fil_name='test_1'\n","PATH = './logs/'+Fil_name\n","print(env.observation_space)\n","print(env.action_space)\n","\n","\n","class DQN(nn.Module):\n","\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32,64, kernel_size=3, stride=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 64, kernel_size=2, stride=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","\n","        # Number of Linear input connections depends on output of conv2d layers\n","        # and therefore the input image size, so compute it.\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 64\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))\n","def get_state(x):\n","\t#print(x)\n","\tx.unsqueeze_(0)\n","\t\n","\tx.transpose_(1,3)\n","\t#print(x)\n","\treturn x\n","\n","\n","model = torch.load(PATH)\n","model.eval()\n","device = 'cpu'\n","def test_model(num_of_episodes,):\n","\t\n","\t\n","\tfor i in range(num_of_episodes):\n","\t\tenv.reset()\n","\n","\t\tstate_dic,_,_,_=     env.step(env.action_space.sample())#env.render()\n","\t\tstate = get_state(torch.tensor(state_dic['image'],dtype =torch.float))\n","\t\treward_this_epi = 0\n","\t\tfor t in count():\n","\t\t\tenv.render()\n","\t\t\ttime.sleep(0.1)\n","\t\t\taction = model(state).max(1)[1].view(1, 1)\n","\t\t\tobservation,reward ,done,_ =env.step(action.item())\n","\t\t\treward = torch.tensor([reward],dtype=torch.long, device=device)\n","\t\t\treward_this_epi = reward_this_epi+ reward.item()\n","\t\t\tstate =get_state(torch.tensor(observation['image'],dtype =torch.float))\n","\t\t\tif done:\n","\t\t\t\treward_this_epi =reward_this_epi/(t+1)\n","\t\t\t\tprint('Episode:',i,'Episode_Score:',reward_this_epi,'Steps_alive',t+1)\n","\t\t\t\tbreak\n","\n","\t\t\n","if __name__ == '__main__':\n","\tprint('Testing..')\n","\ttest_model(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FFfqg4mzr8ugRASkMwJSOSmH2SlO-YZA"},"executionInfo":{"elapsed":812845,"status":"error","timestamp":1653706590037,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"TbLRWzISh01E","outputId":"579e837c-b19f-41d3-e67c-bf072e6f597c"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import gym\n","import gym_minigrid\n","import math\n","import random\n","import numpy as np\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","\n","env = gym.make('MiniGrid-Dynamic-Obstacles-8x8-v0')#'MiniGrid-Empty-5x5-v0')\n","\n","print(env.observation_space)\n","print(env.action_space)\n","\n","\n","\n","Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","\n","class ReplayMemory(object):\n","\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","class DQN(nn.Module):\n","\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32,64, kernel_size=3, stride=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 64, kernel_size=2, stride=1)\n","        self.bn3 = nn.BatchNorm2d(64)\n","\n","        # Number of Linear input connections depends on output of conv2d layers\n","        # and therefore the input image size, so compute it.\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 64\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    # Called with either one element to determine next action, or a batch\n","    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))\n","\n","\n","BATCH_SIZE = 256 #128\n","GAMMA = 0.999\n","EPS_START = 1\n","EPS_END = 0.05\n","\n","EPS_DECAY = 4000 #200 for 50 epi\n","num_episodes = 500\n","TARGET_UPDATE = 30\n","#PATH ='./logs/'\n","\n","# Get screen size so that we can initialize layers correctly based on shape\n","# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n","# which is the result of a clamped and down-scaled render buffer in get_screen()\n","\n","\n","init_screen = env.reset()\n","screen_height =7 \n","screen_width = 7 \n","device = 'cpu'\n","render_status = False\n","save_model = True\n","PATH = './logs/'\n","\n","# Get number of actions from gym action space\n","n_actions = env.action_space.n\n","\n","policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.Adam(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","episode_durations = []\n","eps_of_episode = []\n","reward_hist=[]\n","steps_done = 0\n","\n","\n","def save_logs(Network , grap_plot ,Test_name , ith_sample):\n","    torch.save(Network,PATH+Test_name+ith_sample)\n","    plt.savefig(PATH+ith_sample+'.png')\n","    \n","\n","def get_state(x):\n","\t#print(x)\n","\tx.unsqueeze_(0)\n","\t\n","\tx.transpose_(1,3)\n","\t#print(x)\n","\treturn x\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","   \t\n","\n","    steps_done += 1\n","    eps_of_episode.append(eps_threshold)\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return policy_net(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","\n","\n","def plot_durations():\n","    plt.figure(2)\n","    plt.clf()\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    plt.subplot(221)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration_alive')\n","    plt.plot(durations_t.numpy())\n","    plt.subplot(222)\n","    #plt.title('Training...')\n","    plt.xlabel('Time_Steps')\n","    plt.ylabel('Epsilon')\n","    plt.plot(torch.tensor(eps_of_episode,dtype=torch.float).numpy())\n","    plt.subplot(223)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Total_reward')\n","    rew_hist_tensor = torch.tensor(reward_hist,dtype=torch.float)\n","    plt.plot(rew_hist_tensor.numpy())\n","    #plt.show()\n","\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","\n","    \tplt.subplot(221)\n","    \tmeans = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","    \tmeans = torch.cat((torch.zeros(99), means))\n","    \tplt.plot(means.numpy())\n","    \tplt.subplot(223)\n","    \tmeans = rew_hist_tensor.unfold(0, 100, 1).mean(1).view(-1)\n","    \tmeans = torch.cat((torch.zeros(99), means))\n","    \tplt.plot(means.numpy())\n","\n","\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","    # if is_ipython:\n","    #     display.clear_output(wait=True)\n","    #     display.display(plt.gcf())      \n","\n","def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.bool)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n","\n","    # Compute Huber loss\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()\n","\n","def train():\n","\t\n","\tfor i_episode in range(num_episodes):\n","\t    # Initialize the environment and state\n","\t    env.reset()\n","\t    #last_screen = env.render()\n","\n","\t    #current_screen = env.render()\n","\t    \n","\t    state_dic,_,_,_=     env.step(env.action_space.sample())#env.render()\n","\t    state = get_state(torch.tensor(state_dic['image'],dtype =torch.float))\n","\t    #print(state.size())\n","\t    #print(state)\n","\t    reward_epi = 0 \n","\t    for t in count():\n","\t        # Select and perform an action\n","\t        if render_status:\n","\t        \tenv.render()\n","\t        action = select_action(state)\n","\t        observation, reward, done, _ = env.step(action.item())\n","\t        \n","\t        reward = torch.tensor([reward],dtype=torch.long, device=device)\n","\t        \n","\n","\t        # Observe new state\n","\t        \n","\t        \n","\t        if not done:\n","\t            next_state =get_state(torch.tensor(observation['image'],dtype =torch.float)) #env.render()# current_screen - last_screen\n","\t        else:\n","\t            next_state = None\n","\n","\t        # Store the transition in memory\n","\t        memory.push(state, action, next_state, reward)\n","\n","\t        # Move to the next state\n","\t        state = next_state\n","\n","\t        # Perform one step of the optimization (on the target network)\n","\t        reward_epi = reward_epi+reward.item()\n","\t        optimize_model()\n","\n","\t        if done:\n","\t        \tif t != 0:\n","\t        \t\treward_epi = reward_epi/t\n","\t        \treward_hist.append(reward_epi)\n","\t        \tepisode_durations.append(t + 1)\n","\t        \tplot_durations()\n","\t        \tbreak\n","\t        \t\n","\t    # Update the target network, copying all weights and biases in DQN\n","\t    if i_episode % TARGET_UPDATE == 0:\n","\t        target_net.load_state_dict(policy_net.state_dict())\n","\n","\tprint('Complete')\n","\t#env.render()\n","\tenv.close()\n","\t#plt.ioff()\n","\t#plt.show()\n","\n","\n","if __name__ == '__main__':\n","\tprint(\"Training :\")\n","\ttrain()\n","\tFolder_name = 'test_(8x8)'\n","\tif save_model == True :\n","\t\tsave_logs(policy_net,plt,Folder_name,'2')\n","\n","\t\n","\t\n","\n","\n","\n","\n","\n","\n","\n","\n","# for i_episode in range(20):\n","#     observation = env.reset()\n","#     for t in range(100):\n","#         env.render()\n","#         print(observation)\n","#         action = env.action_space.sample()\n","#         observation, reward, done, info = env.step(action)\n","#         if done:\n","#             print(\"Episode finished after {} timesteps\".format(t+1))\n","#             break\n","# env.close()"]},{"cell_type":"markdown","metadata":{"id":"tYK68rKbnaSN"},"source":["## # 미로찾기 5 (사용 안함)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AQ0CXD4uncSo","outputId":"75112bff-abd3-472e-fb8a-2c9f1507bc53"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 455 ==========\n","Right -> Left -> Left -> Right -> Right -> Right -> Right -> Right -> Right -> Left -> Left -> Left -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Right -> Right -> Right -> Up -> Down -> Left -> Right -> Down -> Right -> Left -> Left -> Left -> Down -> Right -> \n","Left :  0.06488371  Down :  -0.060727447  Right :  0.031920988  Up :  0.016600499\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 456 ==========\n","Right -> Down -> Down -> Down -> Left -> Down -> Left -> Right -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 457 ==========\n","Down -> Down -> Right -> Down -> Left -> Down -> Left -> Left -> Down -> Down -> Up -> Right -> \n","Left :  -0.0076489435  Down :  -0.09644726  Right :  0.019010358  Up :  0.024659405\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 458 ==========\n","Right -> Left -> Down -> Right -> Left -> Down -> Left -> Down -> Down -> Left -> Right -> Left -> Down -> Left -> Left -> Left -> Right -> \n","Left :  -0.0076489435  Down :  -0.09644726  Right :  0.019010358  Up :  0.024659405\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 459 ==========\n","Right -> Left -> Left -> Left -> Right -> Left -> Down -> Right -> Down -> Left -> Down -> Right -> Right -> Right -> Up -> \n","Left :  0.019785672  Down :  -0.047721498  Right :  0.029112538  Up :  0.07382277\n","  (Up)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 460 ==========\n","Right -> Right -> Down -> Right -> Right -> Up -> Right -> Left -> Left -> Right -> Left -> Down -> Right -> Down -> Right -> Right -> Down -> Down -> Up -> Down -> Down -> \n","Left :  -0.054316394  Down :  -0.07873565  Right :  0.04168778  Up :  0.060062595\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 461 ==========\n","Down -> Up -> Right -> Left -> Down -> Up -> Right -> Right -> Down -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 461 중간평가 ==========\n","Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  -0.04456571  Down :  -0.059729274  Right :  -0.011630431  Up :  0.04736597\n","  (Up)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 462 ==========\n","Down -> Right -> Right -> Right -> Right -> Left -> Right -> Up -> Down -> Up -> Left -> Left -> Down -> Right -> Left -> Down -> Down -> Up -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 463 ==========\n","Left -> Right -> Left -> Right -> Down -> Left -> Down -> Right -> Right -> Down -> Left -> Right -> Left -> Down -> Right -> Left -> Right -> Down -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 464 ==========\n","Down -> Up -> Right -> Right -> Right -> Down -> Down -> \n","Left :  -0.0021235384  Down :  -0.08481735  Right :  0.11875135  Up :  0.09576628\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 465 ==========\n","Right -> Right -> Up -> Right -> Left -> Right -> Right -> Left -> Left -> Down -> Down -> Left -> Right -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 466 ==========\n","Left -> Right -> Down -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> Up -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 467 ==========\n","Right -> Right -> Down -> Down -> Left -> Right -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 468 ==========\n","Down -> Right -> Down -> Right -> Left -> Right -> Left -> Right -> Left -> Left -> Right -> Left -> Right -> Right -> Down -> Left -> Down -> Left -> Left -> Right -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 469 ==========\n","Left -> Down -> Right -> Right -> Right -> Left -> Right -> Down -> \n","Left :  -0.0021235384  Down :  -0.08481735  Right :  0.11875135  Up :  0.09576628\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 470 ==========\n","Right -> Left -> Right -> Right -> Left -> Down -> Left -> Up -> Down -> Right -> Down -> Down -> Right -> Left -> Right -> Down -> Right -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 471 ==========\n","Down -> Down -> Left -> Left -> Left -> Left -> Up -> Up -> Left -> Right -> Right -> Right -> Down -> Down -> \n","Left :  -0.0021235384  Down :  -0.08481735  Right :  0.11875135  Up :  0.09576628\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 471 중간평가 ==========\n","Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  -0.04456571  Down :  -0.059729274  Right :  -0.011630431  Up :  0.04736597\n","  (Up)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 472 ==========\n","Right -> Left -> Right -> Right -> Down -> Left -> Left -> Left -> Left -> Up -> Down -> Down -> Down -> Right -> Left -> Left -> Right -> Left -> Down -> Right -> Right -> Up -> Right -> Down -> \n","Left :  0.019785672  Down :  -0.047721498  Right :  0.029112538  Up :  0.07382277\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 473 ==========\n","Left -> Right -> Right -> Down -> Right -> Down -> \n","Left :  -0.0021235384  Down :  -0.08481735  Right :  0.11875135  Up :  0.09576628\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 474 ==========\n","Left -> Right -> Right -> Left -> Down -> Down -> Left -> Down -> Right -> Right -> Down -> Up -> Right -> Right -> Left -> Left -> Down -> Up -> Down -> Left -> Right -> Right -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 475 ==========\n","Left -> Down -> Down -> Down -> Down -> Down -> Left -> Right -> \n","Left :  -0.0076489435  Down :  -0.09644726  Right :  0.019010358  Up :  0.024659405\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 476 ==========\n","Left -> Right -> Right -> Right -> Down -> Down -> \n","Left :  -0.0021235384  Down :  -0.08481735  Right :  0.11875135  Up :  0.09576628\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 477 ==========\n","Down -> Left -> Right -> Down -> Down -> Right -> Right -> Down -> \n","Left :  0.019785672  Down :  -0.047721498  Right :  0.029112538  Up :  0.07382277\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 478 ==========\n","Left -> Left -> Left -> Left -> Down -> Right -> Right -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 479 ==========\n","Right -> Right -> Left -> Left -> Right -> Left -> Left -> Down -> Right -> Left -> Left -> Up -> Right -> Right -> Down -> Left -> Right -> Down -> Left -> Left -> Left -> Down -> Right -> Right -> Left -> Down -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 480 ==========\n","Down -> Down -> Down -> Left -> Right -> Left -> Right -> Right -> Right -> Left -> Right -> Right -> Left -> Left -> Down -> Right -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 481 ==========\n","Right -> Right -> Right -> Left -> Up -> Up -> Left -> Left -> Right -> Down -> Down -> Right -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 481 중간평가 ==========\n","Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  -0.04456571  Down :  -0.059729274  Right :  -0.011630431  Up :  0.04736597\n","  (Up)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 482 ==========\n","Down -> Up -> Right -> Left -> Left -> Left -> Right -> Right -> Right -> Left -> Left -> Right -> Left -> Down -> Down -> Left -> Down -> Right -> Right -> Right -> Right -> Left -> Left -> Down -> Down -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 483 ==========\n","Down -> Down -> Right -> Right -> Down -> Down -> Left -> Right -> Right -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 484 ==========\n","Left -> Left -> Right -> Down -> Left -> Left -> Down -> Up -> Left -> Right -> Left -> Up -> Right -> Right -> Left -> Down -> Right -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 485 ==========\n","Down -> Down -> Right -> Left -> Down -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Up -> Down -> Down -> Up -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Down -> Right -> Down -> \n","Left :  -0.0005491958  Down :  -0.07475299  Right :  0.008996383  Up :  0.020560047\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 486 ==========\n","Right -> Right -> Right -> Right -> Left -> Down -> Right -> Down -> Down -> Right -> \n","Left :  0.06488371  Down :  -0.060727447  Right :  0.031920988  Up :  0.016600499\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 487 ==========\n","Down -> Up -> Down -> Right -> Right -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> Down -> Down -> Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  -0.027828645  Down :  -0.10167733  Right :  0.032778785  Up :  0.0007971856\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 488 ==========\n","Down -> Left -> Left -> Up -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Left -> Right -> Right -> \n","Left :  0.06488371  Down :  -0.060727447  Right :  0.031920988  Up :  0.016600499\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 489 ==========\n","Right -> Left -> Down -> Left -> Down -> Down -> Right -> Left -> Down -> Right -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 490 ==========\n","Right -> Down -> Down -> Right -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 491 ==========\n","Right -> Right -> Down -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 491 중간평가 ==========\n","Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  -0.04456571  Down :  -0.059729274  Right :  -0.011630431  Up :  0.04736597\n","  (Up)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 492 ==========\n","Down -> Right -> Down -> Left -> Up -> Left -> Up -> Left -> Right -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> Left -> Right -> Right -> Left -> Down -> Down -> Right -> Left -> Down -> \n","Left :  -0.054316394  Down :  -0.07873565  Right :  0.04168778  Up :  0.060062595\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 493 ==========\n","Down -> Down -> Down -> Left -> Left -> Right -> Right -> Up -> Left -> Right -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 494 ==========\n","Down -> Down -> Down -> Right -> Right -> Right -> Left -> Left -> Left -> Left -> Down -> Right -> Left -> Down -> Right -> \n","Left :  -0.0076489435  Down :  -0.09644726  Right :  0.019010358  Up :  0.024659405\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 495 ==========\n","Right -> Down -> Left -> Right -> Left -> Right -> Down -> Down -> Left -> Down -> Right -> Left -> Right -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 496 ==========\n","Left -> Left -> Right -> Right -> Down -> Right -> Left -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 497 ==========\n","Down -> Down -> Up -> Down -> Left -> Right -> Left -> Left -> Left -> Down -> Right -> Right -> Up -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 498 ==========\n","Right -> Left -> Right -> Left -> Left -> Left -> Down -> Up -> Left -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> Down -> Right -> \n","Left :  0.06488371  Down :  -0.060727447  Right :  0.031920988  Up :  0.016600499\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 499 ==========\n","Right -> Down -> Left -> Up -> Right -> Right -> Right -> Right -> Left -> Left -> Up -> Left -> Right -> Left -> Down -> Right -> Down -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 500 ==========\n","Left -> Right -> Right -> Left -> Right -> Left -> Down -> Right -> Left -> Right -> Down -> Down -> Left -> Right -> Down -> Left -> Right -> Left -> Down -> \n","Left :  0.047427796  Down :  -0.09417593  Right :  0.04830369  Up :  0.039620116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 501 ==========\n","Down -> Left -> Down -> Left -> Down -> Right -> Right -> Down -> Up -> Up -> Right -> \n","Left :  -0.0063690413  Down :  -0.10011376  Right :  0.06094341  Up :  -0.0072516296\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 501 중간평가 ==========\n","Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  -0.04456571  Down :  -0.059729274  Right :  -0.011630431  Up :  0.04736597\n","  (Up)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 502 ==========\n","Right -> Left -> Right -> Left -> Left -> Right -> Down -> Right -> Right -> Right -> Down -> Left -> \n","Left :  0.009652592  Down :  -0.032472793  Right :  0.008744748  Up :  0.028858611\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 503 ==========\n","Down -> Down -> Left -> Right -> Right -> Down -> Left -> Left -> Down -> Left -> Down -> Down -> Left -> Right -> \n","Left :  0.10576696  Down :  0.09392036  Right :  0.089767314  Up :  0.069280684\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 504 ==========\n","Left -> Down -> Right -> Down -> Down -> Left -> Left -> Down -> Right -> Down -> \n","Left :  0.092280515  Down :  0.050430104  Right :  0.068446085  Up :  0.011575319\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 505 ==========\n","Left -> Right -> Left -> Down -> Down -> Left -> Left -> Left -> Right -> Left -> Down -> Down -> Down -> Up -> Left -> Left -> Left -> Left -> Right -> Left -> Down -> Left -> Up -> Left -> Down -> Right -> \n","Left :  0.06443458  Down :  0.05878798  Right :  0.06731443  Up :  0.07011852\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 506 ==========\n","Down -> Down -> Down -> Left -> Right -> Right -> Down -> Down -> \n","Left :  0.119034894  Down :  0.091453284  Right :  0.03567781  Up :  0.11870233\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 507 ==========\n","Left -> Down -> Down -> Left -> Right -> Left -> Up -> Down -> Left -> Left -> Right -> Right -> Left -> Down -> Right -> Up -> Down -> Left -> Left -> Left -> Left -> Left -> Down -> Down -> Right -> \n","Left :  0.18565327  Down :  0.16871205  Right :  0.12691471  Up :  0.25688696\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 508 ==========\n","Right -> Left -> Right -> Left -> Left -> Right -> Down -> Left -> Left -> Down -> Left -> Right -> Down -> Right -> Left -> Right -> Left -> Left -> Left -> Right -> Down -> Down -> \n","Left :  0.14860672  Down :  0.0035854261  Right :  0.16035466  Up :  0.07265863\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 509 ==========\n","Right -> Down -> Right -> Right -> Down -> \n","Left :  0.13216998  Down :  -0.013111202  Right :  0.14493617  Up :  0.11282092\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 510 ==========\n","Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Down -> Down -> Left -> Down -> Left -> Down -> Left -> Right -> Right -> Left -> Down -> \n","Left :  0.114198685  Down :  0.0014422834  Right :  0.12311223  Up :  0.022567222\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 511 ==========\n","Left -> Left -> Down -> Down -> Left -> Left -> Right -> Left -> Left -> Left -> Down -> Right -> Down -> Right -> Left -> Right -> Down -> \n","Left :  0.08721909  Down :  0.008145547  Right :  -0.004023239  Up :  0.1280069\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 511 중간평가 ==========\n","Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> \n","Left :  0.12093276  Down :  0.09581125  Right :  0.12348921  Up :  0.13285151\n","  (Up)\n","\u001b[41mS\u001b[0mFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 512 ==========\n","Down -> Left -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Down -> Down -> Down -> Right -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.09222901  Down :  0.002621295  Right :  0.007966166  Up :  0.11150332\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 513 ==========\n","Right -> Down -> Up -> Down -> Up -> Down -> Down -> Left -> Down -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.08772331  Down :  -0.013276717  Right :  0.014308583  Up :  0.10148384\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 514 ==========\n","Left -> Left -> Down -> Left -> Left -> Right -> Right -> Right -> Down -> \n","Left :  0.08266773  Down :  0.008096891  Right :  0.10120306  Up :  0.023760755\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 515 ==========\n","Left -> Left -> Left -> Down -> Right -> Right -> Right -> Down -> \n","Left :  0.08410701  Down :  -0.006379463  Right :  0.07530744  Up :  0.008998828\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 516 ==========\n","Left -> Down -> Down -> Down -> Right -> Up -> Down -> Left -> Down -> Down -> Down -> Down -> Right -> Down -> Up -> \n","Left :  0.030181786  Down :  0.05929663  Right :  0.07643756  Up :  0.088898435\n","  (Up)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 517 ==========\n","Left -> Right -> Left -> Right -> Right -> Left -> Down -> Left -> Right -> Left -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.058754668  Down :  0.07411468  Right :  0.004981879  Up :  0.03457682\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 518 ==========\n","Right -> Right -> Left -> Down -> Down -> Right -> Right -> \n","Left :  0.059185006  Down :  0.06758954  Right :  0.00304755  Up :  0.03135909\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 519 ==========\n","******** SUCCESS ********\n","Right -> Left -> Left -> Left -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Right -> Left -> Right -> Right -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.0718262  Down :  0.056082167  Right :  0.07058291  Up :  0.038202435\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 520 ==========\n","Right -> Right -> Down -> Right -> Down -> \n","Left :  0.0870359  Down :  -0.0050186645  Right :  0.06834241  Up :  0.0022949327\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 521 ==========\n","Left -> Down -> Left -> Down -> Right -> Down -> Left -> Right -> Down -> Down -> \n","Left :  0.057538506  Down :  0.0013562664  Right :  0.07587596  Up :  0.005253778\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 521 중간평가 ==========\n","Right -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> \n","Left :  0.0672953  Down :  0.06681115  Right :  0.0640692  Up :  0.06431088\n","  (Left)\n","SF\u001b[41mF\u001b[0mFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 522 ==========\n","Right -> Down -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.05180067  Down :  -0.008936731  Right :  -0.0038031545  Up :  0.058465675\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 523 ==========\n","Left -> Right -> Right -> Right -> Down -> Left -> Down -> Down -> Down -> Left -> Left -> Right -> Right -> Up -> Right -> Right -> Right -> \n","Left :  0.04082855  Down :  0.030167118  Right :  0.0072964597  Up :  0.0127960285\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 524 ==========\n","Down -> Down -> Down -> Left -> Left -> Left -> Right -> Down -> Left -> Right -> Right -> Left -> Left -> Down -> Down -> Right -> \n","Left :  0.043257423  Down :  0.049083784  Right :  0.0049431305  Up :  0.020353448\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 525 ==========\n","Left -> Left -> Down -> Right -> Left -> Left -> Down -> Down -> Left -> Left -> Right -> Right -> Left -> Down -> Down -> \n","Left :  0.037518933  Down :  0.008404512  Right :  0.038618207  Up :  0.0019274992\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 526 ==========\n","Left -> Left -> Left -> Left -> Down -> Left -> Down -> Left -> Down -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.048442885  Down :  -0.013154387  Right :  0.004776283  Up :  0.042940978\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 527 ==========\n","Left -> Right -> Left -> Down -> Up -> Right -> Right -> Left -> Right -> Left -> Down -> Up -> Down -> Right -> Right -> Right -> Up -> Right -> Down -> Up -> Left -> Down -> Right -> Left -> Right -> Up -> Left -> Left -> Right -> Left -> Down -> Right -> Up -> Right -> Down -> Right -> Left -> Right -> Down -> Right -> Right -> Down -> Left -> Down -> Left -> Right -> Right -> Left -> Right -> Down -> Right -> Down -> Right -> Left -> \n","Left :  0.031572096  Down :  0.029743537  Right :  0.031870134  Up :  0.011452621\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 528 ==========\n","Down -> Left -> Down -> Right -> Left -> Left -> Left -> Up -> Right -> Right -> Left -> Up -> Down -> Left -> Down -> Left -> Up -> Right -> Left -> Right -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.044944514  Down :  0.00233226  Right :  0.016556917  Up :  0.049094826\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 529 ==========\n","Left -> Down -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.13114952  Down :  0.124223866  Right :  0.021022016  Up :  0.088995665\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 530 ==========\n","Right -> Down -> Left -> Right -> Left -> Down -> Up -> Right -> Right -> Down -> Left -> Down -> Up -> Right -> Right -> \n","Left :  0.14059816  Down :  0.1328806  Right :  0.0052670576  Up :  0.0690699\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 531 ==========\n","Right -> Down -> Left -> Left -> Left -> Left -> Down -> Right -> Down -> Right -> Right -> Down -> \n","Left :  0.15612158  Down :  0.048261184  Right :  0.11959483  Up :  0.07662026\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 531 중간평가 ==========\n","Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> \n","Left :  0.18746626  Down :  0.14514266  Right :  0.17521356  Up :  0.15384601\n","  (Left)\n","\u001b[41mS\u001b[0mFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 532 ==========\n","Left -> Left -> Right -> Down -> Left -> Left -> Right -> Down -> Left -> Right -> Right -> Down -> Left -> Down -> Right -> Right -> \n","Left :  0.11061554  Down :  0.016644316  Right :  0.060726244  Up :  0.09158309\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 533 ==========\n","Up -> Right -> Left -> Down -> Right -> Down -> Left -> Right -> Down -> Down -> Left -> Up -> Left -> Down -> Down -> Left -> Left -> Left -> Left -> Down -> Left -> Down -> Right -> Up -> \n","Left :  0.091060996  Down :  0.11443547  Right :  0.108592756  Up :  0.1402174\n","  (Up)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 534 ==========\n","Down -> Right -> Right -> Right -> Down -> \n","Left :  0.08300197  Down :  -0.020213887  Right :  0.06064718  Up :  0.0764078\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 535 ==========\n","Left -> Right -> Right -> Left -> Down -> Down -> Left -> Left -> Left -> Right -> Right -> Left -> Down -> Down -> Right -> Down -> \n","Left :  0.12687257  Down :  0.06304277  Right :  0.05468292  Up :  0.10977772\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 536 ==========\n","Left -> Right -> Down -> Right -> Down -> Left -> Down -> Down -> Right -> Left -> Right -> Left -> Down -> \n","Left :  0.1138105  Down :  0.024348052  Right :  0.15728737  Up :  0.02110387\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 537 ==========\n","Left -> Right -> Down -> Left -> Down -> Right -> Down -> Left -> Down -> Right -> Right -> Down -> \n","Left :  0.13293448  Down :  -0.013735581  Right :  -0.040728383  Up :  0.09651039\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 538 ==========\n","Right -> Right -> Right -> Right -> Left -> Right -> Right -> Down -> Right -> Left -> Right -> Left -> Down -> Down -> \n","Left :  0.069565356  Down :  -0.01527385  Right :  0.090290725  Up :  0.0049981005\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 539 ==========\n","Left -> Right -> Right -> Right -> Down -> Right -> Left -> Right -> Down -> Left -> \n","Left :  0.07626112  Down :  0.07806661  Right :  0.100684114  Up :  0.10711848\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 540 ==========\n","Left -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.09197554  Down :  0.08705768  Right :  -0.003194889  Up :  0.035434254\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 541 ==========\n","Right -> Left -> Left -> Left -> Right -> Left -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Right -> Down -> Left -> \n","Left :  0.07688624  Down :  0.08593961  Right :  0.071268514  Up :  0.042911347\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 541 중간평가 ==========\n","Right -> Right -> Right -> Right -> Right -> Down -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> \n","Left :  0.0671096  Down :  0.055930376  Right :  0.061433114  Up :  0.049970407\n","  (Left)\n","SFFFFFFF\n","FFFFF\u001b[41mF\u001b[0mFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 542 ==========\n","Left -> Left -> Down -> Left -> Right -> Down -> Down -> Left -> Left -> Left -> Left -> Left -> Left -> Down -> Down -> Left -> Right -> \n","Left :  0.07206248  Down :  0.07852492  Right :  -0.0036282856  Up :  0.015552515\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 543 ==========\n","Down -> Left -> Right -> Left -> Right -> Down -> Down -> Down -> Right -> Right -> \n","Left :  0.070581496  Down :  0.0140428115  Right :  -0.0020303428  Up :  0.009884847\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 544 ==========\n","Right -> Left -> Down -> Left -> Left -> Down -> Right -> Down -> Right -> Right -> Left -> Left -> Down -> Right -> Left -> Down -> \n","Left :  0.04830432  Down :  0.0102438945  Right :  0.068317935  Up :  -0.0044241827\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 545 ==========\n","Down -> Right -> Down -> Right -> Left -> Down -> Right -> Down -> Down -> \n","Left :  0.06703957  Down :  0.005752513  Right :  -0.0025503915  Up :  0.057379626\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 546 ==========\n","Right -> Right -> Down -> Down -> Right -> \n","Left :  0.050370656  Down :  0.04313893  Right :  0.0072105173  Up :  0.015752379\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 547 ==========\n","Down -> Down -> Down -> Left -> Left -> Down -> Down -> Left -> Down -> Down -> Left -> Right -> Down -> Left -> Left -> Right -> Left -> Down -> Right -> Right -> Down -> Down -> Left -> Left -> Right -> Down -> Down -> Down -> Down -> Left -> Down -> Right -> Left -> Down -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.069602884  Down :  0.0741615  Right :  -0.015092688  Up :  0.029051412\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 548 ==========\n","Down -> Left -> Right -> Right -> Down -> Left -> Down -> Down -> Right -> Left -> Left -> Right -> Right -> Left -> Down -> \n","Left :  0.035880323  Down :  0.006814914  Right :  0.04841754  Up :  0.008410524\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 549 ==========\n","******** SUCCESS ********\n","Down -> Left -> Left -> Left -> Right -> Right -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.08149268  Down :  0.14987105  Right :  0.15752117  Up :  0.095733404\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 550 ==========\n","Left -> Right -> Right -> Up -> Up -> Left -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> Left -> Right -> Right -> Up -> Left -> Left -> Up -> Left -> Right -> Up -> Down -> Down -> Down -> Up -> Left -> Up -> Down -> Right -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.055161968  Down :  0.045787822  Right :  0.0060220584  Up :  0.02302147\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 551 ==========\n","Left -> Left -> Left -> Down -> Left -> Down -> Up -> Left -> Down -> Right -> Right -> Left -> Down -> Right -> Down -> Down -> \n","Left :  0.04586819  Down :  0.008294754  Right :  0.0013683289  Up :  0.051202305\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 551 중간평가 ==========\n","Down -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> \n","Left :  0.04870932  Down :  0.051127415  Right :  0.04864948  Up :  0.047330074\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","\u001b[41mF\u001b[0mFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 552 ==========\n","Left -> Down -> Down -> Right -> Left -> Right -> Down -> Right -> Right -> Left -> Down -> Left -> Down -> \n","Left :  0.047902465  Down :  0.012699175  Right :  0.049733773  Up :  0.010495727\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 553 ==========\n","Left -> Right -> Right -> Left -> Down -> Right -> Down -> Left -> Right -> Down -> Up -> Right -> \n","Left :  0.04880478  Down :  0.04006526  Right :  0.006009968  Up :  0.018345343\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 554 ==========\n","Down -> Down -> Left -> Right -> Down -> Right -> Left -> Right -> Left -> Up -> Down -> Right -> Up -> Left -> Left -> Left -> Left -> Up -> Right -> Left -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Left -> Right -> Left -> Down -> Left -> Down -> Down -> Right -> Down -> \n","Left :  0.04315134  Down :  -0.006233746  Right :  -0.0025610179  Up :  0.052209225\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 555 ==========\n","Right -> Down -> Right -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Left -> \n","Left :  0.05381839  Down :  0.10616249  Right :  0.11671615  Up :  0.06963456\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 556 ==========\n","Left -> Down -> Right -> Right -> Right -> Down -> \n","Left :  0.061396554  Down :  0.002396239  Right :  0.046315525  Up :  0.011097355\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 557 ==========\n","Left -> Down -> Down -> Right -> Down -> Left -> Down -> Right -> Left -> Left -> Down -> Down -> Down -> Right -> Down -> Down -> Right -> Left -> Down -> Down -> Down -> Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  0.1831886  Down :  0.22482407  Right :  0.11911143  Up :  0.095906965\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 558 ==========\n","Left -> Right -> Up -> Up -> Up -> Right -> Down -> Down -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.1445654  Down :  0.08870688  Right :  -0.026315562  Up :  0.074489966\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 559 ==========\n","Right -> Right -> Left -> Down -> Left -> Left -> Up -> Left -> Right -> Down -> Right -> Left -> Left -> Down -> Up -> Left -> Right -> Left -> Right -> Down -> Left -> Up -> Right -> Left -> Right -> Left -> Up -> Left -> Left -> Down -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.10720071  Down :  -0.03553519  Right :  0.13290846  Up :  0.089851424\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 560 ==========\n","Right -> Right -> Right -> Right -> Right -> Right -> Right -> Down -> Right -> Left -> Left -> Down -> Left -> Down -> Right -> \n","Left :  0.090301454  Down :  0.08998515  Right :  0.056099758  Up :  0.07791524\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 561 ==========\n","Down -> Right -> Left -> Up -> Left -> Right -> Left -> Left -> Right -> Left -> Right -> Right -> Right -> Up -> Left -> Left -> Down -> Right -> Left -> Left -> Up -> Right -> Up -> Right -> Left -> Down -> Down -> Right -> Left -> Down -> Left -> Down -> Down -> Down -> Down -> Down -> Left -> Right -> Down -> Left -> Left -> Right -> Down -> Down -> Right -> Left -> Left -> Right -> Down -> Down -> Right -> Left -> Left -> Left -> Right -> Down -> Down -> Down -> Down -> Down -> Left -> Left -> Left -> Right -> Left -> Left -> Down -> Down -> Left -> Left -> Left -> Left -> Left -> Right -> Down -> Down -> Left -> Left -> Left -> Down -> Left -> Down -> Left -> Right -> Down -> Right -> Down -> Left -> Right -> Down -> Left -> Down -> Down -> Down -> Left -> Down -> Right -> Right -> Down -> Left -> \n","Left :  0.116435885  Down :  0.11005553  Right :  0.030354338  Up :  0.089591876\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","F\u001b[41mF\u001b[0mFHFFFG\n","\n","========== Episode 561 중간평가 ==========\n","Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.124054864  Down :  0.10111104  Right :  0.12943757  Up :  0.14127195\n","  (Up)\n","S\u001b[41mF\u001b[0mFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 562 ==========\n","Left -> Right -> Left -> Down -> Left -> Down -> Left -> Right -> Down -> Left -> Right -> Up -> Left -> Up -> Right -> Down -> Down -> Up -> Right -> Down -> Down -> Left -> Left -> Left -> Down -> Left -> Left -> Left -> Right -> \n","Left :  0.108986214  Down :  0.09560959  Right :  -0.026466146  Up :  0.08406859\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 563 ==========\n","Down -> Right -> Down -> Down -> Right -> Down -> Left -> Left -> Right -> Right -> Left -> Down -> \n","Left :  0.07863985  Down :  0.0138336085  Right :  0.09351313  Up :  0.055510167\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 564 ==========\n","Left -> Right -> Right -> Right -> Left -> Right -> Left -> Down -> Left -> Down -> Right -> Down -> Right -> Right -> Right -> \n","Left :  0.078380086  Down :  0.07611993  Right :  0.05133196  Up :  0.0373993\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 565 ==========\n","Right -> Down -> Down -> Down -> Right -> Left -> Down -> Right -> Down -> \n","Left :  0.1201657  Down :  0.023623148  Right :  0.053328797  Up :  0.12778792\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 566 ==========\n","Down -> Down -> Down -> Left -> Left -> Down -> Left -> Left -> Left -> Up -> Right -> Right -> Up -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.17530726  Down :  0.13270842  Right :  0.036879227  Up :  0.0802772\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 567 ==========\n","Left -> Down -> Right -> Left -> Right -> Right -> Left -> Left -> Right -> Left -> Right -> Up -> Left -> Left -> Left -> Right -> Down -> Left -> Right -> Down -> Left -> Down -> Left -> Up -> Up -> Right -> Right -> Down -> Right -> \n","Left :  0.12437057  Down :  0.110789806  Right :  0.008108016  Up :  0.07194536\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 568 ==========\n","Left -> Right -> Down -> Right -> Down -> Left -> Down -> Left -> Right -> Down -> Left -> Up -> Left -> Left -> Down -> Left -> Up -> Right -> Right -> Right -> Right -> Down -> Left -> \n","Left :  0.08943221  Down :  0.08906696  Right :  0.08443305  Up :  0.08441234\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 569 ==========\n","Right -> Right -> Up -> Right -> Right -> Left -> Down -> Down -> \n","Left :  0.08094562  Down :  0.003640756  Right :  0.09453599  Up :  0.04172416\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 570 ==========\n","Right -> Up -> Left -> Right -> Left -> Left -> Right -> Right -> Up -> Down -> Down -> Left -> Left -> Right -> Right -> Down -> Up -> Left -> Down -> Down -> Down -> \n","Left :  0.08640271  Down :  -0.003911242  Right :  0.099165685  Up :  0.047127113\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 571 ==========\n","Right -> Right -> Right -> Down -> Right -> Right -> Left -> Right -> Left -> Left -> Left -> Right -> Left -> Down -> Down -> Down -> Right -> \n","Left :  0.079619735  Down :  -0.0044177994  Right :  -0.0015995316  Up :  0.09004427\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 571 중간평가 ==========\n","Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.082821235  Down :  0.07815493  Right :  0.07672054  Up :  0.08720526\n","  (Up)\n","S\u001b[41mF\u001b[0mFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 572 ==========\n","Right -> Left -> Right -> Right -> Right -> Left -> Right -> Right -> Down -> Right -> Right -> Down -> Down -> Down -> Left -> Right -> Left -> Left -> Right -> Left -> Left -> \n","Left :  0.06425858  Down :  0.06530735  Right :  0.061463088  Up :  0.059178825\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 573 ==========\n","Right -> Down -> Down -> Left -> Right -> Right -> Down -> Left -> Right -> Left -> Down -> Right -> Left -> Right -> Right -> \n","Left :  0.10984741  Down :  0.0031937882  Right :  0.035008658  Up :  0.08341113\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 574 ==========\n","Left -> Right -> Down -> Right -> Right -> Right -> Right -> Left -> Left -> Right -> Left -> Down -> \n","Left :  0.11635971  Down :  -0.00961696  Right :  0.07804514  Up :  0.013438532\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 575 ==========\n","Down -> Down -> Right -> Left -> Left -> Right -> Down -> Right -> Left -> Down -> Right -> Left -> Right -> Down -> \n","Left :  0.04924698  Down :  -0.033158123  Right :  0.009816654  Up :  0.06934655\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 576 ==========\n","Down -> Down -> Right -> Right -> Right -> \n","Left :  0.063595995  Down :  0.048249595  Right :  0.000536412  Up :  0.07069894\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 577 ==========\n","Right -> Left -> Down -> Right -> Left -> Left -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.0508038  Down :  0.044908464  Right :  -0.004169762  Up :  0.081345804\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 578 ==========\n","Down -> Right -> Right -> Right -> Down -> \n","Left :  0.07389159  Down :  0.0068520624  Right :  0.05347111  Up :  0.024456028\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 579 ==========\n","Right -> Left -> Right -> Down -> Right -> Right -> Left -> Down -> Down -> Right -> Up -> \n","Left :  0.02594878  Down :  0.0191096  Right :  0.039416995  Up :  0.047594234\n","  (Up)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 580 ==========\n","Left -> Left -> Left -> Left -> Down -> Left -> Down -> Right -> Left -> Down -> Down -> Right -> Left -> Left -> Right -> Left -> Left -> Left -> Down -> Up -> Right -> Down -> \n","Left :  0.03937371  Down :  0.0004648324  Right :  0.05071727  Up :  0.003415756\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 581 ==========\n","Down -> Left -> Left -> Right -> Right -> Down -> Down -> Right -> Right -> Left -> Left -> Left -> Left -> Left -> Right -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.042826086  Down :  -0.004312491  Right :  0.020010006  Up :  0.054466426\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 581 중간평가 ==========\n","Right -> Down -> Right -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> \n","Left :  0.06485982  Down :  0.06868601  Right :  0.061527226  Up :  0.061923854\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FF\u001b[41mF\u001b[0mHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 582 ==========\n","Down -> Down -> Right -> Right -> Left -> Left -> Right -> Left -> Right -> Right -> Up -> Right -> Right -> Left -> Right -> Right -> Right -> Left -> Right -> Right -> Left -> Down -> Right -> Down -> Down -> Left -> Right -> Right -> Left -> Down -> \n","Left :  0.05257826  Down :  0.035225764  Right :  0.09513977  Up :  0.050362088\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 583 ==========\n","Down -> Down -> Down -> Down -> Right -> Left -> Left -> Left -> Left -> Down -> Down -> Down -> Left -> Left -> Left -> Down -> Left -> Left -> Left -> Down -> Right -> Down -> Right -> Left -> Right -> Up -> Down -> Left -> Down -> Right -> Down -> Down -> Up -> Left -> \n","Left :  0.07575609  Down :  0.08601514  Right :  0.071938284  Up :  0.08333385\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 584 ==========\n","Down -> Right -> Down -> Right -> Left -> Right -> Left -> Down -> Down -> Right -> Left -> Left -> Down -> Up -> Down -> Right -> \n","Left :  0.073123954  Down :  0.06696351  Right :  -0.0011879988  Up :  0.07365355\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 585 ==========\n","Left -> Down -> Down -> Left -> Down -> Down -> Left -> Down -> Right -> \n","Left :  0.07038969  Down :  0.067182824  Right :  -0.0046276636  Up :  0.07721695\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 586 ==========\n","Right -> Down -> Right -> Down -> Up -> Right -> Right -> Left -> Left -> Down -> Up -> Right -> Down -> \n","Left :  0.07107532  Down :  -0.0020343047  Right :  0.0494371  Up :  0.015069718\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 587 ==========\n","Down -> Right -> Right -> Down -> Left -> Down -> Left -> Down -> Right -> Left -> Down -> Down -> Down -> Down -> Left -> Left -> Right -> Left -> Left -> Left -> Down -> Left -> Right -> Down -> Left -> Left -> Down -> Right -> Left -> Left -> Down -> Right -> Down -> Down -> Left -> Left -> Left -> Left -> Left -> Right -> Left -> Right -> Down -> Left -> Right -> Left -> Left -> Right -> Down -> Right -> Up -> Left -> \n","Left :  0.08396417  Down :  0.09221971  Right :  0.08343445  Up :  0.08709423\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 588 ==========\n","Left -> Down -> Down -> Down -> Down -> Right -> Left -> Left -> Down -> Down -> Down -> Down -> Right -> Down -> Left -> Down -> Down -> Right -> Down -> Left -> Down -> Left -> Right -> Right -> Right -> \n","Left :  0.069652155  Down :  0.07029596  Right :  -0.0018331856  Up :  0.078212604\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 589 ==========\n","Down -> Right -> Down -> Right -> Up -> Right -> Left -> Right -> Down -> \n","Left :  0.07358963  Down :  -0.010568287  Right :  0.04957042  Up :  0.015321359\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 590 ==========\n","Down -> Right -> Right -> Up -> Down -> Right -> Left -> Right -> Left -> Down -> Up -> Down -> Left -> Up -> Down -> Right -> Up -> Left -> Right -> Down -> Up -> Down -> Up -> Left -> Up -> Up -> Down -> Left -> Left -> Right -> Left -> Right -> Right -> Up -> Up -> Right -> Up -> Right -> Right -> Down -> Up -> Left -> Up -> Left -> Down -> Down -> \n","Left :  0.063801244  Down :  0.012173938  Right :  0.046956636  Up :  0.0399108\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 591 ==========\n","Left -> Right -> Left -> Down -> Down -> Left -> Right -> Down -> Left -> Down -> Down -> Down -> Down -> Left -> Down -> Left -> Down -> Right -> Left -> Right -> Down -> Right -> Up -> Right -> Down -> \n","Left :  0.07880671  Down :  0.12315772  Right :  0.09878783  Up :  0.10908458\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 591 중간평가 ==========\n","Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.06734661  Down :  0.077005446  Right :  0.05532805  Up :  0.067180246\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","\u001b[41mF\u001b[0mFFHFFFG\n","\n","========== Episode 592 ==========\n","Right -> Left -> Right -> Down -> Down -> Down -> Left -> Right -> Down -> Left -> Left -> Down -> Down -> Right -> \n","Left :  0.10637484  Down :  0.10396886  Right :  0.013995945  Up :  0.08164058\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 593 ==========\n","Left -> Right -> Down -> Down -> Left -> Right -> Down -> Down -> Down -> \n","Left :  0.07471529  Down :  0.027639309  Right :  0.07258399  Up :  0.029239409\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 594 ==========\n","Left -> Left -> Left -> Right -> Right -> Down -> Right -> Left -> Down -> Down -> Left -> Down -> Left -> Right -> Left -> Down -> Left -> Right -> \n","Left :  0.07645315  Down :  0.08414589  Right :  0.0017223693  Up :  0.07955828\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 595 ==========\n","Left -> Right -> Right -> Left -> Left -> Left -> Down -> Down -> Right -> Down -> Left -> Left -> Right -> Down -> Down -> \n","Left :  0.09323168  Down :  0.03127294  Right :  0.09095009  Up :  0.039251793\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 596 ==========\n","Down -> Right -> Down -> Left -> Right -> Right -> Left -> Right -> Right -> \n","Left :  0.08359437  Down :  0.09889744  Right :  0.0026537254  Up :  0.10901603\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 597 ==========\n","Down -> Down -> Right -> Left -> Right -> Down -> Left -> Left -> Down -> Down -> Down -> Up -> Down -> Left -> Left -> Right -> \n","Left :  0.08199285  Down :  0.097133175  Right :  5.964935e-05  Up :  0.10976492\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 598 ==========\n","Right -> Right -> Left -> Left -> Left -> Left -> Left -> Down -> Left -> Down -> Right -> Right -> Right -> \n","Left :  0.078466795  Down :  0.07871522  Right :  0.0063651763  Up :  0.091907874\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 599 ==========\n","Left -> Right -> Right -> Right -> Right -> Down -> Left -> Right -> Right -> Right -> Left -> Down -> Right -> Right -> Left -> Right -> Right -> Down -> Down -> Left -> Down -> \n","Left :  0.068847686  Down :  0.040923517  Right :  0.11795874  Up :  0.03867144\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 600 ==========\n","Down -> Down -> Down -> Left -> Right -> Left -> Left -> Down -> Left -> Left -> Right -> Right -> Down -> \n","Left :  0.1105988  Down :  -0.041540127  Right :  0.03783131  Up :  0.08763133\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 601 ==========\n","Right -> Right -> Left -> Down -> Right -> Down -> Down -> Left -> Down -> Right -> Down -> \n","Left :  0.10856227  Down :  0.09650834  Right :  0.045618847  Up :  0.11428116\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 601 중간평가 ==========\n","******** SUCCESS ********\n","Right -> Down -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Down -> Right -> Down -> Down -> Down -> \n","Left :  -0.074646145  Down :  0.82490784  Right :  0.73432875  Up :  0.27587217\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 602 ==========\n","Left -> Left -> Down -> Down -> Right -> Right -> Left -> Left -> Down -> Down -> Down -> Left -> Right -> \n","Left :  0.105399996  Down :  0.10561064  Right :  0.00053557754  Up :  0.112079546\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 603 ==========\n","Right -> Down -> Right -> Down -> Left -> Right -> Right -> \n","Left :  0.09140994  Down :  0.08787786  Right :  0.023087453  Up :  0.08444827\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 604 ==========\n","Left -> Down -> Left -> Down -> Left -> Right -> Left -> Right -> Right -> Right -> \n","Left :  0.08160737  Down :  0.08247028  Right :  0.02148664  Up :  0.07494192\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 605 ==========\n","Right -> Left -> Right -> Left -> Down -> Right -> Right -> Down -> Up -> Right -> Right -> Down -> Down -> Down -> Right -> Right -> Down -> \n","Left :  0.08094564  Down :  0.028311986  Right :  0.16285259  Up :  0.046693563\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 606 ==========\n","Down -> Left -> Right -> Right -> Right -> Left -> Right -> Left -> Right -> Down -> \n","Left :  0.059714857  Down :  0.037498258  Right :  0.08105273  Up :  0.041369535\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 607 ==========\n","Right -> Left -> Down -> Down -> Left -> Down -> Left -> Left -> Down -> Right -> Left -> Down -> Down -> Left -> Right -> \n","Left :  0.119501695  Down :  0.12694085  Right :  0.0064952  Up :  0.099751845\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 608 ==========\n","Right -> Left -> Down -> Left -> Down -> Down -> Down -> Right -> Left -> Left -> Down -> Down -> Left -> Down -> Down -> Right -> Down -> Down -> Down -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.12810442  Down :  0.12700345  Right :  -0.000411354  Up :  0.10963863\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 609 ==========\n","Left -> Left -> Down -> Right -> Down -> Right -> Down -> Down -> Left -> Right -> Down -> \n","Left :  0.091041856  Down :  0.03720838  Right :  0.051466297  Up :  0.10377439\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 610 ==========\n","Right -> Left -> Left -> Right -> Down -> Down -> Down -> Right -> Right -> Left -> Right -> Left -> Up -> Down -> Up -> Up -> Down -> Right -> \n","Left :  0.07256181  Down :  0.08486584  Right :  -0.025681369  Up :  0.12902334\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 611 ==========\n","Left -> Left -> Right -> Right -> Right -> Left -> Left -> Down -> Left -> Left -> Right -> Down -> Down -> Down -> Down -> \n","Left :  0.07508989  Down :  0.010385871  Right :  0.0613649  Up :  0.011659568\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 611 중간평가 ==========\n","Right -> Down -> Down -> Right -> Down -> Down -> Left -> Left -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.07466464  Down :  0.08566501  Right :  0.072221406  Up :  0.057893354\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","\u001b[41mF\u001b[0mFFHFFFG\n","\n","========== Episode 612 ==========\n","Right -> Left -> Right -> Down -> Right -> Down -> Up -> Down -> Down -> Left -> Right -> Right -> Right -> Right -> \n","Left :  0.05839195  Down :  0.0568564  Right :  0.022846103  Up :  0.068884514\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 613 ==========\n","Right -> Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  0.08091028  Down :  0.09194377  Right :  -0.0034157112  Up :  0.098393574\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 614 ==========\n","Down -> Right -> Down -> Right -> Left -> Down -> Left -> Right -> Down -> Left -> Right -> Right -> Right -> \n","Left :  0.07678187  Down :  -0.0024692193  Right :  0.008187093  Up :  0.07998267\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 615 ==========\n","Down -> Left -> Down -> Left -> Down -> Left -> Down -> Down -> Down -> Left -> Down -> Right -> Left -> Down -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Down -> Left -> Left -> Left -> Down -> Right -> Right -> Left -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.14442843  Down :  0.14831166  Right :  0.04781428  Up :  0.12072997\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 616 ==========\n","Right -> Left -> Left -> Right -> Left -> Left -> Left -> Right -> Left -> Down -> Right -> Right -> Left -> Down -> Right -> Left -> Right -> Left -> Down -> Left -> Down -> Down -> Left -> Left -> Left -> Right -> \n","Left :  0.17620751  Down :  0.13704012  Right :  0.033316836  Up :  0.09255397\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 617 ==========\n","Right -> Left -> Left -> Left -> Down -> Right -> Right -> Right -> Left -> Left -> Right -> Left -> Down -> Right -> Left -> Right -> Down -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.11568333  Down :  0.07169682  Right :  0.044721827  Up :  0.10331029\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 618 ==========\n","Down -> Down -> Right -> Right -> Down -> Left -> Down -> Left -> Left -> Up -> Right -> Right -> Right -> Down -> \n","Left :  0.09576645  Down :  0.053796593  Right :  0.11512171  Up :  0.059383184\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 619 ==========\n","Right -> Right -> Right -> Up -> Down -> Right -> Right -> Right -> Right -> Left -> Right -> Left -> Left -> Right -> Left -> Left -> Down -> Right -> Down -> \n","Left :  0.3067652  Down :  0.42705524  Right :  0.50884193  Up :  0.35598633\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 620 ==========\n","Down -> Down -> Down -> Right -> Down -> Down -> \n","Left :  0.27613527  Down :  0.0221297  Right :  0.29564142  Up :  0.12438476\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 621 ==========\n","Down -> Left -> Left -> Down -> Down -> Right -> Left -> Right -> Down -> Down -> \n","Left :  0.3086846  Down :  0.10736958  Right :  0.23511915  Up :  0.12255199\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 621 중간평가 ==========\n","Right -> Down -> Down -> Down -> Down -> Left -> Down -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> \n","Left :  0.21770029  Down :  0.20050111  Right :  0.051858015  Up :  0.12691408\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","\u001b[41mF\u001b[0mHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 622 ==========\n","Right -> Down -> Right -> Right -> Down -> \n","Left :  0.2558657  Down :  0.095404804  Right :  0.2750627  Up :  0.14045224\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 623 ==========\n","Right -> Down -> Right -> Right -> Left -> Down -> Down -> Right -> Down -> \n","Left :  0.20607825  Down :  0.06853055  Right :  0.21367031  Up :  0.06812916\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 624 ==========\n","Left -> Left -> Down -> Left -> Down -> Left -> Left -> Down -> Left -> Left -> Left -> Down -> Down -> Right -> \n","Left :  0.22334692  Down :  0.20038456  Right :  0.0016441271  Up :  0.2053647\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 625 ==========\n","Left -> Down -> Left -> Down -> Down -> Left -> Left -> Left -> Left -> Down -> Left -> Down -> Left -> Down -> Right -> \n","Left :  0.21656275  Down :  0.18981174  Right :  -0.0071373954  Up :  0.20734245\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 626 ==========\n","Right -> Down -> Right -> Right -> Left -> Left -> Right -> Down -> Down -> Up -> Left -> Left -> Left -> Left -> Right -> Right -> Left -> Down -> Down -> Left -> Down -> Down -> Down -> Right -> Down -> Right -> Left -> Right -> Right -> \n","Left :  0.24151021  Down :  0.23846129  Right :  0.09175506  Up :  0.20958632\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 627 ==========\n","Right -> Right -> Down -> Right -> Down -> \n","Left :  0.3027197  Down :  -0.0021424815  Right :  0.34668738  Up :  0.15123916\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 628 ==========\n","Down -> Left -> Right -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Left -> \n","Left :  0.18160746  Down :  0.903217  Right :  0.74206555  Up :  0.30630416\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 629 ==========\n","Right -> Right -> Right -> Left -> Right -> Right -> Left -> Left -> Down -> Down -> Down -> Right -> Down -> \n","Left :  0.13963246  Down :  0.042878762  Right :  0.15511568  Up :  0.050126217\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 630 ==========\n","Down -> Down -> Right -> Down -> Down -> Right -> Left -> Right -> Right -> \n","Left :  0.17232998  Down :  0.08898205  Right :  0.107973054  Up :  0.19895801\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 631 ==========\n","Right -> Left -> Right -> Right -> Right -> Down -> Down -> \n","Left :  0.24575165  Down :  -0.058480434  Right :  0.34098333  Up :  0.10175022\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 631 중간평가 ==========\n","Right -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> Down -> Down -> Right -> Down -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.3830243  Down :  1.0570229  Right :  1.131511  Up :  0.71149343\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFH\u001b[41mF\u001b[0m\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 632 ==========\n","Right -> Left -> Down -> Left -> Down -> Right -> Right -> Down -> Up -> Right -> \n","Left :  0.19510767  Down :  0.2068963  Right :  0.005952537  Up :  0.20115791\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 633 ==========\n","Left -> Right -> Right -> Down -> Down -> Right -> \n","Left :  0.2118702  Down :  0.21981607  Right :  0.0034513772  Up :  0.20830639\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 634 ==========\n","Right -> Right -> Left -> Down -> Right -> Left -> Left -> Left -> Up -> Down -> Up -> Down -> Right -> Left -> Down -> Right -> Right -> Left -> Down -> Left -> Down -> Down -> Left -> Left -> Down -> Down -> Up -> Right -> \n","Left :  0.2333679  Down :  0.31453884  Right :  -0.03976819  Up :  0.27864188\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 635 ==========\n","Right -> Right -> Right -> Left -> Right -> Up -> Down -> Down -> \n","Left :  0.2394894  Down :  0.11965968  Right :  0.36321065  Up :  0.1939848\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 636 ==========\n","Down -> Left -> Right -> Right -> Right -> Down -> \n","Left :  0.27655035  Down :  0.112661995  Right :  0.45021027  Up :  0.21768923\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 637 ==========\n","Down -> Left -> Right -> Down -> Left -> Left -> Right -> Left -> Down -> Left -> Right -> Down -> Right -> Left -> Down -> \n","Left :  0.18404627  Down :  0.006190963  Right :  0.22676374  Up :  0.054835483\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 638 ==========\n","Right -> Right -> Right -> Up -> Down -> Down -> \n","Left :  0.20026168  Down :  -0.02541288  Right :  0.3828431  Up :  0.09222189\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 639 ==========\n","******** SUCCESS ********\n","Right -> Right -> Right -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Right -> Right -> Down -> Down -> Right -> Right -> Left -> Right -> Right -> Right -> Left -> Right -> Left -> Down -> Down -> Right -> Down -> Right -> Right -> Down -> Down -> \n","Left :  0.060288083  Down :  0.8325522  Right :  1.290593  Up :  0.5233928\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 640 ==========\n","Right -> Right -> Left -> Right -> Right -> Up -> Down -> Left -> Down -> Down -> Up -> Right -> \n","Left :  0.16212077  Down :  0.15794295  Right :  0.017300397  Up :  0.17916855\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 641 ==========\n","Down -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> \n","Left :  0.29016265  Down :  0.025019199  Right :  0.41074467  Up :  0.10319894\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 641 중간평가 ==========\n","Right -> Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.23915373  Down :  0.35368615  Right :  0.30376834  Up :  0.378797\n","  (Up)\n","SFF\u001b[41mF\u001b[0mFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 642 ==========\n","Down -> Right -> Down -> Down -> Left -> Right -> Down -> Down -> \n","Left :  0.14447013  Down :  0.0032344088  Right :  0.17303896  Up :  0.022062415\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 643 ==========\n","Left -> Right -> Right -> Down -> Right -> Right -> Up -> Right -> Down -> Down -> Left -> Down -> Right -> \n","Left :  0.17301667  Down :  0.17138809  Right :  -0.010067895  Up :  0.174299\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 644 ==========\n","Right -> Right -> Down -> Down -> Left -> Left -> Left -> Right -> Left -> Left -> Down -> Down -> Down -> Down -> Left -> Left -> Left -> Right -> \n","Left :  0.17794144  Down :  0.16724709  Right :  0.023450166  Up :  0.15410323\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 645 ==========\n","Down -> Down -> Right -> Down -> Down -> Right -> Right -> \n","Left :  0.19944963  Down :  0.08776072  Right :  0.022156954  Up :  0.17119393\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 646 ==========\n","Down -> Right -> Left -> Left -> Right -> Down -> Left -> Up -> Right -> Down -> Left -> Right -> Left -> Right -> Left -> Down -> Right -> Left -> Down -> Down -> Down -> Down -> Down -> Left -> Left -> Down -> Down -> Left -> Right -> Right -> Right -> \n","Left :  0.22296153  Down :  0.1312229  Right :  -0.024602279  Up :  0.17314439\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 647 ==========\n","Right -> Down -> Right -> Right -> Right -> Left -> Right -> Right -> Up -> Right -> Right -> Right -> Left -> Left -> Up -> Right -> Down -> Up -> Up -> Left -> Right -> Right -> Up -> Down -> Up -> Right -> Down -> Up -> Up -> Down -> Left -> Right -> Right -> Left -> Down -> Left -> Left -> Right -> Right -> Right -> Right -> Down -> Left -> Left -> \n","Left :  0.058985613  Down :  0.3320868  Right :  0.56223255  Up :  0.21226837\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 648 ==========\n","Left -> Left -> Down -> Right -> Down -> Right -> Left -> Left -> Up -> Left -> Left -> Down -> Left -> Up -> Right -> Right -> Right -> Right -> Down -> Left -> \n","Left :  0.33354703  Down :  0.19640422  Right :  0.4131741  Up :  0.25750947\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 649 ==========\n","Down -> Right -> Right -> Down -> Left -> Right -> Down -> Right -> Left -> Right -> Right -> Down -> Right -> Right -> Left -> Right -> Down -> \n","Left :  0.4878465  Down :  0.04640762  Right :  0.8807156  Up :  0.14008948\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 650 ==========\n","Right -> Left -> Up -> Right -> Left -> Right -> Left -> Right -> Down -> Left -> Right -> Right -> Right -> Right -> Left -> Down -> \n","Left :  0.21609017  Down :  -0.0068802536  Right :  0.24286509  Up :  0.05478899\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 651 ==========\n","Up -> Right -> Left -> Up -> Left -> Up -> Left -> Up -> Right -> Right -> Down -> Right -> Left -> Right -> Left -> Right -> Left -> Down -> Left -> Left -> Left -> Down -> Down -> Left -> Left -> Left -> Right -> Down -> \n","Left :  0.12660111  Down :  -0.003521368  Right :  0.11553908  Up :  0.02537429\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 651 중간평가 ==========\n","Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.17268495  Down :  0.19389957  Right :  0.17977458  Up :  0.21415552\n","  (Up)\n","\u001b[41mS\u001b[0mFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 652 ==========\n","Right -> Down -> Down -> Left -> Right -> Left -> Down -> Up -> Up -> Down -> Left -> Down -> Down -> Left -> Left -> Left -> Left -> Right -> Left -> Right -> Right -> Down -> \n","Left :  0.1175202  Down :  -0.038596533  Right :  -0.007733837  Up :  0.12297045\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 653 ==========\n","Right -> Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  0.12512451  Down :  0.12548165  Right :  -0.00032147765  Up :  0.14701681\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 654 ==========\n","Right -> Left -> Right -> Right -> Right -> Up -> Left -> Right -> Up -> Down -> Right -> Left -> Down -> \n","Left :  0.17794009  Down :  0.0055446625  Right :  0.197228  Up :  0.041961446\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 655 ==========\n","Left -> Right -> Down -> Down -> Down -> Right -> Right -> Right -> Up -> Right -> Right -> Down -> Right -> Right -> Down -> Left -> Right -> Down -> Down -> Left -> \n","Left :  0.20793131  Down :  0.5450322  Right :  0.5541653  Up :  0.41790658\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 656 ==========\n","Right -> Down -> Down -> Left -> Right -> Left -> Up -> Down -> Down -> Down -> Left -> Left -> Left -> Left -> Left -> Right -> Left -> Left -> Left -> Down -> Down -> Up -> Right -> \n","Left :  0.1155348  Down :  0.11316744  Right :  -0.0018022805  Up :  0.14462383\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 657 ==========\n","Left -> Right -> Down -> Right -> Right -> Down -> \n","Left :  0.16707748  Down :  -0.0015077963  Right :  0.20262462  Up :  0.041653585\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 658 ==========\n","Left -> Left -> Right -> Down -> Down -> Right -> Left -> Right -> Left -> Down -> Left -> Left -> Left -> Down -> Left -> Left -> Down -> Left -> Down -> Up -> Down -> Right -> \n","Left :  0.1233373  Down :  0.11889355  Right :  0.0005211532  Up :  0.12416342\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 659 ==========\n","Left -> Right -> Left -> Down -> Right -> Right -> Left -> Down -> Left -> Down -> Down -> Right -> Right -> Left -> Right -> Left -> Down -> \n","Left :  0.107816495  Down :  0.0011578649  Right :  0.112899624  Up :  0.008787239\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 660 ==========\n","Down -> Left -> Down -> Up -> Right -> Right -> Right -> Down -> \n","Left :  0.17713462  Down :  0.0023025647  Right :  0.22681452  Up :  0.019014876\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 661 ==========\n","Left -> Down -> Down -> Up -> Left -> Right -> Left -> Down -> Down -> Down -> Left -> Down -> Down -> Down -> Right -> Left -> Down -> Right -> Down -> Right -> Down -> Left -> Left -> Down -> Down -> Down -> Down -> Left -> Down -> Left -> Down -> Left -> Down -> Right -> Left -> Down -> Down -> Down -> Down -> Left -> Right -> Left -> Down -> Left -> Right -> Down -> Left -> Down -> Right -> Left -> Down -> Down -> Down -> Left -> Right -> Left -> Right -> Left -> Down -> Right -> Left -> Down -> Right -> Down -> Left -> Left -> Down -> Down -> Down -> Down -> Right -> Down -> Down -> Left -> Down -> Down -> Right -> Left -> Down -> Left -> Down -> Down -> Right -> Down -> Left -> Down -> Left -> Down -> Down -> Down -> Right -> Left -> Left -> Down -> Right -> Right -> Left -> Right -> Left -> Left -> \n","Left :  0.15142542  Down :  0.14220135  Right :  0.13311265  Up :  0.061504457\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","\u001b[41mF\u001b[0mFFHFFFG\n","\n","========== Episode 661 중간평가 ==========\n","Right -> Down -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> Right -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> \n","Left :  0.5514559  Down :  0.6737562  Right :  0.7303128  Up :  0.7598678\n","  (Up)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHF\u001b[41mF\u001b[0m\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 662 ==========\n","Down -> Right -> Right -> Left -> Right -> Right -> Right -> Right -> Down -> Down -> \n","Left :  0.2973112  Down :  0.243785  Right :  0.5103795  Up :  0.2563613\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 663 ==========\n","Right -> Right -> Down -> Right -> Down -> \n","Left :  0.25548995  Down :  -0.017359316  Right :  0.3383668  Up :  0.027685825\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 664 ==========\n","Down -> Down -> Down -> Left -> Left -> Left -> Right -> Right -> Down -> Down -> \n","Left :  0.18463789  Down :  0.06001529  Right :  0.020120978  Up :  0.118621394\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 665 ==========\n","******** SUCCESS ********\n","Left -> Down -> Right -> Right -> Right -> Right -> Right -> Right -> Left -> Left -> Left -> Left -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.31897926  Down :  0.7942693  Right :  0.7879581  Up :  0.58037657\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 666 ==========\n","******** SUCCESS ********\n","Right -> Right -> Right -> Right -> Down -> Right -> Down -> Right -> Down -> Down -> Left -> Right -> Right -> Up -> Down -> Left -> Right -> Up -> Right -> Right -> Down -> Up -> Down -> Left -> Left -> Right -> Right -> Left -> Right -> Left -> Right -> Down -> Down -> Down -> \n","Left :  0.34710306  Down :  0.859596  Right :  0.8362942  Up :  0.6241919\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 667 ==========\n","Down -> Right -> Down -> Left -> Right -> Left -> Up -> Left -> Right -> Right -> Right -> Right -> Down -> Left -> \n","Left :  0.28709427  Down :  0.28477272  Right :  0.41198903  Up :  0.2730758\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 668 ==========\n","Left -> Down -> Left -> Right -> Right -> Left -> Right -> Right -> Left -> Left -> Down -> Left -> Right -> Left -> Left -> Up -> Down -> Up -> Left -> Down -> Right -> Down -> Down -> Left -> Down -> Left -> Right -> \n","Left :  0.24249387  Down :  0.2920175  Right :  -0.010397047  Up :  0.202275\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 669 ==========\n","Down -> Right -> Left -> Down -> Left -> Left -> Right -> Down -> Down -> Left -> Right -> Left -> Down -> Down -> Left -> Down -> Left -> Down -> Left -> Down -> Down -> Down -> Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  0.18398249  Down :  0.17361869  Right :  0.054034606  Up :  0.111237295\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 670 ==========\n","Down -> Right -> Down -> Down -> Right -> Left -> Right -> Left -> Left -> Down -> Right -> Left -> Left -> Left -> Down -> Left -> Down -> Left -> Down -> Left -> Left -> Down -> Down -> Left -> Right -> Down -> Right -> Down -> Left -> Down -> Left -> Left -> Left -> Left -> Right -> Left -> Left -> Down -> Left -> Down -> Down -> Right -> Left -> Right -> Left -> Left -> Left -> Left -> Right -> Down -> Left -> Down -> Right -> Down -> Left -> Left -> Left -> Down -> Down -> Right -> Right -> Left -> Right -> Left -> Left -> Down -> Left -> Right -> Left -> Left -> Left -> Down -> Right -> Right -> Left -> Left -> Down -> Down -> Down -> Left -> Left -> Left -> Right -> Left -> Left -> Left -> Left -> Right -> Left -> Left -> Left -> Left -> Down -> Left -> Left -> Left -> Left -> Down -> Down -> Left -> \n","Left :  0.15809603  Down :  0.1291964  Right :  0.1287725  Up :  0.13691053\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","\u001b[41mF\u001b[0mFFHFFFG\n","\n","========== Episode 671 ==========\n","Right -> Right -> Down -> Left -> Right -> Right -> Right -> Right -> Down -> Right -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> Left -> Left -> \n","Left :  0.104637936  Down :  0.45927835  Right :  0.6292095  Up :  0.24522208\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 671 중간평가 ==========\n","Right -> Down -> Right -> Right -> Right -> Right -> Down -> Right -> Down -> Right -> Down -> Down -> Down -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.26023054  Down :  0.6272307  Right :  0.62898856  Up :  0.42835477\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFH\u001b[41mF\u001b[0m\n","FFFHFFFG\n","\n","========== Episode 672 ==========\n","Right -> Left -> Right -> Left -> Left -> Left -> Down -> Down -> Down -> Right -> Right -> Right -> Left -> Left -> Down -> Left -> Down -> Right -> \n","Left :  0.25533858  Down :  0.25651973  Right :  -0.03361395  Up :  0.28585488\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 673 ==========\n","Down -> Up -> Right -> Down -> Right -> Down -> Left -> Right -> Down -> Right -> Right -> Down -> Right -> Left -> Right -> Down -> Down -> Up -> Down -> Left -> \n","Left :  0.26646906  Down :  0.2260468  Right :  0.18961048  Up :  0.27812898\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFF\u001b[41mH\u001b[0mFHF\n","FFFHFFFG\n","\n","========== Episode 674 ==========\n","Down -> Right -> Right -> Right -> Right -> Right -> Down -> Right -> Down -> Right -> Left -> Right -> Right -> Down -> Right -> Left -> Right -> Left -> Down -> \n","Left :  0.30578643  Down :  0.057594605  Right :  0.3831517  Up :  0.09837131\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 675 ==========\n","Left -> Left -> Right -> Right -> Down -> Down -> Up -> Right -> Down -> \n","Left :  0.22616112  Down :  -0.007991917  Right :  0.25290188  Up :  0.09152269\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 676 ==========\n","Down -> Down -> Down -> Down -> Down -> Left -> Left -> Down -> Right -> \n","Left :  0.1608321  Down :  0.12383792  Right :  -0.018489942  Up :  0.19483846\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 677 ==========\n","Right -> Left -> Right -> Left -> Right -> Left -> Right -> Right -> Right -> Down -> Left -> Left -> Down -> Right -> Right -> \n","Left :  0.18548709  Down :  0.16518158  Right :  0.04130508  Up :  0.23114014\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 678 ==========\n","Left -> Right -> Right -> Right -> Down -> Down -> \n","Left :  0.19553992  Down :  -0.0037448332  Right :  0.22463174  Up :  0.09572448\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 679 ==========\n","Right -> Down -> Down -> Right -> Right -> \n","Left :  0.1583165  Down :  0.14370698  Right :  -0.006680757  Up :  0.21743411\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 680 ==========\n","Right -> Left -> Left -> Down -> Right -> Left -> Right -> Down -> Right -> Right -> \n","Left :  0.16727659  Down :  0.12699735  Right :  -0.0045730174  Up :  0.22048017\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 681 ==========\n","Left -> Right -> Down -> Right -> Down -> Up -> Left -> Left -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Up -> Down -> Up -> Down -> Left -> Right -> Up -> Right -> Right -> Left -> Right -> Right -> Down -> Right -> Left -> Down -> \n","Left :  0.15623724  Down :  0.07927243  Right :  0.23935433  Up :  0.10543971\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 681 중간평가 ==========\n","Down -> Right -> Right -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> \n","Left :  0.15591754  Down :  0.1928771  Right :  0.1908867  Up :  0.17729938\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FF\u001b[41mF\u001b[0mHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 682 ==========\n","Right -> Right -> Right -> Down -> Right -> Right -> Down -> Right -> Right -> Down -> Left -> Down -> Down -> \n","Left :  0.23639984  Down :  0.004087165  Right :  0.28977078  Up :  0.048913687\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 683 ==========\n","Left -> Left -> Down -> Down -> Up -> Right -> Left -> Down -> Down -> Down -> Down -> Up -> Right -> Right -> Up -> Left -> Down -> Right -> Right -> \n","Left :  0.13403112  Down :  0.006773062  Right :  -0.026089318  Up :  0.16765743\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 684 ==========\n","Down -> Left -> Down -> Right -> Right -> Left -> Right -> Up -> Right -> Right -> Right -> Down -> Left -> Down -> Left -> Left -> Right -> Left -> Up -> Up -> Right -> Right -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Right -> Left -> Down -> Right -> Up -> Left -> Right -> Down -> Right -> Up -> Right -> Left -> Down -> Right -> Down -> Right -> Right -> Left -> Down -> \n","Left :  0.22816306  Down :  -0.0037538335  Right :  0.27626532  Up :  0.04039003\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 685 ==========\n","Right -> Left -> Right -> Down -> Right -> Down -> Up -> Down -> Up -> Right -> Right -> Left -> Right -> Right -> Left -> Down -> Right -> Left -> Left -> \n","Left :  0.13738512  Down :  0.19383767  Right :  0.1991268  Up :  0.17687508\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 686 ==========\n","Right -> Down -> Left -> Down -> Up -> Down -> Right -> Right -> Up -> Left -> Down -> Right -> Left -> Right -> Down -> Up -> Up -> Down -> Up -> Right -> Left -> Down -> Left -> Down -> Left -> Right -> Down -> Left -> Down -> Down -> Left -> Right -> \n","Left :  0.12732261  Down :  0.10764025  Right :  0.012489222  Up :  0.14398895\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 687 ==========\n","Left -> Left -> Right -> Down -> Right -> Right -> Left -> Left -> Down -> Down -> Down -> Right -> Left -> Down -> \n","Left :  0.12399021  Down :  -0.0056504533  Right :  0.1304148  Up :  -0.0069342554\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 688 ==========\n","Down -> Right -> Right -> Left -> Right -> Right -> Down -> \n","Left :  0.14304985  Down :  -0.0045784935  Right :  0.16096702  Up :  0.07272874\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 689 ==========\n","Right -> Left -> Down -> Right -> Down -> Left -> Up -> Right -> Left -> Left -> Left -> Right -> Left -> Left -> Down -> Up -> Down -> Right -> Left -> Left -> Right -> Right -> Up -> Down -> Left -> Right -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.11469859  Down :  0.12341469  Right :  -0.0037756935  Up :  0.13856342\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 690 ==========\n","Right -> Down -> Right -> Down -> Left -> Right -> Left -> Right -> Down -> Right -> Left -> Down -> Right -> \n","Left :  0.09239949  Down :  -0.0014892966  Right :  -0.015496954  Up :  0.11639657\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 691 ==========\n","Down -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> \n","Left :  0.11940702  Down :  0.053188294  Right :  0.16770844  Up :  0.062048078\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 691 중간평가 ==========\n","Right -> Right -> Right -> Down -> Right -> Down -> Down -> Down -> Right -> Right -> Right -> Down -> Down -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.10610342  Down :  0.20545244  Right :  0.20906189  Up :  0.15217032\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFH\u001b[41mF\u001b[0m\n","FFFHFFFG\n","\n","========== Episode 692 ==========\n","Right -> Right -> Down -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.15554838  Down :  0.005441822  Right :  0.18452895  Up :  0.020497132\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 693 ==========\n","Right -> Left -> Down -> Right -> Left -> Down -> Down -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> \n","Left :  0.08580738  Down :  0.0022787526  Right :  -0.002488099  Up :  0.107079074\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 694 ==========\n","Down -> Right -> Left -> Right -> Right -> Right -> Right -> Right -> Left -> Right -> Right -> Right -> Left -> Left -> Down -> Down -> \n","Left :  0.1288208  Down :  0.046481676  Right :  0.17263123  Up :  0.05879646\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 695 ==========\n","Down -> Down -> Right -> Right -> Right -> \n","Left :  0.107266456  Down :  0.13645586  Right :  -0.0018813163  Up :  0.13310258\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 696 ==========\n","Right -> Right -> Left -> Down -> Down -> Down -> Down -> Right -> Right -> \n","Left :  0.08559497  Down :  -0.00730744  Right :  -0.01556465  Up :  0.11351104\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 697 ==========\n","Left -> Left -> Down -> Right -> Down -> Right -> Left -> Down -> Right -> Left -> Down -> Down -> \n","Left :  0.0875395  Down :  -0.0022752136  Right :  0.09801939  Up :  -0.016462963\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 698 ==========\n","Left -> Left -> Right -> Down -> Down -> Down -> Right -> Left -> Left -> Right -> Down -> Down -> \n","Left :  0.08644846  Down :  -0.00019282103  Right :  0.09860197  Up :  -0.014920097\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 699 ==========\n","Left -> Right -> Left -> Right -> Right -> Left -> Right -> Left -> Left -> Right -> Right -> Down -> Right -> Left -> Left -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> \n","Left :  0.10107968  Down :  -0.0025285035  Right :  0.12750396  Up :  0.06453254\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 700 ==========\n","Right -> Right -> Down -> Right -> Right -> Left -> Right -> Down -> Left -> \n","Left :  0.093997374  Down :  0.14907598  Right :  0.14992845  Up :  0.1315074\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 701 ==========\n","Right -> Down -> Down -> Right -> Left -> Right -> Right -> \n","Left :  0.11092401  Down :  0.109731756  Right :  0.0027645305  Up :  0.115427084\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 701 중간평가 ==========\n","Right -> Right -> Right -> Right -> Down -> Right -> Down -> Right -> Down -> Right -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> \n","Left :  0.1845485  Down :  0.22019881  Right :  0.17089194  Up :  0.17560622\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHF\u001b[41mF\u001b[0m\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 702 ==========\n","Down -> Right -> Down -> Left -> Right -> Right -> Left -> Right -> Up -> Left -> Right -> Down -> Right -> \n","Left :  0.09014441  Down :  0.101975285  Right :  0.0051404387  Up :  0.108181134\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 703 ==========\n","Right -> Down -> Left -> Left -> Right -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.14237311  Down :  0.18035945  Right :  -0.0005410835  Up :  0.14634182\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 704 ==========\n","Left -> Down -> Down -> Left -> Up -> Down -> Up -> Left -> Left -> Down -> Up -> Down -> Left -> Up -> Down -> Up -> Down -> Up -> Right -> Down -> Down -> Right -> Left -> Left -> Right -> Right -> Right -> Right -> Left -> Left -> Down -> Right -> \n","Left :  0.09577582  Down :  0.021241449  Right :  -0.0070161447  Up :  0.12303272\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 705 ==========\n","Left -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.11427479  Down :  0.13387462  Right :  -0.0010176674  Up :  0.13881962\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 706 ==========\n","Down -> Left -> Down -> Up -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> Right -> Down -> \n","Left :  0.120215915  Down :  -0.0009888262  Right :  0.16153473  Up :  0.0086412355\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 707 ==========\n","Right -> Right -> Right -> Left -> Right -> Down -> Right -> Right -> Down -> Right -> Down -> Right -> Right -> Left -> Down -> Right -> Right -> Down -> Left -> \n","Left :  0.040816043  Down :  0.089980066  Right :  0.14410338  Up :  0.12234084\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 708 ==========\n","Down -> Right -> Right -> Right -> Down -> \n","Left :  0.10006873  Down :  0.0021527708  Right :  0.12297898  Up :  0.06896263\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 709 ==========\n","Right -> Right -> Left -> Left -> Down -> Down -> Down -> Down -> Left -> Down -> Down -> Right -> \n","Left :  0.095791504  Down :  0.101358466  Right :  0.025088042  Up :  0.09870343\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 710 ==========\n","Up -> Down -> Right -> Down -> Down -> Left -> Right -> Right -> Left -> Right -> Right -> Down -> \n","Left :  0.124176756  Down :  -0.0018195212  Right :  0.15726706  Up :  0.008687217\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 711 ==========\n","Right -> Left -> Down -> Down -> Down -> Up -> Left -> Down -> Up -> Down -> Left -> Right -> Right -> Right -> Down -> \n","Left :  0.110872306  Down :  0.024248146  Right :  0.14284882  Up :  0.011563055\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 711 중간평가 ==========\n","******** SUCCESS ********\n","Right -> Right -> Right -> Right -> Down -> Down -> Right -> Right -> Down -> Right -> Down -> Down -> Down -> Down -> \n","Left :  0.1299195  Down :  0.15815309  Right :  0.12843977  Up :  0.12909216\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 712 ==========\n","Right -> Right -> Right -> Left -> Left -> Down -> Left -> Down -> Down -> Left -> Up -> Left -> Left -> Right -> Right -> Right -> \n","Left :  0.088556945  Down :  0.11843521  Right :  0.0068842843  Up :  0.11470559\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 713 ==========\n","Down -> Down -> Down -> Up -> Left -> Right -> Down -> Down -> Down -> \n","Left :  0.095707804  Down :  -0.0042900294  Right :  0.09479883  Up :  -0.016735848\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 714 ==========\n","Up -> Left -> Down -> Down -> Right -> Right -> Down -> Right -> Down -> \n","Left :  0.1160329  Down :  0.01200524  Right :  0.14408758  Up :  0.004612606\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 715 ==========\n","Left -> Right -> Right -> Right -> Right -> Down -> Right -> Left -> Right -> Down -> Down -> \n","Left :  0.12396936  Down :  0.021387681  Right :  0.17362088  Up :  0.041754216\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 716 ==========\n","Right -> Left -> Down -> Down -> Left -> Right -> Left -> Left -> Down -> Down -> Down -> Down -> Left -> Down -> Down -> Down -> Down -> Down -> Down -> Right -> Down -> Right -> Left -> Down -> Left -> Right -> Down -> Down -> Down -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.10822236  Down :  0.15831783  Right :  -0.021455877  Up :  0.116541\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 717 ==========\n","Down -> Left -> Down -> Left -> Left -> Right -> Right -> Down -> Down -> Down -> \n","Left :  0.094543934  Down :  -0.023729213  Right :  0.0052431226  Up :  0.10032889\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 718 ==========\n","Up -> Left -> Down -> Up -> Up -> Up -> Up -> Down -> Down -> Left -> Down -> Right -> Down -> Down -> \n","Left :  0.14096808  Down :  -0.03839305  Right :  0.109832615  Up :  -0.03177153\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 719 ==========\n","Down -> Down -> Down -> Down -> Right -> Down -> \n","Left :  0.14627938  Down :  -0.041603133  Right :  0.1239799  Up :  -0.0368286\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 720 ==========\n","Left -> Up -> Left -> Left -> Right -> Left -> Right -> Left -> Right -> Down -> Right -> Left -> Right -> Right -> Left -> Left -> Left -> Down -> Right -> Left -> Down -> Up -> Down -> Left -> Left -> Left -> Right -> Down -> Right -> Up -> Right -> Down -> \n","Left :  0.1299875  Down :  0.03372938  Right :  0.1160067  Up :  0.05479095\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 721 ==========\n","Right -> Right -> Down -> Down -> Right -> \n","Left :  0.1433222  Down :  0.15565291  Right :  0.009843491  Up :  0.1681203\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 721 중간평가 ==========\n","Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.13887264  Down :  0.13471001  Right :  0.14354837  Up :  0.1506846\n","  (Up)\n","\u001b[41mS\u001b[0mFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 722 ==========\n","Down -> Right -> Left -> Up -> Up -> Right -> Right -> Right -> Right -> Left -> Right -> Down -> Right -> Down -> Left -> Left -> \n","Left :  0.11906019  Down :  0.1633545  Right :  0.18446812  Up :  0.18526599\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 723 ==========\n","Right -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> \n","Left :  0.13858794  Down :  0.11215532  Right :  0.30103615  Up :  0.14886737\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 724 ==========\n","******** SUCCESS ********\n","Left -> Left -> Right -> Left -> Down -> Right -> Right -> Right -> Right -> Left -> Left -> Right -> Left -> Left -> Right -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Right -> Right -> Down -> Down -> Down -> \n","Left :  0.2926293  Down :  0.49718595  Right :  0.4378091  Up :  0.36476833\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 725 ==========\n","Down -> Left -> Left -> Down -> Down -> Down -> Down -> Left -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> Right -> Left -> Down -> Right -> Right -> Left -> Down -> Left -> Down -> Down -> Right -> Right -> Down -> Right -> \n","Left :  0.16140325  Down :  0.17727207  Right :  0.00027308613  Up :  0.17121412\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 726 ==========\n","Down -> Right -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.13196522  Down :  -0.027328491  Right :  -0.0401323  Up :  0.1632\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 727 ==========\n","Left -> Down -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Left -> Down -> Up -> Down -> Up -> Left -> Down -> Down -> Right -> Right -> Down -> \n","Left :  0.11058613  Down :  -0.00741145  Right :  0.14930646  Up :  0.027463574\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 728 ==========\n","Down -> Right -> Right -> Right -> Right -> Left -> Down -> \n","Left :  0.17731112  Down :  -0.0066403076  Right :  0.21472353  Up :  0.09227699\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 729 ==========\n","Down -> Right -> Right -> Right -> Down -> \n","Left :  0.18826395  Down :  -0.017237954  Right :  0.22388071  Up :  0.097625926\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 730 ==========\n","Down -> Right -> Down -> Down -> Left -> Down -> Left -> Left -> Left -> Left -> Left -> Left -> Left -> Right -> Right -> Left -> Down -> \n","Left :  0.11605874  Down :  0.029177576  Right :  0.13225138  Up :  0.054523688\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 731 ==========\n","Down -> Right -> Down -> Left -> Right -> Left -> Left -> Down -> Left -> Down -> Down -> Up -> Right -> Down -> \n","Left :  0.12763721  Down :  -0.031962164  Right :  0.1358643  Up :  0.03028638\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 731 중간평가 ==========\n","Down -> Right -> Right -> Right -> Right -> Right -> Up -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.23571631  Down :  0.26982424  Right :  0.27016002  Up :  0.27022222\n","  (Up)\n","SFFFFF\u001b[41mF\u001b[0mF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 732 ==========\n","Right -> Left -> Left -> Down -> Right -> Down -> Right -> Down -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Left -> \n","Left :  0.026591428  Down :  0.22385597  Right :  0.33065116  Up :  0.11780664\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 733 ==========\n","Down -> Down -> Left -> Left -> Right -> Left -> Left -> Right -> Right -> Up -> Right -> Right -> Right -> Left -> Right -> Right -> Down -> Right -> Left -> Left -> Right -> Down -> Right -> Left -> Down -> Down -> \n","Left :  0.3267859  Down :  0.04347168  Right :  0.403243  Up :  0.16657098\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 734 ==========\n","Left -> Down -> Left -> Right -> Down -> Right -> Right -> \n","Left :  0.15166803  Down :  0.16138068  Right :  0.0027827322  Up :  0.18194407\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 735 ==========\n","Right -> Left -> Left -> Left -> Right -> Left -> Down -> Right -> Left -> Right -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> Right -> Down -> Down -> Right -> Down -> Left -> \n","Left :  0.03486622  Down :  0.48111954  Right :  0.43663248  Up :  0.31172857\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 736 ==========\n","Down -> Right -> Right -> Right -> Left -> Right -> Down -> \n","Left :  0.23576194  Down :  0.02888199  Right :  0.25694406  Up :  0.12484644\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 737 ==========\n","Left -> Right -> Right -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Down -> Down -> Up -> Left -> Left -> Right -> Right -> Left -> Down -> Right -> Up -> Down -> Up -> Right -> Right -> Down -> Down -> Down -> Left -> \n","Left :  0.046888407  Down :  0.20575449  Right :  0.30588067  Up :  0.12003443\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 738 ==========\n","Down -> Left -> Right -> Left -> Right -> Right -> Right -> Down -> \n","Left :  0.19078884  Down :  0.021027848  Right :  0.2403291  Up :  0.10065413\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 739 ==========\n","Up -> Down -> Down -> Right -> Left -> Up -> Right -> Left -> Up -> Down -> Left -> Down -> Left -> Up -> Up -> Down -> Down -> Up -> Right -> Right -> Right -> Right -> Right -> Up -> Left -> Left -> Down -> Left -> Right -> Left -> Right -> Left -> Right -> Down -> \n","Left :  0.27353096  Down :  0.009152606  Right :  0.28358525  Up :  0.144158\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 740 ==========\n","Right -> Right -> Down -> Right -> Left -> Right -> Left -> Left -> Right -> Right -> Left -> Down -> Up -> Left -> Right -> Right -> Down -> \n","Left :  0.23595919  Down :  0.0065727755  Right :  0.27453873  Up :  0.12163875\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 741 ==========\n","Down -> Down -> Up -> Left -> Left -> Down -> Up -> Right -> Right -> Left -> Left -> Up -> Left -> Left -> Down -> Right -> Right -> Right -> Right -> Down -> Down -> Down -> Right -> Right -> Left -> Left -> Down -> Right -> Left -> Right -> Down -> Right -> \n","Left :  0.16856629  Down :  0.12785679  Right :  0.008651957  Up :  0.1727216\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 741 중간평가 ==========\n","Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.19671035  Down :  0.20153514  Right :  0.21162023  Up :  0.21393894\n","  (Up)\n","\u001b[41mS\u001b[0mFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 742 ==========\n","Right -> Down -> Right -> Down -> Left -> Left -> Right -> Right -> Down -> Down -> Left -> Right -> Left -> Right -> Left -> Right -> Left -> Left -> Left -> Down -> Down -> Left -> Left -> Left -> Left -> Left -> Right -> \n","Left :  0.14351079  Down :  0.11099873  Right :  0.053370267  Up :  0.09190077\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 743 ==========\n","Left -> Left -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Right -> Down -> Down -> Left -> Right -> Right -> Right -> Down -> Down -> Left -> \n","Left :  0.09092485  Down :  0.48179197  Right :  0.44035703  Up :  0.27187133\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 744 ==========\n","Up -> Down -> Right -> Right -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> Right -> \n","Left :  0.20927387  Down :  0.24405892  Right :  -0.02991566  Up :  0.23535553\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 745 ==========\n","Down -> Up -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Left -> Up -> Right -> Right -> Right -> Right -> Down -> Down -> Left -> \n","Left :  0.2440429  Down :  0.25397062  Right :  0.3311724  Up :  0.26822814\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 746 ==========\n","Right -> Right -> Right -> Left -> Right -> Down -> Right -> Right -> Left -> Left -> Right -> Right -> Down -> Left -> Right -> Down -> \n","Left :  0.25305963  Down :  -0.023882888  Right :  0.33593404  Up :  0.07360521\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 747 ==========\n","Right -> Right -> Down -> Down -> Left -> Left -> Down -> Right -> Down -> Right -> Up -> Right -> Right -> Left -> Right -> Left -> Right -> Down -> Left -> \n","Left :  -0.07654715  Down :  0.32858056  Right :  0.42832989  Up :  0.1229613\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 748 ==========\n","Right -> Right -> Left -> Left -> Down -> Left -> Right -> Right -> Right -> Down -> \n","Left :  0.31059578  Down :  -0.004811667  Right :  0.35143107  Up :  0.11550057\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 749 ==========\n","Right -> Down -> Right -> Right -> Down -> \n","Left :  0.30602148  Down :  0.0044372156  Right :  0.38241264  Up :  0.11456992\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 750 ==========\n","Right -> Down -> Left -> Left -> Left -> Left -> Down -> Down -> Down -> Down -> Right -> \n","Left :  0.24844663  Down :  0.3153959  Right :  -0.0069317967  Up :  0.2997158\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 751 ==========\n","Right -> Right -> Down -> Right -> Left -> Right -> Down -> \n","Left :  0.33566803  Down :  0.01904758  Right :  0.4168895  Up :  0.1509879\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 751 중간평가 ==========\n","******** SUCCESS ********\n","Right -> Right -> Right -> Right -> Right -> Right -> Right -> Down -> Down -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.23206028  Down :  0.5600491  Right :  0.5154277  Up :  0.3823936\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 752 ==========\n","Left -> Down -> Left -> Left -> Right -> Right -> Right -> Left -> Right -> Right -> Left -> Right -> Down -> Right -> Left -> Down -> Up -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Left -> Down -> Up -> Left -> \n","Left :  0.28483352  Down :  0.25484306  Right :  0.3802504  Up :  0.32745048\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 753 ==========\n","Left -> Left -> Down -> Left -> Right -> Right -> Down -> Down -> Down -> Up -> Right -> Right -> Right -> \n","Left :  0.3070008  Down :  0.3843134  Right :  0.05093065  Up :  0.2912166\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 754 ==========\n","Left -> Left -> Down -> Right -> Down -> Down -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> \n","Left :  0.5829444  Down :  -0.087572925  Right :  0.7158723  Up :  0.19109768\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 755 ==========\n","******** SUCCESS ********\n","Right -> Right -> Right -> Right -> Up -> Right -> Right -> Left -> Right -> Left -> Right -> Left -> Right -> Down -> Down -> Down -> Right -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.17773597  Down :  0.41703632  Right :  0.4375084  Up :  0.31910402\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 756 ==========\n","Right -> Right -> Right -> Right -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Left -> Left -> Right -> Left -> Right -> Right -> Down -> Right -> Right -> Left -> Down -> Down -> \n","Left :  0.44307616  Down :  -0.11007921  Right :  0.5427828  Up :  0.08991064\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 757 ==========\n","Right -> Right -> Down -> Right -> Left -> Left -> Left -> Right -> Right -> Left -> Right -> Down -> Down -> Left -> Down -> Down -> \n","Left :  0.18212746  Down :  -0.015103355  Right :  0.17728113  Up :  0.042540863\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 758 ==========\n","Down -> Right -> Right -> Left -> Down -> Right -> Left -> Down -> Right -> Left -> Down -> Left -> Down -> Left -> Left -> Left -> Right -> \n","Left :  0.18637308  Down :  0.16971707  Right :  0.019211829  Up :  0.15905517\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 759 ==========\n","Right -> Down -> Down -> Right -> Down -> Right -> Left -> Left -> Right -> Right -> Right -> Down -> Left -> \n","Left :  -0.006356895  Down :  0.27882776  Right :  0.37038255  Up :  0.13618886\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 760 ==========\n","Right -> Left -> Right -> Right -> Right -> Right -> Right -> Right -> Left -> Down -> Down -> Right -> Down -> Down -> Left -> Left -> Right -> Left -> Right -> Left -> Left -> \n","Left :  0.00059307367  Down :  0.27973905  Right :  0.36691463  Up :  0.13911319\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 761 ==========\n","Right -> Down -> Right -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.30845234  Down :  0.4101923  Right :  0.0083875805  Up :  0.31151938\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 761 중간평가 ==========\n","Right -> Right -> Right -> Right -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> Up -> \n","Left :  0.25396028  Down :  0.27113655  Right :  0.27536392  Up :  0.27889377\n","  (Up)\n","SFFF\u001b[41mF\u001b[0mFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 762 ==========\n","Left -> Down -> Left -> Right -> Down -> Right -> Down -> Down -> Down -> \n","Left :  0.14996666  Down :  -0.030393735  Right :  -0.021352842  Up :  0.22457512\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 763 ==========\n","Down -> Left -> Right -> Right -> Down -> Right -> \n","Left :  0.20474893  Down :  0.27173316  Right :  -0.0006546229  Up :  0.23279501\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 764 ==========\n","Left -> Right -> Right -> Down -> Down -> Down -> Right -> Left -> Right -> Right -> Right -> \n","Left :  0.26161283  Down :  0.43518728  Right :  -0.0150487125  Up :  0.31815657\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 765 ==========\n","Right -> Left -> Right -> Right -> Left -> Left -> Down -> Right -> Down -> Down -> Left -> Down -> Down -> Up -> Right -> Right -> Up -> Left -> Down -> Down -> \n","Left :  0.214652  Down :  -0.011933953  Right :  0.2388871  Up :  0.039075814\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 766 ==========\n","Left -> Down -> Down -> Left -> Left -> Left -> Left -> Down -> Left -> Left -> Right -> Down -> Down -> \n","Left :  0.229899  Down :  -0.009557202  Right :  0.24589765  Up :  0.04051667\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 767 ==========\n","Right -> Left -> Down -> Left -> Down -> Down -> Right -> Right -> Right -> Left -> Down -> Left -> Down -> \n","Left :  0.18028727  Down :  0.017728135  Right :  0.2318655  Up :  0.052390978\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 768 ==========\n","Down -> Right -> Right -> Down -> Right -> \n","Left :  0.2593699  Down :  0.3337587  Right :  0.0036977082  Up :  0.30517742\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 769 ==========\n","Right -> Left -> Left -> Down -> Right -> Down -> Left -> Left -> Down -> Down -> Left -> Right -> Right -> Left -> Right -> Right -> \n","Left :  0.25378668  Down :  -0.022233725  Right :  -0.003886804  Up :  0.3182156\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 770 ==========\n","Right -> Right -> Down -> Down -> Left -> Left -> Down -> Right -> Left -> Right -> Down -> Right -> Left -> Right -> Up -> Down -> Right -> \n","Left :  0.26235595  Down :  -0.02969499  Right :  -0.009223014  Up :  0.31729564\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 771 ==========\n","Right -> Left -> Down -> Down -> Down -> Left -> Right -> Down -> Left -> Right -> Left -> Left -> Left -> Down -> Up -> Down -> Left -> Down -> Up -> Down -> Down -> Right -> Down -> Right -> Up -> Right -> Down -> \n","Left :  0.21638322  Down :  0.238431  Right :  0.17301567  Up :  0.20679933\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFF\u001b[41mH\u001b[0mFFFG\n","\n","========== Episode 771 중간평가 ==========\n","Down -> Down -> Down -> Right -> Right -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Down -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.026296318  Down :  0.4203524  Right :  0.44088456  Up :  0.20237115\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFH\u001b[41mF\u001b[0m\n","FFFHFFFG\n","\n","========== Episode 772 ==========\n","Down -> Right -> Left -> Down -> Down -> Left -> Left -> Right -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Right -> \n","Left :  0.32066017  Down :  0.32639068  Right :  0.051179722  Up :  0.29508045\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 773 ==========\n","Right -> Down -> Right -> Down -> Down -> Left -> Left -> Right -> Left -> Left -> Right -> Right -> Left -> Right -> Left -> Right -> Right -> Left -> Left -> Right -> Left -> Down -> Right -> Down -> \n","Left :  0.21438898  Down :  -0.02826193  Right :  0.004603386  Up :  0.30647245\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 774 ==========\n","Right -> Down -> Left -> Down -> Left -> Down -> Right -> Down -> Left -> Down -> Left -> Right -> \n","Left :  0.23926082  Down :  0.23460159  Right :  0.009248361  Up :  0.2822528\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 775 ==========\n","Down -> Down -> Left -> Down -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.3380528  Down :  0.34180242  Right :  0.04987692  Up :  0.30272523\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 776 ==========\n","Down -> Down -> Right -> Right -> Left -> Down -> Down -> Right -> Up -> Down -> Up -> Right -> Left -> Left -> Left -> Right -> Right -> Right -> Left -> Down -> Left -> Down -> \n","Left :  0.22707331  Down :  -0.057670847  Right :  0.2743973  Up :  -0.029538564\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 777 ==========\n","Down -> Right -> Right -> Down -> Down -> Down -> Right -> \n","Left :  0.25073677  Down :  0.024961546  Right :  0.022643775  Up :  0.31625745\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 778 ==========\n","Right -> Down -> Right -> Down -> Up -> Down -> Up -> Down -> Left -> Down -> Right -> Right -> Left -> Right -> Down -> \n","Left :  0.28765178  Down :  0.025434688  Right :  0.26876634  Up :  0.041242823\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 779 ==========\n","Down -> Left -> Down -> Down -> Down -> Down -> Right -> \n","Left :  0.27287376  Down :  0.20162565  Right :  -0.03201154  Up :  0.2873884\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 780 ==========\n","Right -> Left -> Right -> Down -> Down -> Right -> Down -> Right -> Right -> Right -> \n","Left :  0.36560073  Down :  0.37814906  Right :  0.097957775  Up :  0.312671\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 781 ==========\n","Left -> Down -> Left -> Down -> Down -> Left -> Right -> Right -> Right -> Left -> Right -> Right -> Right -> \n","Left :  0.27742505  Down :  0.2970616  Right :  0.054526232  Up :  0.28512168\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 781 중간평가 ==========\n","Right -> Down -> Right -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> Up -> Down -> \n","Left :  0.2276162  Down :  0.24369359  Right :  0.23038244  Up :  0.20754641\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FF\u001b[41mF\u001b[0mHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 782 ==========\n","Down -> Right -> Down -> Right -> Left -> Left -> Right -> Down -> Left -> Right -> Down -> Right -> Up -> Down -> Up -> Down -> Up -> Right -> Right -> Down -> Down -> Right -> Down -> Right -> \n","Left :  0.2186372  Down :  0.24576283  Right :  0.02188477  Up :  0.2126371\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 783 ==========\n","Down -> Down -> Right -> Right -> Left -> Right -> Down -> Left -> Left -> Right -> Down -> Right -> Left -> Right -> Down -> \n","Left :  0.20919979  Down :  0.028209433  Right :  -0.009190768  Up :  0.30730265\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 784 ==========\n","Down -> Down -> Left -> Down -> Right -> Right -> Down -> Left -> Down -> \n","Left :  0.21276625  Down :  -0.0056743175  Right :  0.27665377  Up :  0.03636741\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 785 ==========\n","Down -> Left -> Left -> Down -> Down -> Down -> Down -> Right -> \n","Left :  0.25833887  Down :  0.20011829  Right :  -0.02614221  Up :  0.3002371\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 786 ==========\n","Down -> Down -> Left -> Down -> Left -> Down -> Down -> Up -> Right -> Right -> Right -> \n","Left :  0.26384434  Down :  0.012546092  Right :  -0.027694285  Up :  0.34105104\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 787 ==========\n","Down -> Down -> Down -> Right -> Left -> Left -> Right -> Down -> Down -> \n","Left :  0.2171602  Down :  -0.0054326653  Right :  0.30432546  Up :  0.021640092\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 788 ==========\n","Down -> Left -> Right -> Right -> Down -> Down -> Down -> Left -> Left -> Down -> Down -> Left -> Right -> \n","Left :  0.301378  Down :  0.24373195  Right :  -0.016173989  Up :  0.25121102\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","F\u001b[41mH\u001b[0mFFHFHF\n","FFFHFFFG\n","\n","========== Episode 789 ==========\n","Right -> Right -> Right -> Right -> Down -> Right -> Right -> Down -> Left -> Down -> \n","Left :  0.25674456  Down :  -0.04707299  Right :  0.34744  Up :  0.046522364\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFF\u001b[41mH\u001b[0mFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 790 ==========\n","Down -> Left -> Left -> Left -> Left -> Right -> Right -> Down -> Down -> Right -> Right -> Down -> Left -> \n","Left :  0.07986914  Down :  0.18862976  Right :  0.24616542  Up :  0.092048034\n","  (Left)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 791 ==========\n","Down -> Right -> Down -> Left -> Left -> Left -> Down -> Right -> Right -> Left -> Down -> Left -> Down -> Left -> Left -> Right -> \n","Left :  0.19392243  Down :  0.20812368  Right :  0.020122975  Up :  0.17958467\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","F\u001b[41mH\u001b[0mHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 791 중간평가 ==========\n","******** SUCCESS ********\n","Down -> Right -> Right -> Down -> Down -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Down -> Down -> \n","Left :  -0.07458259  Down :  1.1343056  Right :  0.8334271  Up :  0.4857154\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 792 ==========\n","Down -> Down -> Down -> Left -> Right -> Left -> Right -> Down -> Right -> Down -> \n","Left :  0.21701059  Down :  0.034884937  Right :  -0.003331393  Up :  0.1788913\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FH\u001b[41mH\u001b[0mFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 793 ==========\n","Right -> Right -> Right -> Down -> Right -> Down -> Down -> Down -> Down -> Right -> Down -> Right -> \n","Left :  0.30290323  Down :  0.34123242  Right :  0.022085324  Up :  0.25038627\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHF\u001b[41mH\u001b[0mF\n","FFFHFFFG\n","\n","========== Episode 794 ==========\n","Right -> Right -> Left -> Right -> Left -> Down -> Right -> Down -> Up -> Right -> Left -> Down -> Right -> \n","Left :  0.1926605  Down :  0.24017441  Right :  -0.00028853118  Up :  0.24746989\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 795 ==========\n","Down -> Down -> Down -> Down -> Right -> Right -> Right -> \n","Left :  0.28091076  Down :  0.040506706  Right :  -0.013437048  Up :  0.2643439\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 796 ==========\n","******** SUCCESS ********\n","Right -> Down -> Right -> Right -> Right -> Right -> Right -> Down -> Left -> Right -> Right -> Down -> Down -> Down -> Down -> Down -> \n","Left :  0.19316518  Down :  0.75201553  Right :  0.7489606  Up :  0.47849095\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFF\u001b[41mG\u001b[0m\n","\n","========== Episode 797 ==========\n","Left -> Down -> Up -> Left -> Right -> Right -> Down -> Right -> Right -> Right -> Down -> Right -> Left -> Right -> Right -> Down -> Down -> Left -> Down -> \n","Left :  0.531033  Down :  -0.2330678  Right :  0.7006198  Up :  0.07408546\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFF\u001b[41mH\u001b[0mF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 798 ==========\n","Left -> Right -> Down -> Left -> Right -> Down -> Down -> Right -> Right -> Down -> \n","Left :  0.34788007  Down :  -0.02317749  Right :  0.4089744  Up :  0.086769655\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 799 ==========\n","Right -> Down -> Right -> Down -> Left -> Right -> Left -> Down -> Right -> Right -> Right -> Left -> Down -> \n","Left :  0.3182516  Down :  -0.0626699  Right :  0.3248948  Up :  0.021941133\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 800 ==========\n","Right -> Right -> Left -> Left -> Left -> Left -> Right -> Right -> Down -> Left -> Right -> Right -> Down -> \n","Left :  0.41601482  Down :  -0.010428026  Right :  0.57908964  Up :  0.13737181\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 801 ==========\n","Down -> Right -> Right -> Left -> Right -> Right -> Down -> \n","Left :  0.53641456  Down :  -0.0025860667  Right :  0.7059853  Up :  0.1732499\n","  (Down)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 801 중간평가 ==========\n","Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> Right -> \n","Left :  0.55304635  Down :  0.6666043  Right :  0.73969436  Up :  0.59030485\n","  (Right)\n","SFFFFFF\u001b[41mF\u001b[0m\n","FFFFFFFF\n","FFFHFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n","========== Episode 802 ==========\n","Up -> Up -> Left -> Left -> Down -> Right -> Right -> Left -> Right -> Down -> Right -> \n","Left :  0.33208025  Down :  0.3836739  Right :  -0.095565215  Up :  0.5816723\n","  (Right)\n","SFFFFFFF\n","FFFFFFFF\n","FFF\u001b[41mH\u001b[0mFFFF\n","FFFFFHFF\n","FFFHFFFF\n","FHHFFFHF\n","FHFFHFHF\n","FFFHFFFG\n","\n"]}],"source":["from re import escape\n","from threading import active_count\n","import os\n","import gym\n","import tensorflow as tf\n","import numpy as np\n","import random\n","from collections import deque\n","\n","# 뉴럴 네트워크 모델 만들기\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(128, input_dim=64, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n","    tf.keras.layers.Dense(4, activation='linear')\n","])\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam',\n","              loss='mse')\n","\n","score = []\n","memory = deque(maxlen=50000)\n","\n","\n","# FrozenLake8x8 환경 구성\n","env = gym.make('FrozenLake8x8-v0',is_slippery=False)\n","eps = 1\n","\n","answer_queue = []\n","\n","move_list = ['Left', 'Down','Right','Up']\n","\n","# 10000회 에피소드 시작\n","for i in range(10000):\n","    print(\"========== Episode {} ==========\".format(i+1))\n","    state_num = env.reset()\n","    state_arr = np.zeros(64)\n","    state_arr[state_num] = 1\n","    state = np.reshape(state_arr, [1, 64])\n","    answer_queue.clear()\n","\n","    if eps > 0.01:\n","      eps *= 0.9995\n","\n","    # 100 timesteps\n","\n","    for t in range(100):\n","\n","        if np.random.rand() < eps:\n","            action = np.random.randint(0, 3)\n","        else:\n","            predict = model.predict(state)\n","            action = np.argmax(predict)\n","\n","        next_state_num, reward, done, _ = env.step(action)\n","        \n","        next_state_arr = np.zeros(64)\n","        next_state_arr[next_state_num] = 1\n","        next_state = np.reshape(next_state_arr, [1, 64])\n","\n","        answer_queue.append(move_list[action])\n","        memory.append((state, action, reward, next_state, done))\n","\n","        if done or t == 99:\n","            if next_state_num == 63:\n","              print(\"******** SUCCESS ********\")\n","\n","            for k in answer_queue:\n","              print(k + ' -> ', end='')\n","            print('')\n","\n","            x = model.predict(state)[0]\n","            print('Left : ', x[0], ' Down : ', x[1] , ' Right : ', x[2] , ' Up : ', x[3])\n","            env.render()\n","            print('')\n","            break\n","\n","        state = next_state.copy()\n","        state_num = next_state_num\n","\n","\n","    if i % 10 == 0:\n","      \n","      print(\"========== Episode {} 중간평가 ==========\".format(i+1))\n","      state_num = env.reset()\n","      state_arr = np.zeros(64)\n","      state_arr[state_num] = 1\n","      state = np.reshape(state_arr, [1, 64])\n","      answer_queue.clear()\n","\n","      for t in range(50):\n","         predict = model.predict(state)\n","         action = np.argmax(predict)\n","         next_state_num, reward, done, _ = env.step(action)\n","        \n","         next_state_arr = np.zeros(64)\n","         next_state_arr[next_state_num] = 1\n","         next_state = np.reshape(next_state_arr, [1, 64])\n","\n","         answer_queue.append(move_list[action])\n","         \n","\n","         if done or t == 49:\n","            if next_state_num == 63:\n","              print(\"******** SUCCESS ********\")\n","\n","            for k in answer_queue:\n","                print(k + ' -> ', end='')\n","            print('')\n","\n","            x = model.predict(state)[0]\n","            print('Left : ', x[0], ' Down : ', x[1] , ' Right : ', x[2] , ' Up : ', x[3])\n","            env.render()\n","            print('')\n","            break\n","\n","         state = next_state.copy()\n","         state_num = next_state_num\n","\n","    # Training\n","    if i > 500:\n","        minibatch = random.sample(memory, 64)\n","\n","        for state, action, reward, next_state, done in minibatch:\n","            target = reward\n","            if not done:\n","                target = reward + 0.9 * np.amax(model.predict(next_state)[0])\n","            target_outputs = model.predict(state)\n","            target_outputs[0][action] = target\n","            model.fit(state, target_outputs, epochs=1, verbose=0)\n","\n","env.close()"]},{"cell_type":"markdown","metadata":{"id":"XOGBsP48Tdji"},"source":["## # 미로찾기 6 (사용 불가)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":722},"executionInfo":{"elapsed":18719,"status":"error","timestamp":1653742666763,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"},"user_tz":-540},"id":"oifcHbWbVAMM","outputId":"5bf604d7-05ed-46f7-c9ca-e58fbea70cee"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","total call vs corrected answer : 0 0\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-661f13a187a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg_cntr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mg_data_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             \u001b[0maction_ga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_ga\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mga_th\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_resource_ga\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m             \u001b[0;31m#print(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_ga\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-661f13a187a9>\u001b[0m in \u001b[0;36moptimize_resource_ga\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m#print(ga_comb_temp[itr1],P_macro_subband)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mgenerate_power_matrix_macro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0mthroughput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-661f13a187a9>\u001b[0m in \u001b[0;36mgenerate_power_matrix_macro\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_subband\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mpw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_macro_subband\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mpw_R\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtransmit_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthita\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthita_3db\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_watt_dbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0mU_received_power_subband\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpw_m_hata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpw_R\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU_macro_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-661f13a187a9>\u001b[0m in \u001b[0;36mtransmit_power\u001b[0;34m(thita, thita_3db, Am, power_dbm)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransmit_power\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthita\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthita_3db\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_dbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthita\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mthita_3db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mg_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpower_dbm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mg_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamin\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \"\"\"\n\u001b[1;32m   2879\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out,\n\u001b[0;32m-> 2880\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# This branch is needed for reductions like any which don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# library\n","\n","import sys\n","\n","import math as mt\n","import numpy as np\n","\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","\n","# function definition\n","\n","def circle(x, y,r):\n","    ang=np.arange(0, 2*mt.pi, 0.01)\n","    xp=r*np.cos(ang)\n","    yp=r*np.sin(ang)\n","    plt.plot(x+xp,y+yp)\n","    return\n","\n","def random_beam():\n","    x=[]\n","    x.append(60)\n","    x.append((60+120)%360)\n","    x.append((60-120)%360)\n","    return x\n","\n","def point_d(thita,x1,y1,l):\n","    x2=[]\n","    y2=[]\n","    if thita==90:\n","        x2.append(x1)\n","        x2.append(x1)\n","        y2.append(y1+l)\n","        y2.append(y1-l)\n","    if (thita>180 and thita<270) or (thita<=180 and thita>90):\n","        x2.append(l*np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(l * np.sin(np.deg2rad(thita)) + y1)\n","        x2.append(-l * np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(-l * np.sin(np.deg2rad(thita)) + y1)\n","    else:\n","        x2.append(-l*np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(-l * np.sin(np.deg2rad(thita)) + y1)\n","        x2.append(l * np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(l * np.sin(np.deg2rad(thita)) + y1)\n","\n","\n","    return x2, y2\n","\n","\n","\n","def random_allocation(c_x,c_y,angl,d,rng,num):\n","    X=[]\n","    Y=[]\n","    x=np.random.randint(d,rng+1,num)\n","    y=np.random.randint(0,angl,num)\n","    for i in range(num) :\n","        [a,b]=point_d(y[i],c_x,c_y,x[i])\n","        if y[i]<90 or y[i]>270 :\n","            X.append(a[1])\n","            Y.append(b[1])\n","        else:\n","            X.append(a[0])\n","            Y.append(b[0])\n","    return X,Y\n","\n","\n","\n","def find_points_in_angle(x2,y2,x3,y3,angl,q,w):\n","    result_x=[]\n","    result_y=[]\n","    ang=[]\n","    global U_neighbor\n","    global U_neighbor_sector\n","    for i in range(len(x3)):\n","        if (x3[i]-x2)==0:\n","            if y3[i]>=y2:\n","                ang.append(90)\n","            else:\n","                ang.append(270)\n","        else:\n","            ang.append(np.rad2deg(np.arctan2((y3[i]-y2),(x3[i]-x2)))%360)\n","        angl1=angl+60\n","        angl2=angl-60\n","        if angl1>=360 and ang[i]>=0 and ang[i]<90:\n","            ang[i]=ang[i]+360\n","        if angl2<0:\n","            angl2=angl2%360\n","        if angl2>angl1:\n","            angl1=angl1+360\n","            if ang[i]>=0 and ang[i]<180:\n","                ang[i]=ang[i]+360\n","        r=ang[i]\n","        if angl2<=r and r<=angl1:\n","            t=1\n","        else:\n","            t=0\n","        if t==1:\n","            result_x.append(x3[i])\n","            result_y.append(y3[i])\n","            U_neighbor[i].extend([q])\n","            U_neighbor_sector[i].extend([w])\n","            t=0\n","\n","    return result_x, result_y\n","\n","def find_dis(x1,y1,x0,y0):\n","    return np.sqrt((x0-x1)**2+(y0-y1)**2)\n","\n","def find_angl(x2,y2,x3,y3,angl):\n","    z=[]\n","    if (x3-x2)==0:\n","        if y3>=y2:\n","            ang=90\n","            z=ang\n","        else:\n","            ang=270\n","            z=ang\n","    else:\n","        ang=np.rad2deg(np.arctan2((y3-y2),(x3-x2)))%360\n","        if angl>=0 and angl<90 and ang>270 and ang < 360 :\n","            z=360-(ang-angl)\n","        elif ang >= 0 and ang < 90 and angl > 270 and angl < 360:\n","            z=360-(angl-ang)\n","        else:\n","            z=np.abs(angl-ang)\n","\n","    return z\n","\n","def power_watt_dbm(power):\n","    return 10*np.log10(power*1000)\n","\n","def transmit_power(thita,thita_3db,Am, power_dbm):\n","    x=-np.min([12*(thita/thita_3db)**2, Am])\n","    g_x=10**(x/10)\n","    return (10**(power_dbm/10))/1000*g_x\n","\n","def pw_m_hata(p,d):\n","    pl=128.1+37.6*np.log10(d/1000)\n","    G=10**(-pl/10)\n","    return G*p\n","\n","\n","\n","def profile_power(subbands,slot,p_setting,power):\n","    ln=len(p_setting)\n","\n","    pset=[]\n","    for i in range(len(slot)):\n","\n","        p=power+1\n","        t=0\n","        k=[]\n","        while (p>=power):\n","            p=0\n","            t=t+1\n","            l=[]\n","            for j in range(len(subbands)):\n","\n","                l.append(np.random.randint(0,ln,1))\n","                p=p+(subbands[j]*p_setting[l[j][0]])\n","            k.append(l)\n","\n","        for j in range(len(subbands)):\n","            pset.append(p_setting[k[t - 1][j][0]])\n","\n","    return pset\n","\n","\n","def convert_subband_power(sub,x):\n","    z=[]\n","    for i in range(len(x)) :\n","        z.append(sub[i]*x[i])\n","\n","    return z\n","\n","\n","def generate_power_matrix_macro():\n","    global thita\n","    global U_x\n","    global num_M\n","    global N_subband\n","    global P_macro_subband\n","    global thita_3db\n","    global A_m\n","    global U_received_power_subband\n","    U_received_power_subband=[]\n","\n","    for i in range(len(U_x)):\n","        U_received_power_subband.append([])\n","\n","        for j in range(num_M):\n","            U_received_power_subband[i].append([])\n","\n","            for a in range(N_subband):\n","                pw=P_macro_subband[j][a]\n","                pw_R= transmit_power(thita[i][j], thita_3db, A_m, power_watt_dbm(pw))\n","                U_received_power_subband[i][j].append(pw_m_hata(pw_R,U_macro_distance[i][j]))\n","\n","    return\n","\n","def sinr_db(p,pn):\n","\n","    return 10* np.log10(p/pn)\n","\n","def db_sinr(val):\n","\n","    return 10**(val/10)\n","\n","def sinr_to_cqi(i):\n","\n","    if i<=-5:\n","        out=1\n","\n","    elif i <=-2.5 and i> -5:\n","        out=2\n","\n","    elif i <=0 and i> -2.5:\n","        out=3\n","\n","    elif i <=2.4 and i> 0:\n","        out=4\n","\n","    elif i <=4 and i>2.4:\n","        out=5\n","\n","    elif i <=6 and i> 4:\n","        out=6\n","\n","    elif i <=8 and i> 6:\n","        out=7\n","\n","    elif i <=10 and i> 8:\n","        out=8\n","\n","    elif i <=13 and i> 10:\n","        out=9\n","\n","    elif i <=16 and i> 13:\n","        out=10\n","\n","    elif i <=18 and i> 16:\n","        out=11\n","\n","    elif i <=20.5 and i> 18:\n","        out=12\n","\n","    elif i <=24 and i> 20.5:\n","        out=13\n","\n","    elif i <=26.4 and i> 24:\n","        out=14\n","\n","    elif i> 26.4:\n","        out=15\n","\n","    return  out\n","\n","def shanon_formula(p,pn):\n","    alpha=1\n","    del_f=12*15*10**3\n","    N0=(10**(-174/10))/1000\n","    z1=p/(N0*del_f+pn)\n","\n","    return del_f*np.log2(1+alpha*z1)\n","\n","\n","def throughput():\n","    global U_received_power_subband\n","    global U_throughput_subband\n","    global U_SINR_subband\n","    global U_CQI_subband\n","    global P_own\n","    global P_intr\n","    global sub\n","    global U_x\n","    global U_association_macro\n","    global N_subband\n","    global num_M\n","\n","    U_throughput_subband=[]\n","    U_SINR_subband=[]\n","    U_CQI_subband=[]\n","\n","    for i in range(len(U_x)):\n","        U_throughput_subband.append([])\n","        U_SINR_subband.append([])\n","        U_CQI_subband.append([])\n","        q=U_association_macro[i]\n","\n","        if q>0:\n","            id_cell=q-1\n","            P_own=[]\n","            P_intr=[]\n","\n","            for X in range(N_subband):\n","                P_own.append(U_received_power_subband[i][id_cell][X])\n","                P_intr.append(0)\n","\n","                for H in range(num_M):\n","\n","                    if H !=id_cell:\n","                        P_intr[X] = P_intr[X] + U_received_power_subband[i][H][X]\n","\n","                U_SINR_subband[i].append(sinr_db(P_own[X], P_intr[X]))\n","                U_CQI_subband[i].append(sinr_to_cqi(U_SINR_subband[i][X]))\n","                U_throughput_subband[i].append(sub[X] * shanon_formula(P_own[X], P_intr[X]) / (1024 * 1024))\n","\n","    return\n","\n","\n","\n","def calculate_sinr(cell_m,user_i,subband_x):\n","\n","    return db_sinr(U_SINR_subband[(num_U*cell_m)+user_i][subband_x])\n","\n","\n","def calculate_gain(cell_m,user_i):\n","\n","    d=U_macro_distance[(num_U*cell_m)+user_i][cell_m]\n","\n","    pl=128.1+37.6*np.log10(d/1000)\n","    G=10**(-pl/10)\n","    #print('G    :',G)\n","    return G\n","\n","def calculate_power(cell_m,cell_n,user_i,subband_x):\n","\n","    pw = P_macro_subband[cell_m][subband_x]\n","    pw_R = transmit_power(thita[(num_U*cell_n)+user_i][subband_x], thita_3db, A_m, power_watt_dbm(pw))\n","    #print(pw,pw_R)\n","    return pw_R\n","\n","\n","\n","def optimize_resource_ga():\n","    global ga_comb\n","    global ga_comb2\n","    global ga_fit_comb\n","    global P_macro_subband\n","    global N_subband\n","    global O_macro_pos\n","    global O_macro_no\n","    global O_macro_sum\n","    global num_M\n","    global num_U\n","    global sub\n","    global slots_slots\n","    global MC_power\n","    global P_max_macro\n","\n","    O_macro_sum=[]\n","    ga_comb_temp=[]\n","\n","    for itr1 in range(6000):\n","        x=[]\n","\n","        for i in range(num_M):\n","           x.extend(profile_power(sub,slots_slots,MC_power,P_max_macro))\n","\n","        ga_comb_temp.append(x)\n","\n","    ga_comb=np.unique(ga_comb_temp,axis=0).tolist()\n","\n","\n","    for itr1 in range(len(ga_comb)):\n","\n","        for i in range(len(M_x)):\n","            P_macro_subband[i]=ga_comb[itr1][i*N_subband: (i+1)*N_subband]\n","\n","        #print(ga_comb_temp[itr1],P_macro_subband)\n","        generate_power_matrix_macro()\n","        throughput()\n","\n","        O_macro_no = []\n","        O_macro_pos = []\n","\n","        for i in range(len(M_x)):\n","            [a,b]=calc_max(i*num_U,((i+1)*num_U))\n","            O_macro_no.append(a)\n","            O_macro_pos.append(b)\n","\n","        O_macro_sum.append(np.sum(O_macro_no))\n","\n","    q=np.sort(O_macro_sum).tolist()\n","    Q = np.sort(O_macro_sum).tolist()\n","    w = np.argsort(O_macro_sum).tolist()\n","    W = np.argsort(O_macro_sum).tolist()\n","\n","    O_macro_no=[]\n","    O_macro_pos=[]\n","    O_macro_sum=[]\n","    ga_fit_comb=[[],[],[],[],[],[],[],[],[],[],[],[]]\n","    ga_comb2=ga_comb\n","\n","    LEN=len(ga_comb2)\n","    sys.stdout.flush()\n","    for uu in range(3000):\n","        O_macro_no = []\n","        O_macro_pos = []\n","        O_macro_sum=[]\n","        #prev_config=[]\n","\n","        ga_fit_comb[0]=ga_comb[w[-1]]\n","        ga_fit_comb[1] = ga_comb[w[-2]]\n","        ga_fit_comb[2] = ga_comb[w[-3]]\n","        ga_fit_comb[3] = ga_comb[w[-4]]\n","\n","        ga_comb=[]\n","        w=[]\n","        q=[]\n","\n","        [ga_fit_comb[4],ga_fit_comb[5]]=split_merge_ga(ga_fit_comb[0],ga_fit_comb[1])\n","        ga_fit_comb[4]=mutation_ga(ga_fit_comb[4])\n","        ga_fit_comb[5] = mutation_ga(ga_fit_comb[5])\n","\n","        [ga_fit_comb[6], ga_fit_comb[7]] = split_merge_ga(ga_fit_comb[0], ga_fit_comb[2])\n","        ga_fit_comb[6] = mutation_ga(ga_fit_comb[6])\n","        ga_fit_comb[7] = mutation_ga(ga_fit_comb[7])\n","\n","        [ga_fit_comb[8], ga_fit_comb[9]] = split_merge_ga(ga_fit_comb[0], ga_fit_comb[3])\n","        ga_fit_comb[8] = mutation_ga(ga_fit_comb[8])\n","        ga_fit_comb[9] = mutation_ga(ga_fit_comb[9])\n","\n","\n","        [ga_fit_comb[2], ga_fit_comb[3]] = split_merge_ga(ga_comb2[W[np.random.randint(LEN-10, LEN,1)[0]]], ga_comb2[W[np.random.randint(LEN-10, LEN,1)[0]]])\n","        ga_fit_comb[2] = mutation_ga(ga_fit_comb[2])\n","        ga_fit_comb[3] = mutation_ga(ga_fit_comb[3])\n","\n","        [ga_fit_comb[10], ga_fit_comb[11]] = split_merge_ga(ga_comb2[W[np.random.randint(LEN - 50, LEN, 1)[0]]],ga_comb2[W[np.random.randint(LEN - 50, LEN, 1)[0]]])\n","        ga_fit_comb[10] = mutation_ga(ga_fit_comb[10])\n","        ga_fit_comb[11] = mutation_ga(ga_fit_comb[11])\n","\n","        ga_comb = np.unique(ga_fit_comb, axis=0).tolist()\n","\n","        OM_position=[]\n","\n","        for itr1 in range(len(ga_comb)):\n","\n","            for i in range(len(M_x)):\n","                P_macro_subband[i] = ga_comb[itr1][i * N_subband: (i + 1) * N_subband]\n","\n","            # print(ga_comb_temp[itr1],P_macro_subband)\n","            generate_power_matrix_macro()\n","            throughput()\n","\n","            O_macro_no = []\n","            O_macro_pos = []\n","\n","            for i in range(len(M_x)):\n","                [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","                O_macro_no.extend(a)\n","                O_macro_pos.extend(b)\n","\n","            #print(O_macro_pos)\n","            OM_position.append(O_macro_pos)\n","            O_macro_sum.append(np.sum(O_macro_no))\n","\n","        #print(O_macro_sum)\n","\n","        q = np.sort(O_macro_sum).tolist()\n","        w = np.argsort(O_macro_sum).tolist()\n","\n","        current_config = ga_comb[w[-1]]\n","\n","        if uu==0:\n","            prev_config= ga_comb[w[-1]]\n","            cont_itr=0\n","\n","        if current_config==prev_config :\n","            cont_itr=cont_itr+1\n","        else:\n","            cont_itr=0\n","\n","        prev_config=ga_comb[w[-1]]\n","\n","\n","        if cont_itr >500:\n","            break\n","\n","    power_config=ga_comb[w[-1]]\n","    ff=np.digitize(power_config,MC_power).tolist()\n","    ff.extend(OM_position[w[-1]])\n","    #print(\"power_config\",ff)\n","    #g_ga_th.append(q[-1])\n","    #print(\"throughput_ga :\", q[-1])\n","    return power_config,ff,q[-1]\n","\n","def calc_max(xi,xe):\n","    global U_throughput_subband\n","\n","    return np.amax(U_throughput_subband[xi:xe],axis=0).tolist() , np.argmax(U_throughput_subband[xi:xe],axis=0).tolist()\n","\n","\n","def split_merge_ga(v1,v2):\n","\n","    z1=[]\n","    z2=[]\n","    a=np.random.randint(1,num_M+1,1)\n","    b = np.random.randint(0, num_M+1 - a, 1)\n","\n","    temp_v11=v1[0:(a[0]-1)*N_subband]\n","    temp_v12 = v1[(a[0]-1) * N_subband: (a[0]+b[0])*N_subband]\n","    temp_v13 = v1[(a[0] + b[0]) * N_subband:]\n","\n","    temp_v21 = v2[0:(a[0] - 1) * N_subband]\n","    temp_v22 = v2[(a[0] - 1) * N_subband: (a[0] + b[0]) * N_subband]\n","    temp_v23 = v2[(a[0] + b[0]) * N_subband:]\n","\n","    z1.extend(temp_v11)\n","    z1.extend(temp_v22)\n","    z1.extend(temp_v13)\n","\n","    z2.extend(temp_v21)\n","    z2.extend(temp_v12)\n","    z2.extend(temp_v23)\n","\n","    return z1, z2\n","\n","def mutation_ga(v):\n","\n","    global MC_power\n","    z=[]\n","\n","    temp=v[:]\n","\n","    a=np.random.randint(0,7,1)\n","    if a[0]==1:\n","        ln=len(v)\n","        p1=np.random.randint(0,ln,1)\n","        q1=np.random.randint(0,len(MC_power),1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]]=MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","\n","        right=check_max(temp)\n","\n","        if right <0.5:\n","            z=temp\n","        else:\n","            z=v\n","\n","    elif a[0] == 2:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","    elif a[0] == 3:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        p4 = np.random.randint(0, ln, 1)\n","        q4 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","        temp[p4[0]] = MC_power[q4[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","    elif a[0] == 4:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        p4 = np.random.randint(0, ln, 1)\n","        q4 = np.random.randint(0, len(MC_power), 1)\n","\n","        p5 = np.random.randint(0, ln, 1)\n","        q5 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","        temp[p4[0]] = MC_power[q4[0]]\n","        temp[p5[0]] = MC_power[q5[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","\n","    else :\n","        ln = len(v)\n","        p = np.random.randint(0, ln, 1)\n","        q = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p[0]] = MC_power[q[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","\n","    return z\n","\n","\n","def check_max(v):\n","\n","    z=0\n","    for irr in range(num_M):\n","\n","        if np.sum(v[irr*N_subband:(irr+1)*N_subband]) <= 2.5 :\n","            z=(z | 0)\n","        else:\n","            z= (z | 1)\n","\n","    return z\n","\n","def check_ga_with_drl(action):\n","    global g_total_call\n","    global g_total_corrected\n","    global final_comb\n","    global M_x\n","    global ln_fl_comb\n","    action_drl=[]\n","    if (g_cntr-1) < g_data_len:\n","        #print(\"running ---------------\")\n","        action_ga=data_set['arr_2'][g_cntr-1].tolist()\n","        ga_th=data_set['arr_3'][g_cntr-1].tolist()\n","       # action_wmmse = data_set['arr_4'][g_cntr - 1].tolist()\n","       # wmmse_th = data_set['arr_5'][g_cntr - 1].tolist()\n","\n","    else:\n","\n","        action_ga,_,ga_th=optimize_resource_ga()\n","        g_data_action_ga.append(action_ga)\n","        g_data_ga_th.append(ga_th)\n","       # action_wmmse, wmmse_th = optimize_resource_wmmse()\n","       # g_data_action_wmmse.append(action_wmmse)\n","       # g_data_wmmse_th.append(wmmse_th)\n","\n","\n","    g_ga_th.append(ga_th)\n","  #  g_wmmse_th.append(wmmse_th)\n","\n","    #print(\"throughput_ga :\", ga_th)\n","\n","    #for i in range(len(M_x)):\n","      #  action_drl.extend(final_comb[action[i]-i*ln_fl_comb])\n","    #answer=np.double(action_drl==action_ga)\n","    #print(answer,action_drl,action_ga)\n","    #g_total_call=g_total_call+1\n","    #g_total_corrected=g_total_corrected+answer\n","    #g_drl_th.append(g_drl_th_val)\n","\n","    #g_eql_th.append(g_eql_th_val)\n","    #g_rnd_th.append(g_rnd_th_val)\n","\n","\n","\n","  #  print(\"Throughput GA: \",ga_th,' DRL: ', g_drl_th_val,' EQL: ', g_eql_th_val,' RND: ',g_rnd_th_val,' WMMSE: ',wmmse_th)\n","    np.savez(\"result_5c_2h_5p_lr2.npz\", g_ga_th)\n","    np.save(\"counter_v2_5c_2h_5p_lr2.npy\",g_cntr)\n","    if g_cntr > g_data_len:\n","        np.savez(\"data_set_5c.npz\",g_data_x,g_data_y,g_data_action_ga,g_data_ga_th)\n","\n","\n","    return\n","\n","\n","########################################################################################################################\n","\n","\n","\n","def optimize_resource_wmmse():\n","\n","    #v_k_0=np.random.rand(0,np.sqrt(0.8),num_M)\n","    global P_macro_subband\n","    global N_subband\n","    global num_U\n","    global num_M\n","    global ln_fl_comb\n","    global final_comb\n","    global k_m_n\n","    global v_k_old\n","    global u_k_old\n","    global w_k_old\n","\n","\n","    global v_k_new\n","    global u_k_new\n","    global w_k_new\n","\n","    del_f = 12 * 15 * 10 ** 3\n","    N0 = (10 ** (-174 / 10)) / 1000\n","\n","\n","    for i in range(num_M):\n","        P_macro_subband[i] = final_comb[np.random.randint(0, ln_fl_comb)]\n","\n","    v_k_old=np.sqrt(P_macro_subband).tolist()\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    K_macro_no = []\n","    k_m_n = []\n","\n","    # for calculating user association\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        # K_macro_no.append(a)\n","        k_m_n.append(b)\n","    #print(k_m_n)\n","\n","    # for u_k_old\n","    u_k_old=[]\n","\n","    for i in range(len(M_x)):      # u_k\n","        u_k_old.append([])\n","\n","        for X in range(N_subband):   # u_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):    # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * calculate_power(j, i, k_m_n[i][X], X) )\n","\n","            sum_den=sum_den+(N0*del_f)\n","\n","            u_k_old[i].append(np.sqrt(calculate_gain(i,k_m_n[i][X])) * np.sqrt(calculate_power(i, i, k_m_n[i][X], X))/ sum_den)\n","\n","    # for u_k_old\n","    w_k_old=[]\n","\n","    for i in range(len(M_x)):      # w_k\n","        w_k_old.append([])\n","\n","        for X in range(N_subband):   # w_k^n\n","\n","            w_k_old[i].append(1/ (u_k_old[i][X] * np.sqrt(calculate_gain(i,k_m_n[i][X])) *  np.sqrt(calculate_power(i, i, k_m_n[i][X], X))))\n","    for itr_wmmse in range(40):\n","\n","        update_v_k()\n","        update_u_k()\n","        update_w_k()\n","        if u_k_old==u_k_new:\n","            break\n","        u_k_old=u_k_new\n","        w_k_old=w_k_new\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    O_macro_no = []\n","    O_macro_pos = []\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        O_macro_no.append(a)\n","        O_macro_pos.append(b)\n","\n","\n","\n","    #print('Final   :',P_macro_subband)\n","\n","\n","\n","    return P_macro_subband, np.sum(O_macro_no)   # action , throughput\n","\n","def update_v_k():\n","    global P_macro_subband\n","    global v_k_new\n","    global u_k_old\n","    global w_k_old\n","    global k_m_n\n","    # for v_k_new\n","    v_k_new = []\n","\n","    for i in range(len(M_x)):  # v_k\n","        v_k_new.append([])\n","\n","        for X in range(N_subband):  # v_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):  # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * (( u_k_old[j][X])**2) * w_k_old[j][X])\n","\n","            #sum_den = sum_den + 1\n","\n","            v_k_new[i].append(\n","                np.sqrt(calculate_gain(i, k_m_n[i][X])) * w_k_old[i][X] * u_k_old[i][X] / sum_den)\n","\n","    P_macro_subband=np.square(v_k_new).tolist()\n","\n","    normalized_check_max()\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    k_m_n = []\n","\n","    # for calculating user association\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        # K_macro_no.append(a)\n","        k_m_n.append(b)\n","\n","    #print(np.square(v_k_new).tolist())\n","    #print(P_macro_subband)\n","\n","    return\n","\n","def update_u_k():\n","    global u_k_new\n","\n","    del_f = 12 * 15 * 10 ** 3\n","    N0 = (10 ** (-174 / 10)) / 1000\n","    u_k_new = []\n","\n","    for i in range(len(M_x)):  # u_k\n","        u_k_new.append([])\n","\n","        for X in range(N_subband):  # u_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):  # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * calculate_power(j, i, k_m_n[i][X], X))\n","\n","            sum_den = sum_den + (N0 * del_f)\n","\n","            u_k_new[i].append(\n","                np.sqrt(calculate_gain(i, k_m_n[i][X])) * np.sqrt(calculate_power(i, i, k_m_n[i][X], X)) / sum_den)\n","\n","    #print(u_k_new)\n","\n","    return\n","\n","def update_w_k():\n","    global w_k_new\n","    w_k_new = []\n","\n","    for i in range(len(M_x)):  # w_k\n","        w_k_new.append([])\n","\n","        for X in range(N_subband):  # w_k^n\n","\n","            w_k_new[i].append(1 / (u_k_new[i][X] * np.sqrt(calculate_gain(i, k_m_n[i][X])) * np.sqrt(\n","                calculate_power(i, i, k_m_n[i][X], X))))\n","\n","    return\n","\n","def normalized_check_max():\n","\n","\n","    for i in range(len(M_x)):  #\n","\n","        for X in range(N_subband):  #\n","            P_macro_subband[i][X]= normalized_power(P_macro_subband[i][X])\n","\n","        if np.sum(P_macro_subband[i][0:N_subband]) >2.41:\n","            P_macro_subband[i]=(0.8*np.ones(N_subband)).tolist()\n","\n","\n","\n","\n","    return\n","\n","\n","def normalized_power(inpt):\n","\n","    if inpt <(MC_power[0]+MC_power[1])/2:\n","        output=MC_power[0]\n","    elif (MC_power[0]+MC_power[1])/2 <= inpt < (MC_power[1]+MC_power[2])/2:\n","        output=MC_power[1]\n","    elif (MC_power[1]+MC_power[2])/2 <= inpt < (MC_power[2]+MC_power[3])/2:\n","        output=MC_power[2]\n","    elif (MC_power[2]+MC_power[3])/2 <= inpt < (MC_power[3]+MC_power[4])/2:\n","        output=MC_power[3]\n","    elif (MC_power[3]+MC_power[4])/2 <= inpt :\n","        output=MC_power[4]\n","\n","    return output\n","\n","\n","\n","\n","# -------------------- ENVIRONMENT ---------------------\n","\n","#s,s_ini = self.env_reset()\n","\n","def env_reset():\n","    global thita\n","    global g_drl_th_val\n","    global g_eql_th_val\n","    global g_rnd_th_val\n","    global thita_3db\n","    global P_max_macro\n","    global MC_power\n","    global slots_slots\n","    global sub\n","    global A_m\n","    global R_m\n","    global num_U\n","    global num_M\n","    global M_x\n","    global M_y\n","    global M_cell_beam\n","    global M_cell_associated_user_id\n","    global U_x\n","    global U_y\n","    global U_association_macro\n","    global U_neighbor\n","    global U_neighbor_sector\n","    global M_cell_region_x\n","    global M_cell_region_y\n","    global U_macro_distance\n","    global U_macro_power\n","    global M_cell_txblock_power\n","    global P_macro_subband\n","    global U_received_power_subband\n","    global U_throughput_subband\n","    global U_SINR_subband\n","    global U_CQI_subband\n","    global g_action\n","    global g_cntr\n","\n","    global current_throughput\n","    global previous_throughput\n","\n","    global g_counter\n","\n","    global k_m_n\n","    global v_k_old\n","    global u_k_old\n","    global w_k_old\n","\n","    global v_k_new\n","    global u_k_new\n","    global w_k_new\n","\n","    k_m_n = []\n","    v_k_old = []\n","    u_k_old = []\n","    w_k_old = []\n","\n","    v_k_new = []\n","    u_k_new = []\n","    w_k_new = []\n","\n","    g_counter = 0\n","    current_throughput = []\n","    previous_throughput = 0\n","    g_drl_th_val = 0\n","    g_eql_th_val = 0\n","    g_rnd_th_val = 0\n","\n","    M_cell_beam = []\n","    M_cell_associated_user_id = []\n","    M_cell_region_x = []\n","    M_cell_region_y = []\n","    M_cell_txblock_power = []\n","\n","    U_x = []\n","    U_y = []\n","    U_association_macro = []\n","    U_neighbor = []\n","    U_neighbor_sector = []\n","    U_macro_distance = []\n","    U_macro_power = []\n","    U_throughputt = []\n","\n","    P_macro_subband = []\n","    U_received_power_subband = []\n","    U_throughput_subband = []\n","\n","    U_SINR_subband = []\n","    U_CQI_subband = []\n","\n","    itr = 0\n","    for i in range(len(M_x)):\n","        M_cell_beam.append(random_beam())\n","        M_cell_associated_user_id.append([])\n","\n","        for j in range(num_U):\n","            M_cell_associated_user_id[i].extend([itr + 1])\n","            U_association_macro.append(i + 1)\n","            itr = itr + 1\n","\n","        # [x, y] = random_allocation(M_x[i], M_y[i], 360, 0.2 * R_m, R_m, num_U)\n","        # U_x.extend(x)\n","        # U_y.extend(y)\n","\n","    # ***********************************************************************************************************************\n","\n","    # g_data_x.append(U_x)\n","    # g_data_y.append(U_y)\n","    if g_cntr < g_data_len:\n","        U_x = data_set['arr_0'][g_cntr].tolist()\n","        # print(U_x)\n","        U_y = data_set['arr_1'][g_cntr].tolist()\n","\n","    else:\n","        for i in range(len(M_x)):\n","            [x, y] = random_allocation(M_x[i], M_y[i], 360, 0.2 * R_m, R_m, num_U)\n","            U_x.extend(x)\n","            U_y.extend(y)\n","\n","        g_data_x.append(U_x)\n","        g_data_y.append(U_y)\n","\n","    g_cntr = g_cntr + 1\n","    print(g_cntr)\n","\n","    # ***********************************************************************************************************************\n","    for i in range(len(U_x)):\n","        U_neighbor.append([])\n","        U_neighbor_sector.append([])\n","\n","    for i in range(len(M_x)):\n","        M_cell_region_x.append([[], [], []])\n","        M_cell_region_y.append([[], [], []])\n","\n","        for j in range(3):\n","            [a, b] = find_points_in_angle(M_x[i], M_y[i], U_x, U_y, M_cell_beam[i][j], i + 1, j + 1)\n","            M_cell_region_x[i][j].extend(a)\n","            M_cell_region_y[i][j].extend(b)\n","\n","    thita = np.zeros((len(U_x), len(M_x)))\n","\n","    for i in range(len(U_x)):\n","        U_macro_distance.append([])\n","        U_macro_power.append([])\n","\n","        for j in range(len(M_x)):\n","            U_macro_distance[i].append(find_dis(U_x[i], U_y[i], M_x[j], M_y[j]))\n","            angl = M_cell_beam[j][U_neighbor_sector[i][j] - 1]\n","\n","            thita[i][j] = find_angl(M_x[j], M_y[j], U_x[i], U_y[i], angl)\n","            a = transmit_power(thita[i][j], thita_3db, A_m, power_watt_dbm(P_max_macro))\n","            U_macro_power[i].append(pw_m_hata(a, U_macro_distance[i][j]))\n","\n","    for i in range(len(M_x)):\n","        M_cell_txblock_power.append(profile_power(sub, slots_slots, MC_power, P_max_macro))\n","        P_macro_subband.append(M_cell_txblock_power[i])\n","\n","    generate_power_matrix_macro()\n","\n","    throughput()\n","\n","    temp_var = []\n","\n","    for i in range(num_M * num_U):\n","        temp_var.extend(U_CQI_subband[i])\n","        temp_var.append(np.double(U_macro_distance[i][U_association_macro[i] - 1] / R_m >= 0.5))\n","\n","    return np.array(temp_var)\n","\n","\n","########################################################################################################################\n","\n","# variable definition\n","\n","current_throughput=[]\n","previous_throughput=0\n","\n","g_counter=0\n","g_action=[]\n","g_total_call=0\n","g_total_corrected=0\n","g_ga_th=[]\n","g_wmmse_th=[]\n","g_drl_th_val=0\n","g_drl_th=[]\n","g_eql_th_val=0\n","g_rnd_th_val=0\n","g_eql_th=[]\n","g_rnd_th=[]\n","\n","g_cntr=0\n","g_data_len=0\n","\n","g_data_x=[]\n","g_data_y=[]\n","\n","g_data_action_ga=[]\n","g_data_vector_ga=[]\n","g_data_ga_th=[]\n","\n","g_data_action_wmmse=[]\n","g_data_wmmse_th=[]\n","\n","\n","\n","M_cell_beam=[]\n","M_cell_associated_user_id=[]\n","M_cell_cor_x=[]\n","M_cell_cor_y=[]\n","M_cell_region_x=[]\n","M_cell_region_y=[]\n","M_cell_txblock_power=[]\n","\n","U_x=[]\n","U_y=[]\n","U_association_macro=[]\n","U_neighbor=[]\n","U_neighbor_sector=[]\n","U_macro_distance=[]\n","U_macro_power=[]\n","U_throughputt=[]\n","\n","P_macro_subband=[]\n","\n","U_received_power_subband=[]\n","U_throughput_subband=[]\n","U_SINR_subband=[]\n","U_CQI_subband=[]\n","\n","ga_comb=[]\n","ga_comb2=[]\n","ga_fit_comb=[]\n","\n","O_macro_no=[]\n","O_macro_pos=[]\n","O_macro_sum=[]\n","\n","thita=[]\n","\n","\n","thita_3db=70\n","A_m=35\n","P_max_macro=40\n","alpha=25\n","r=1000\n","R_m=500\n","min_RM=600\n","num_M=5\n","num_U=5\n","N=9000\n","N_subband=3\n","\n","MC_power_1=[0.4, 0.6, 0.8,1.0,1.2]\n","MC_power=[0.4,0.6, 0.8,1.0,1.2]\n","\n","N_RB=48\n","N_slot=1\n","N_subframes=1\n","sub=[]\n","slots_slots=[1]\n","sub.append(mt.floor(N_RB/N_subband))\n","sub.append(mt.floor(N_RB/N_subband))\n","\n","# for 5 cell system\n","M_x=[272, -270, -72, 490, -804]\n","M_y=[668, 136, -839, -100, -405]\n","\n","# for 10 cell system\n","#M_x=[-507.325029580438,1002.33404665068,145.312062677023,200.78357265330,1638.02723651541,1373.51667496699,-505.567176719993,89.0624746033709,888.768341569969,700.98746226480]\n","#M_y=[622.439530990585,1204.09269092070,-857.441644095846,0.776230721301,-266.682269021143,409.885301601770,-276.654621800917,971.99443198228,-404.073417200223,500.42153804114]\n","\n","# for 15 cell system\n","#M_x=[-507.325029580438,1002.33404665068,145.312062677023,1008.94157032003,200.78357265330,1638.02723651541,1373.51667496699,-505.567176719993,89.0624746033709,208.3844792471699,-1205.45088276488,-1203.86653509258,888.768341569969,-623.017861398548,700.98746226480]\n","#M_y=[622.439530990585,1204.09269092070,-857.441644095846,-1254.30978634305,0.776230721301,-566.682269021143,309.885301601770,-276.654621800917,971.99443198228,-1708.16795562791,281.640997912069,-609.705714626437,-404.073417200223,-1209.60615767022,500.42153804114]\n","\n","\n","sub.append(N_RB-sub[N_subband-2]*(N_subband-1))\n","#print(sub)\n","final_comb=[]\n","P_own=[]\n","P_intr=[]\n","P_SINR=[]\n","\n","\n","# final_comb : combination of all the actions for a particular cell\n","\n","power_comb = list(map(list, itertools.product(MC_power_1, repeat=N_subband)))\n","\n","for i in power_comb:\n","    temp_sum=0.0\n","    for j in range(N_subband):\n","        temp_sum=temp_sum+ i[j]*sub[j]\n","    if temp_sum <=40 :\n","        final_comb.append(i)\n","\n","ln_fl_comb=len(final_comb)\n","\n","#print(final_comb[12])\n","\n","plt.figure(1)\n","plt.plot(M_x,M_y,'b*')\n","\n","for i in range(len(M_x)):\n","    circle(M_x[i],M_y[i],R_m)\n","#plt.show()  # to plot the figure\n","\n","\n","\n","\n","\n","\n","\n","\n","try:\n","\n","    g_cntr=0\n","\n","    ########################################################################################################################\n","    #g_cntr=np.load(\"counter_5c_1.npy\").tolist()\n","    #data_set = np.load(\"data_set_5c_1.npz\")\n","    #g_data_len = len(data_set['arr_0'])\n","    #g_data_x = data_set['arr_0'].tolist()\n","    #g_data_y = data_set['arr_1'].tolist()\n","    #g_data_action_ga = data_set['arr_2'].tolist()\n","    #g_data_ga_th = data_set['arr_3'].tolist()\n","    #g_data_action_wmmse = data_set['arr_4'].tolist()\n","    #g_data_wmmse_th = data_set['arr_5'].tolist()\n","    #g_data_vector_ga=data_set['arr_6'].tolist()\n","    #print(g_data_len,g_cntr)\n","    #print(g_data_ga_th)\n","\n","\n","\n","    ########################################################################################################################\n","\n","    while True:\n","        s=env_reset().tolist()\n","        #print(s)\n","        #a,b,c=optimize_resource_ga()\n","        #print(a,b,c)\n","\n","        if (g_cntr) > g_data_len:\n","            action_ga, vector_ga, ga_th = optimize_resource_ga()\n","            #print(s)\n","            s.extend(vector_ga)\n","            vector_ga=s\n","            #print(vector_ga)\n","            g_data_action_ga.append(action_ga)\n","            g_data_ga_th.append(ga_th)\n","            g_data_vector_ga.append(vector_ga)\n","            action_wmmse, wmmse_th = optimize_resource_wmmse()\n","            g_data_action_wmmse.append(action_wmmse)\n","            g_data_wmmse_th.append(wmmse_th)\n","\n","        np.save(\"counter_5c_1\", g_cntr)\n","        if g_cntr > g_data_len:\n","            np.savez(\"data_set_5c_1.npz\", g_data_x, g_data_y, g_data_action_ga, g_data_ga_th, g_data_action_wmmse, g_data_wmmse_th,g_data_vector_ga)\n","\n","\n","finally:\n","   # agent.brain.model.save(\"dqn_5c_2h_5p_lr2.h5\")\n","    #np.save(\"data_5c_2h_5p_lr2.npy\", agent.memory.samples)\n","\n","    print(\"total call vs corrected answer :\", g_total_call,g_total_corrected)\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsxR1rI4TOzh"},"outputs":[],"source":["# library\n","\n","import sys\n","import math\n","import random\n","import math as mt\n","import numpy as np\n","import time\n","from keras import backend as K\n","import tensorflow as tf\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","\n","# function definition\n","\n","def circle(x, y,r):\n","    ang=np.arange(0, 2*mt.pi, 0.01)\n","    xp=r*np.cos(ang)\n","    yp=r*np.sin(ang)\n","    plt.plot(x+xp,y+yp)\n","    return\n","\n","def random_beam():\n","    x=[]\n","    x.append(60)\n","    x.append((60+120)%360)\n","    x.append((60-120)%360)\n","    return x\n","\n","def point_d(thita,x1,y1,l):\n","    x2=[]\n","    y2=[]\n","    if thita==90:\n","        x2.append(x1)\n","        x2.append(x1)\n","        y2.append(y1+l)\n","        y2.append(y1-l)\n","    if (thita>180 and thita<270) or (thita<=180 and thita>90):\n","        x2.append(l*np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(l * np.sin(np.deg2rad(thita)) + y1)\n","        x2.append(-l * np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(-l * np.sin(np.deg2rad(thita)) + y1)\n","    else:\n","        x2.append(-l*np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(-l * np.sin(np.deg2rad(thita)) + y1)\n","        x2.append(l * np.cos(np.deg2rad(thita)) + x1)\n","        y2.append(l * np.sin(np.deg2rad(thita)) + y1)\n","\n","\n","    return x2, y2\n","\n","\n","\n","def random_allocation(c_x,c_y,angl,d,rng,num):\n","    X=[]\n","    Y=[]\n","    x=np.random.randint(d,rng+1,num)\n","    y=np.random.randint(0,angl,num)\n","    for i in range(num) :\n","        [a,b]=point_d(y[i],c_x,c_y,x[i])\n","        if y[i]<90 or y[i]>270 :\n","            X.append(a[1])\n","            Y.append(b[1])\n","        else:\n","            X.append(a[0])\n","            Y.append(b[0])\n","    return X,Y\n","\n","\n","\n","def find_points_in_angle(x2,y2,x3,y3,angl,q,w):\n","    result_x=[]\n","    result_y=[]\n","    ang=[]\n","    global U_neighbor\n","    global U_neighbor_sector\n","    for i in range(len(x3)):\n","        if (x3[i]-x2)==0:\n","            if y3[i]>=y2:\n","                ang.append(90)\n","            else:\n","                ang.append(270)\n","        else:\n","            ang.append(np.rad2deg(np.arctan2((y3[i]-y2),(x3[i]-x2)))%360)\n","        angl1=angl+60\n","        angl2=angl-60\n","        if angl1>=360 and ang[i]>=0 and ang[i]<90:\n","            ang[i]=ang[i]+360\n","        if angl2<0:\n","            angl2=angl2%360\n","        if angl2>angl1:\n","            angl1=angl1+360\n","            if ang[i]>=0 and ang[i]<180:\n","                ang[i]=ang[i]+360\n","        r=ang[i]\n","        if angl2<=r and r<=angl1:\n","            t=1\n","        else:\n","            t=0\n","        if t==1:\n","            result_x.append(x3[i])\n","            result_y.append(y3[i])\n","            U_neighbor[i].extend([q])\n","            U_neighbor_sector[i].extend([w])\n","            t=0\n","\n","    return result_x, result_y\n","\n","def find_dis(x1,y1,x0,y0):\n","    return np.sqrt((x0-x1)**2+(y0-y1)**2)\n","\n","def find_angl(x2,y2,x3,y3,angl):\n","    z=[]\n","    if (x3-x2)==0:\n","        if y3>=y2:\n","            ang=90\n","            z=ang\n","        else:\n","            ang=270\n","            z=ang\n","    else:\n","        ang=np.rad2deg(np.arctan2((y3-y2),(x3-x2)))%360\n","        if angl>=0 and angl<90 and ang>270 and ang < 360 :\n","            z=360-(ang-angl)\n","        elif ang >= 0 and ang < 90 and angl > 270 and angl < 360:\n","            z=360-(angl-ang)\n","        else:\n","            z=np.abs(angl-ang)\n","\n","    return z\n","\n","def power_watt_dbm(power):\n","    return 10*np.log10(power*1000)\n","\n","def transmit_power(thita,thita_3db,Am, power_dbm):\n","    x=-np.min([12*(thita/thita_3db)**2, Am])\n","    g_x=10**(x/10)\n","    return (10**(power_dbm/10))/1000*g_x\n","\n","def pw_m_hata(p,d):\n","    pl=128.1+37.6*np.log10(d/1000)\n","    G=10**(-pl/10)\n","    return G*p\n","\n","\n","\n","def profile_power(subbands,slot,p_setting,power):\n","    ln=len(p_setting)\n","\n","    pset=[]\n","    for i in range(len(slot)):\n","\n","        p=power+1\n","        t=0\n","        k=[]\n","        while (p>=power):\n","            p=0\n","            t=t+1\n","            l=[]\n","            for j in range(len(subbands)):\n","\n","                l.append(np.random.randint(0,ln,1))\n","                p=p+(subbands[j]*p_setting[l[j][0]])\n","            k.append(l)\n","\n","        for j in range(len(subbands)):\n","            pset.append(p_setting[k[t - 1][j][0]])\n","\n","    return pset\n","\n","\n","def convert_subband_power(sub,x):\n","    z=[]\n","    for i in range(len(x)) :\n","        z.append(sub[i]*x[i])\n","\n","    return z\n","\n","\n","def generate_power_matrix_macro():\n","    global thita\n","    global U_x\n","    global num_M\n","    global N_subband\n","    global P_macro_subband\n","    global thita_3db\n","    global A_m\n","    global U_received_power_subband\n","    U_received_power_subband=[]\n","\n","    for i in range(len(U_x)):\n","        U_received_power_subband.append([])\n","\n","        for j in range(num_M):\n","            U_received_power_subband[i].append([])\n","\n","            for a in range(N_subband):\n","                pw=P_macro_subband[j][a]\n","                pw_R= transmit_power(thita[i][j], thita_3db, A_m, power_watt_dbm(pw))\n","                U_received_power_subband[i][j].append(pw_m_hata(pw_R,U_macro_distance[i][j]))\n","\n","    return\n","\n","def sinr_db(p,pn):\n","\n","    return 10* np.log10(p/pn)\n","\n","def db_sinr(val):\n","\n","    return 10**(val/10)\n","\n","def sinr_to_cqi(i):\n","\n","    if i<=-5:\n","        out=1\n","\n","    elif i <=-2.5 and i> -5:\n","        out=2\n","\n","    elif i <=0 and i> -2.5:\n","        out=3\n","\n","    elif i <=2.4 and i> 0:\n","        out=4\n","\n","    elif i <=4 and i>2.4:\n","        out=5\n","\n","    elif i <=6 and i> 4:\n","        out=6\n","\n","    elif i <=8 and i> 6:\n","        out=7\n","\n","    elif i <=10 and i> 8:\n","        out=8\n","\n","    elif i <=13 and i> 10:\n","        out=9\n","\n","    elif i <=16 and i> 13:\n","        out=10\n","\n","    elif i <=18 and i> 16:\n","        out=11\n","\n","    elif i <=20.5 and i> 18:\n","        out=12\n","\n","    elif i <=24 and i> 20.5:\n","        out=13\n","\n","    elif i <=26.4 and i> 24:\n","        out=14\n","\n","    elif i> 26.4:\n","        out=15\n","\n","    return  out\n","\n","def shanon_formula(p,pn):\n","    alpha=1\n","    del_f=12*15*10**3\n","    N0=(10**(-174/10))/1000\n","    z1=p/(N0*del_f+pn)\n","\n","    return del_f*np.log2(1+alpha*z1)\n","\n","\n","def throughput():\n","    global U_received_power_subband\n","    global U_throughput_subband\n","    global U_SINR_subband\n","    global U_CQI_subband\n","    global P_own\n","    global P_intr\n","    global sub\n","    global U_x\n","    global U_association_macro\n","    global N_subband\n","    global num_M\n","\n","    U_throughput_subband=[]\n","    U_SINR_subband=[]\n","    U_CQI_subband=[]\n","\n","    for i in range(len(U_x)):\n","        U_throughput_subband.append([])\n","        U_SINR_subband.append([])\n","        U_CQI_subband.append([])\n","        q=U_association_macro[i]\n","\n","        if q>0:\n","            id_cell=q-1\n","            P_own=[]\n","            P_intr=[]\n","\n","            for X in range(N_subband):\n","                P_own.append(U_received_power_subband[i][id_cell][X])\n","                P_intr.append(0)\n","\n","                for H in range(num_M):\n","\n","                    if H !=id_cell:\n","                        P_intr[X] = P_intr[X] + U_received_power_subband[i][H][X]\n","\n","                U_SINR_subband[i].append(sinr_db(P_own[X], P_intr[X]))\n","                U_CQI_subband[i].append(sinr_to_cqi(U_SINR_subband[i][X]))\n","                U_throughput_subband[i].append(sub[X] * shanon_formula(P_own[X], P_intr[X]) / (1024 * 1024))\n","\n","    return\n","\n","def optimize_resource_wmmse():\n","\n","    #v_k_0=np.random.rand(0,np.sqrt(0.8),num_M)\n","    global P_macro_subband\n","    global N_subband\n","    global num_U\n","    global num_M\n","    global ln_fl_comb\n","    global final_comb\n","    global k_m_n\n","    global v_k_old\n","    global u_k_old\n","    global w_k_old\n","\n","\n","    global v_k_new\n","    global u_k_new\n","    global w_k_new\n","\n","    del_f = 12 * 15 * 10 ** 3\n","    N0 = (10 ** (-174 / 10)) / 1000\n","\n","\n","    for i in range(num_M):\n","        P_macro_subband[i] = final_comb[np.random.randint(0, ln_fl_comb)]\n","\n","    v_k_old=np.sqrt(P_macro_subband).tolist()\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    K_macro_no = []\n","    k_m_n = []\n","\n","    # for calculating user association\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        # K_macro_no.append(a)\n","        k_m_n.append(b)\n","    #print(k_m_n)\n","\n","    # for u_k_old\n","    u_k_old=[]\n","\n","    for i in range(len(M_x)):      # u_k\n","        u_k_old.append([])\n","\n","        for X in range(N_subband):   # u_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):    # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * calculate_power(j, i, k_m_n[i][X], X) )\n","\n","            sum_den=sum_den+(N0*del_f)\n","\n","            u_k_old[i].append(np.sqrt(calculate_gain(i,k_m_n[i][X])) * np.sqrt(calculate_power(i, i, k_m_n[i][X], X))/ sum_den)\n","\n","    # for u_k_old\n","    w_k_old=[]\n","\n","    for i in range(len(M_x)):      # w_k\n","        w_k_old.append([])\n","\n","        for X in range(N_subband):   # w_k^n\n","\n","            w_k_old[i].append(1/ (u_k_old[i][X] * np.sqrt(calculate_gain(i,k_m_n[i][X])) *  np.sqrt(calculate_power(i, i, k_m_n[i][X], X))))\n","    for itr_wmmse in range(40):\n","\n","        update_v_k()\n","        update_u_k()\n","        update_w_k()\n","        if u_k_old==u_k_new:\n","            break\n","        u_k_old=u_k_new\n","        w_k_old=w_k_new\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    O_macro_no = []\n","    O_macro_pos = []\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        O_macro_no.append(a)\n","        O_macro_pos.append(b)\n","\n","\n","\n","    print('Final   :',P_macro_subband)\n","\n","\n","\n","    return P_macro_subband, np.sum(O_macro_no)   # action , throughput\n","\n","def update_v_k():\n","    global P_macro_subband\n","    global v_k_new\n","    global u_k_old\n","    global w_k_old\n","    global k_m_n\n","    # for v_k_new\n","    v_k_new = []\n","\n","    for i in range(len(M_x)):  # v_k\n","        v_k_new.append([])\n","\n","        for X in range(N_subband):  # v_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):  # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * (( u_k_old[j][X])**2) * w_k_old[j][X])\n","\n","            #sum_den = sum_den + 1\n","\n","            v_k_new[i].append(\n","                np.sqrt(calculate_gain(i, k_m_n[i][X])) * w_k_old[i][X] * u_k_old[i][X] / sum_den)\n","\n","    P_macro_subband=np.square(v_k_new).tolist()\n","\n","    normalized_check_max()\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    k_m_n = []\n","\n","    # for calculating user association\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        # K_macro_no.append(a)\n","        k_m_n.append(b)\n","\n","    #print(np.square(v_k_new).tolist())\n","    #print(P_macro_subband)\n","\n","    return\n","\n","def update_u_k():\n","    global u_k_new\n","\n","    del_f = 12 * 15 * 10 ** 3\n","    N0 = (10 ** (-174 / 10)) / 1000\n","    u_k_new = []\n","\n","    for i in range(len(M_x)):  # u_k\n","        u_k_new.append([])\n","\n","        for X in range(N_subband):  # u_k^n\n","\n","            sum_den = 0\n","            for j in range(len(M_x)):  # j=1\n","\n","                sum_den = sum_den + (calculate_gain(j, k_m_n[i][X]) * calculate_power(j, i, k_m_n[i][X], X))\n","\n","            sum_den = sum_den + (N0 * del_f)\n","\n","            u_k_new[i].append(\n","                np.sqrt(calculate_gain(i, k_m_n[i][X])) * np.sqrt(calculate_power(i, i, k_m_n[i][X], X)) / sum_den)\n","\n","    #print(u_k_new)\n","\n","    return\n","\n","def update_w_k():\n","    global w_k_new\n","    w_k_new = []\n","\n","    for i in range(len(M_x)):  # w_k\n","        w_k_new.append([])\n","\n","        for X in range(N_subband):  # w_k^n\n","\n","            w_k_new[i].append(1 / (u_k_new[i][X] * np.sqrt(calculate_gain(i, k_m_n[i][X])) * np.sqrt(\n","                calculate_power(i, i, k_m_n[i][X], X))))\n","\n","    return\n","\n","def normalized_check_max():\n","\n","\n","    for i in range(len(M_x)):  #\n","\n","        for X in range(N_subband):  #\n","            P_macro_subband[i][X]= normalized_power(P_macro_subband[i][X])\n","\n","        if np.sum(P_macro_subband[i][0:N_subband]) >2.41:\n","            P_macro_subband[i]=(0.8*np.ones(N_subband)).tolist()\n","\n","    return\n","\n","\n","def normalized_power(inpt):\n","\n","    if inpt <(MC_power[0]+MC_power[1])/2:\n","        output=MC_power[0]\n","    elif (MC_power[0]+MC_power[1])/2 <= inpt < (MC_power[1]+MC_power[2])/2:\n","        output=MC_power[1]\n","    elif (MC_power[1]+MC_power[2])/2 <= inpt < (MC_power[2]+MC_power[3])/2:\n","        output=MC_power[2]\n","    elif (MC_power[2]+MC_power[3])/2 <= inpt < (MC_power[3]+MC_power[4])/2:\n","        output=MC_power[3]\n","    elif (MC_power[3]+MC_power[4])/2 <= inpt :\n","        output=MC_power[4]\n","\n","    return output\n","\n","def optimize_resource_iwf():\n","\n","    global P_macro_subband\n","    global N_subband\n","    global num_U\n","    global num_M\n","    global ln_fl_comb\n","    global final_comb\n","    global k_m_n\n","\n","    for i in range(num_M):\n","        P_macro_subband[i] = final_comb[np.random.randint(0, ln_fl_comb)]\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    K_macro_no = []\n","    k_m_n = []\n","\n","# for calculating user association\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        #K_macro_no.append(a)\n","        k_m_n.append(b)\n","    print(k_m_n)\n","    #g = np.sum(K_macro_no)\n","\n","\n","# for calulating t_m\n","    t_m=[]\n","\n","    for i in range(len(M_x)):      # t_m\n","        t_m.append([])\n","\n","        for X in range(N_subband):   # t_m^n\n","\n","            sum_total = 0\n","            for j in range(len(M_x)):    # j=1, j=/m\n","\n","                if j !=i:\n","\n","                    sum_den = 0\n","                    for l in range(len(M_x)):     #l=1\n","                        sum_den = sum_den + (calculate_power(l, j, k_m_n[j][X], X) * calculate_gain(l, k_m_n[j][X]))\n","\n","                    sum_den = sum_den + 1\n","\n","                    sum_total=sum_total+(calculate_gain(i,k_m_n[j][X]) * calculate_sinr(j,k_m_n[j][X],X) )/sum_den\n","            t_m[i].append(sum_total)\n","\n","    print(t_m)\n","\n","    # for updating the power\n","\n","    gamma_m=10\n","    p_m=[]\n","\n","    for i in range(len(M_x)):      # p_m\n","        p_m.append([])\n","\n","        for X in range(N_subband):   # p_m^n\n","\n","            sum_num = 0\n","            for j in range(len(M_x)):    # j=1, j=/m\n","\n","                if j !=i:\n","\n","                    sum_num = sum_num + (calculate_power(j, j, k_m_n[j][X], X) * calculate_gain(j, k_m_n[j][X]))\n","\n","            sum_num=sum_num+1\n","\n","            p_m[i].append(1/((gamma_m* np.log(2))+t_m[i][X]) - sum_num/calculate_gain(i,k_m_n[i][X]))\n","\n","\n","    print(\"p_m   \", p_m)\n","\n","    return\n","\n","def calculate_sinr(cell_m,user_i,subband_x):\n","\n","    return db_sinr(U_SINR_subband[(num_U*cell_m)+user_i][subband_x])\n","\n","\n","def calculate_gain(cell_m,user_i):\n","\n","    d=U_macro_distance[(num_U*cell_m)+user_i][cell_m]\n","\n","    pl=128.1+37.6*np.log10(d/1000)\n","    G=10**(-pl/10)\n","    #print('G    :',G)\n","    return G\n","\n","def calculate_power(cell_m,cell_n,user_i,subband_x):\n","\n","    pw = P_macro_subband[cell_m][subband_x]\n","    pw_R = transmit_power(thita[(num_U*cell_n)+user_i][subband_x], thita_3db, A_m, power_watt_dbm(pw))\n","    #print(pw,pw_R)\n","    return pw_R\n","\n","\n","\n","def optimize_resource_ga():\n","    global ga_comb\n","    global ga_comb2\n","    global ga_fit_comb\n","    global P_macro_subband\n","    global N_subband\n","    global O_macro_pos\n","    global O_macro_no\n","    global O_macro_sum\n","    global num_M\n","    global num_U\n","    global sub\n","    global slots_slots\n","    global MC_power\n","    global P_max_macro\n","\n","    O_macro_sum=[]\n","    ga_comb_temp=[]\n","\n","    for itr1 in range(6000):\n","        x=[]\n","\n","        for i in range(num_M):\n","           x.extend(profile_power(sub,slots_slots,MC_power,P_max_macro))\n","\n","        ga_comb_temp.append(x)\n","\n","    ga_comb=np.unique(ga_comb_temp,axis=0).tolist()\n","\n","\n","    for itr1 in range(len(ga_comb)):\n","\n","        for i in range(len(M_x)):\n","            P_macro_subband[i]=ga_comb[itr1][i*N_subband: (i+1)*N_subband]\n","\n","        #print(ga_comb_temp[itr1],P_macro_subband)\n","        generate_power_matrix_macro()\n","        throughput()\n","\n","        O_macro_no = []\n","        O_macro_pos = []\n","\n","        for i in range(len(M_x)):\n","            [a,b]=calc_max(i*num_U,((i+1)*num_U))\n","            O_macro_no.append(a)\n","            O_macro_pos.append(b)\n","\n","        O_macro_sum.append(np.sum(O_macro_no))\n","\n","    q=np.sort(O_macro_sum).tolist()\n","    Q = np.sort(O_macro_sum).tolist()\n","    w = np.argsort(O_macro_sum).tolist()\n","    W = np.argsort(O_macro_sum).tolist()\n","\n","    O_macro_no=[]\n","    O_macro_pos=[]\n","    O_macro_sum=[]\n","    ga_fit_comb=[[],[],[],[],[],[],[],[],[],[],[],[]]\n","    ga_comb2=ga_comb\n","\n","    LEN=len(ga_comb2)\n","\n","    for uu in range(3000):\n","        O_macro_no = []\n","        O_macro_pos = []\n","        O_macro_sum=[]\n","        #prev_config=[]\n","\n","        ga_fit_comb[0]=ga_comb[w[-1]]\n","        ga_fit_comb[1] = ga_comb[w[-2]]\n","        ga_fit_comb[2] = ga_comb[w[-3]]\n","        ga_fit_comb[3] = ga_comb[w[-4]]\n","\n","        ga_comb=[]\n","        w=[]\n","        q=[]\n","\n","        [ga_fit_comb[4],ga_fit_comb[5]]=split_merge_ga(ga_fit_comb[0],ga_fit_comb[1])\n","        ga_fit_comb[4]=mutation_ga(ga_fit_comb[4])\n","        ga_fit_comb[5] = mutation_ga(ga_fit_comb[5])\n","\n","        [ga_fit_comb[6], ga_fit_comb[7]] = split_merge_ga(ga_fit_comb[0], ga_fit_comb[2])\n","        ga_fit_comb[6] = mutation_ga(ga_fit_comb[6])\n","        ga_fit_comb[7] = mutation_ga(ga_fit_comb[7])\n","\n","        [ga_fit_comb[8], ga_fit_comb[9]] = split_merge_ga(ga_fit_comb[0], ga_fit_comb[3])\n","        ga_fit_comb[8] = mutation_ga(ga_fit_comb[8])\n","        ga_fit_comb[9] = mutation_ga(ga_fit_comb[9])\n","\n","\n","        [ga_fit_comb[2], ga_fit_comb[3]] = split_merge_ga(ga_comb2[W[np.random.randint(LEN-10, LEN,1)[0]]], ga_comb2[W[np.random.randint(LEN-10, LEN,1)[0]]])\n","        ga_fit_comb[2] = mutation_ga(ga_fit_comb[2])\n","        ga_fit_comb[3] = mutation_ga(ga_fit_comb[3])\n","\n","        [ga_fit_comb[10], ga_fit_comb[11]] = split_merge_ga(ga_comb2[W[np.random.randint(LEN - 50, LEN, 1)[0]]],ga_comb2[W[np.random.randint(LEN - 50, LEN, 1)[0]]])\n","        ga_fit_comb[10] = mutation_ga(ga_fit_comb[10])\n","        ga_fit_comb[11] = mutation_ga(ga_fit_comb[11])\n","\n","        ga_comb = np.unique(ga_fit_comb, axis=0).tolist()\n","\n","        OM_position=[]\n","\n","        for itr1 in range(len(ga_comb)):\n","\n","            for i in range(len(M_x)):\n","                P_macro_subband[i] = ga_comb[itr1][i * N_subband: (i + 1) * N_subband]\n","\n","            # print(ga_comb_temp[itr1],P_macro_subband)\n","            generate_power_matrix_macro()\n","            throughput()\n","\n","            O_macro_no = []\n","            O_macro_pos = []\n","\n","            for i in range(len(M_x)):\n","                [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","                O_macro_no.extend(a)\n","                O_macro_pos.extend(b)\n","\n","            #print(O_macro_pos)\n","            OM_position.append(O_macro_pos)\n","            O_macro_sum.append(np.sum(O_macro_no))\n","\n","        #print(O_macro_sum)\n","\n","        q = np.sort(O_macro_sum).tolist()\n","        w = np.argsort(O_macro_sum).tolist()\n","\n","        current_config = ga_comb[w[-1]]\n","\n","        if uu==0:\n","            prev_config= ga_comb[w[-1]]\n","            cont_itr=0\n","\n","        if current_config==prev_config :\n","            cont_itr=cont_itr+1\n","        else:\n","            cont_itr=0\n","\n","        prev_config=ga_comb[w[-1]]\n","\n","\n","        if cont_itr >500:\n","            break\n","\n","    power_config=ga_comb[w[-1]]\n","    ff=np.digitize(power_config,MC_power).tolist()\n","    ff.extend(OM_position[w[-1]])\n","    #print(\"power_config\",ff)\n","    #g_ga_th.append(q[-1])\n","    #print(\"throughput_ga :\", q[-1])\n","    return power_config,ff,q[-1]\n","\n","def calc_max(xi,xe):\n","    global U_throughput_subband\n","\n","    return np.amax(U_throughput_subband[xi:xe],axis=0).tolist() , np.argmax(U_throughput_subband[xi:xe],axis=0).tolist()\n","\n","\n","def split_merge_ga(v1,v2):\n","\n","    z1=[]\n","    z2=[]\n","    a=np.random.randint(1,num_M+1,1)\n","    b = np.random.randint(0, num_M+1 - a, 1)\n","\n","    temp_v11=v1[0:(a[0]-1)*N_subband]\n","    temp_v12 = v1[(a[0]-1) * N_subband: (a[0]+b[0])*N_subband]\n","    temp_v13 = v1[(a[0] + b[0]) * N_subband:]\n","\n","    temp_v21 = v2[0:(a[0] - 1) * N_subband]\n","    temp_v22 = v2[(a[0] - 1) * N_subband: (a[0] + b[0]) * N_subband]\n","    temp_v23 = v2[(a[0] + b[0]) * N_subband:]\n","\n","    z1.extend(temp_v11)\n","    z1.extend(temp_v22)\n","    z1.extend(temp_v13)\n","\n","    z2.extend(temp_v21)\n","    z2.extend(temp_v12)\n","    z2.extend(temp_v23)\n","\n","    return z1, z2\n","\n","def mutation_ga(v):\n","\n","    global MC_power\n","    z=[]\n","\n","    temp=v[:]\n","\n","    a=np.random.randint(0,7,1)\n","    if a[0]==1:\n","        ln=len(v)\n","        p1=np.random.randint(0,ln,1)\n","        q1=np.random.randint(0,len(MC_power),1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]]=MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","\n","        right=check_max(temp)\n","\n","        if right <0.5:\n","            z=temp\n","        else:\n","            z=v\n","\n","    elif a[0] == 2:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","    elif a[0] == 3:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        p4 = np.random.randint(0, ln, 1)\n","        q4 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","        temp[p4[0]] = MC_power[q4[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","    elif a[0] == 4:\n","        ln = len(v)\n","        p1 = np.random.randint(0, ln, 1)\n","        q1 = np.random.randint(0, len(MC_power), 1)\n","\n","        p2 = np.random.randint(0, ln, 1)\n","        q2 = np.random.randint(0, len(MC_power), 1)\n","\n","        p3 = np.random.randint(0, ln, 1)\n","        q3 = np.random.randint(0, len(MC_power), 1)\n","\n","        p4 = np.random.randint(0, ln, 1)\n","        q4 = np.random.randint(0, len(MC_power), 1)\n","\n","        p5 = np.random.randint(0, ln, 1)\n","        q5 = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p1[0]] = MC_power[q1[0]]\n","        temp[p2[0]] = MC_power[q2[0]]\n","        temp[p3[0]] = MC_power[q3[0]]\n","        temp[p4[0]] = MC_power[q4[0]]\n","        temp[p5[0]] = MC_power[q5[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","\n","    else :\n","        ln = len(v)\n","        p = np.random.randint(0, ln, 1)\n","        q = np.random.randint(0, len(MC_power), 1)\n","\n","        temp[p[0]] = MC_power[q[0]]\n","\n","        right = check_max(temp)\n","\n","        if right < 0.5:\n","            z = temp\n","        else:\n","            z = v\n","\n","\n","    return z\n","\n","\n","def check_max(v):\n","\n","    z=0\n","    for irr in range(num_M):\n","\n","        if np.sum(v[irr*N_subband:(irr+1)*N_subband]) <= 2.5 :\n","            z=(z | 0)\n","        else:\n","            z= (z | 1)\n","\n","    return z\n","\n","def check_ga_with_drl(action):\n","    global g_total_call\n","    global g_total_corrected\n","    global final_comb\n","    global M_x\n","    global ln_fl_comb\n","    action_drl=[]\n","    if (g_cntr-1) < g_data_len:\n","        #print(\"running ---------------\")\n","        action_ga=data_set['arr_2'][g_cntr-1].tolist()\n","        ga_th=data_set['arr_3'][g_cntr-1].tolist()\n","        action_wmmse = data_set['arr_4'][g_cntr - 1].tolist()\n","        wmmse_th = data_set['arr_5'][g_cntr - 1].tolist()\n","\n","    else:\n","\n","        action_ga,_,ga_th=optimize_resource_ga()\n","        g_data_action_ga.append(action_ga)\n","        g_data_ga_th.append(ga_th)\n","        action_wmmse, wmmse_th = optimize_resource_wmmse()\n","        g_data_action_wmmse.append(action_wmmse)\n","        g_data_wmmse_th.append(wmmse_th)\n","\n","\n","    g_ga_th.append(ga_th)\n","    g_wmmse_th.append(wmmse_th)\n","\n","    #print(\"throughput_ga :\", ga_th)\n","\n","    for i in range(len(M_x)):\n","        action_drl.extend(final_comb[action[i]-i*ln_fl_comb])\n","    answer=np.double(action_drl==action_ga)\n","    print(answer,action_drl,action_ga)\n","    g_total_call=g_total_call+1\n","    g_total_corrected=g_total_corrected+answer\n","    g_drl_th.append(g_drl_th_val)\n","\n","    g_eql_th.append(g_eql_th_val)\n","    g_rnd_th.append(g_rnd_th_val)\n","\n","\n","\n","    print(\"Throughput GA: \",ga_th,' DRL: ', g_drl_th_val,' EQL: ', g_eql_th_val,' RND: ',g_rnd_th_val,' WMMSE: ',wmmse_th)\n","    np.savez(\"result_5c_3h_5p.npz\", g_drl_th, g_ga_th,g_eql_th,g_rnd_th,g_wmmse_th)\n","    np.save(\"counter_v2_5c_3h_5p_lr1.npy\",g_cntr)\n","    if g_cntr > g_data_len:\n","        np.savez(\"data_set_5c.npz\",g_data_x,g_data_y,g_data_action_ga,g_data_ga_th,g_data_action_wmmse,g_data_wmmse_th)\n","\n","\n","    return\n","\n","\n","########################################################################################################################\n","\n","# functions related to DQN\n","def self_env_step(a):\n","    global ln_fl_comb\n","    global M_x\n","    global P_max_macro\n","    global num_U\n","    global num_M\n","    global g_counter\n","    global O_macro_no\n","    global O_macro_pos\n","    global final_comb\n","    global current_throughput\n","    global previous_throughput\n","\n","    g_counter=g_counter+1\n","\n","    for i in range(len(M_x)):\n","        P_macro_subband[i] = final_comb[a[i]-i*ln_fl_comb]\n","\n","    generate_power_matrix_macro()\n","    throughput()\n","\n","    O_macro_no = []\n","    O_macro_pos = []\n","\n","    for i in range(len(M_x)):\n","        [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","        O_macro_no.append(a)\n","        O_macro_pos.append(b)\n","\n","    current_throughput=np.sum(O_macro_no)\n","\n","    if current_throughput> previous_throughput and g_counter<=10:\n","        if current_throughput==previous_throughput:\n","            reward=1\n","        else:\n","            reward = 1\n","        done=False\n","\n","        previous_throughput=current_throughput\n","\n","        temp_var = []     # temp_var here means next state\n","\n","        for i in range(num_M * num_U):\n","            temp_var.extend(U_CQI_subband[i])\n","            temp_var.append(np.double(U_macro_distance[i][U_association_macro[i] - 1] / R_m >= 0.5))\n","    else:\n","        if g_counter>10 and current_throughput>=previous_throughput:\n","            reward=1\n","        else:\n","            reward=1\n","        temp_var=None\n","        done=True\n","\n","\n","\n","    return np.array(temp_var), reward, done, current_throughput\n","\n","\n","\n","\n","# ----------\n","HUBER_LOSS_DELTA = 1.0\n","LEARNING_RATE = 0.00025\n","\n","# ----------\n","def huber_loss(y_true, y_pred):\n","    err = y_true - y_pred\n","\n","    cond = K.abs(err) < HUBER_LOSS_DELTA\n","    L2 = 0.5 * K.square(err)\n","    L1 = HUBER_LOSS_DELTA * (K.abs(err) - 0.5 * HUBER_LOSS_DELTA)\n","\n","    loss = tf.where(cond, L2, L1)  # Keras does not cover where function in tensorflow :-(\n","\n","    return K.mean(loss)\n","\n","\n","# -------------------- BRAIN ---------------------------\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.optimizers import *\n","\n","class Brain:\n","    def __init__(self, stateCnt, actionCnt):\n","        self.stateCnt = stateCnt\n","        self.actionCnt = actionCnt\n","\n","        self.model = self._createModel()\n","        self.model_ = self._createModel()\n","\n","    def _createModel(self):\n","        model = Sequential()\n","\n","        model.add(Dense(units=actionCnt*4, activation='relu', input_dim=stateCnt))\n","        model.add(Dense(units=actionCnt * 3, activation='relu'))\n","        model.add(Dense(units=actionCnt*2,activation='relu'))\n","        model.add(Dense(units=actionCnt, activation='linear'))\n","\n","        opt = RMSprop(lr=LEARNING_RATE)\n","        model.compile(loss=huber_loss, optimizer=opt)\n","        #model.compile(loss='mse', optimizer=opt)\n","\n","        return model\n","\n","    def train(self, x, y, epochs=1, verbose=0):\n","        self.model.fit(x, y, batch_size=64*1, epochs=epochs, verbose=verbose)\n","\n","    def predict(self, s, target=False):\n","        if target:\n","            return self.model_.predict(s)\n","        else:\n","            return self.model.predict(s)\n","\n","    def predictOne(self, s, target=False):\n","\n","        return self.predict(s.reshape(1, self.stateCnt), target=target).flatten()\n","        #return self.predict([s], target=target)\n","\n","    def updateTargetModel(self):\n","        self.model_.set_weights(self.model.get_weights())\n","\n","\n","\n","# -------------------- MEMORY --------------------------\n","class Memory:  # stored as ( s, a, r, s_ )\n","    samples = []\n","\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","\n","    def add(self, sample):\n","        self.samples.append(sample)\n","\n","        if len(self.samples) > self.capacity:\n","            self.samples.pop(0)\n","\n","    def sample(self, n):\n","        n = min(n, len(self.samples))\n","        return random.sample(self.samples, n)\n","\n","    def isFull(self):\n","        return len(self.samples) >= self.capacity\n","\n","\n","\n","# -------------------- AGENT ---------------------------\n","MEMORY_CAPACITY = 50000\n","BATCH_SIZE = 64\n","\n","GAMMA = 0.99\n","\n","MAX_EPSILON = 1\n","MIN_EPSILON = 0.01\n","LAMBDA = 0.001  # speed of decay\n","\n","UPDATE_TARGET_FREQUENCY = 1000\n","\n","\n","class Agent:\n","    steps = 0\n","    epsilon = MAX_EPSILON\n","\n","    def __init__(self, stateCnt, actionCnt):\n","        self.stateCnt = stateCnt\n","        self.actionCnt = actionCnt\n","\n","        self.brain = Brain(stateCnt, actionCnt)\n","        self.memory = Memory(MEMORY_CAPACITY)\n","\n","    def act(self, s):\n","        global num_M\n","        global ln_fl_comb\n","\n","        temp_arg= self.brain.predictOne(s)\n","        #print(\"temp_arg\",len(temp_arg))\n","        z=[]\n","        for i in range(num_M):\n","            z.append(i*ln_fl_comb+np.argmax(temp_arg[i*ln_fl_comb:(i+1)*ln_fl_comb]))\n","\n","            if random.random() < self.epsilon:\n","                z[i]=np.random.randint(i * ln_fl_comb, (i + 1) * ln_fl_comb)\n","                #print(\"yes\", i,z[i],self.epsilon)\n","\n","        return z\n","\n","\n","    def observe(self, sample):  # in (s, a, r, s_) format\n","        self.memory.add(sample)\n","\n","        if self.steps % UPDATE_TARGET_FREQUENCY == 0:\n","            self.brain.updateTargetModel()\n","            np.save(\"data_5c_3h_5p.npy\", agent.memory.samples)\n","            np.save(\"step_5c_3h_5p.npy\",agent.steps)\n","            agent.brain.model.save(\"dqn_5c_3h_5p.h5\")\n","\n","        # debug the Q function in poin S\n","        if self.steps % 100 == 0:\n","            S = init_env\n","            pred = agent.brain.predictOne(S)\n","            print(pred)\n","            sys.stdout.flush()\n","\n","        # slowly decrease Epsilon based on our eperience\n","        self.steps += 1\n","        self.epsilon = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * math.exp(-LAMBDA * self.steps)\n","\n","    def replay(self):\n","        batch = self.memory.sample(BATCH_SIZE)\n","        batchLen = len(batch)\n","\n","        no_state = np.zeros(self.stateCnt)\n","\n","        states = np.array([o[0] for o in batch])\n","        #print(\"states\", states.shape)\n","        states_ = np.array([(no_state if o[3] is None else o[3]) for o in batch])\n","        #print(\"states-----\",states_)\n","        p = self.brain.predict(states)\n","        p_ = self.brain.predict(states_, target=True)\n","\n","        x = np.zeros((batchLen, self.stateCnt))\n","        y = np.zeros((batchLen, self.actionCnt))\n","\n","        for i in range(batchLen):\n","            o = batch[i]\n","            s = o[0]; a = o[1]; r = o[2]; s_ = o[3]\n","            #print(\"a    =\",a)\n","\n","            t = p[i]\n","            #print(\"before   :\",t)\n","            if s_ is None:\n","                t[a] = r\n","            else:\n","                t[a] = r + GAMMA * np.amax(p_[i])\n","            #t[a] = r + GAMMA * np.amax(p_[i])\n","            #print(\"after   :\",t)\n","            x[i] = s\n","            y[i] = t\n","\n","        self.brain.train(x, y)\n","\n","\n","class RandomAgent:\n","    memory = Memory(MEMORY_CAPACITY)\n","    #memory = Memory(10000)\n","\n","    def __init__(self, actionCnt):\n","        self.actionCnt = actionCnt\n","\n","    def act(self, s):\n","        global num_M\n","        global ln_fl_comb\n","        z=[]\n","        for i in range(num_M):\n","            z.append(np.random.randint(i*ln_fl_comb,(i+1)*ln_fl_comb))\n","        return z\n","\n","    def observe(self, sample):  # in (s, a, r, s_) format\n","        self.memory.add(sample)\n","\n","    def replay(self):\n","        pass\n","\n","\n","\n","# -------------------- ENVIRONMENT ---------------------\n","class Environment:\n","    def __init__(self, problem):\n","        self.problem = problem\n","        #self.env = gym.make(problem)\n","\n","    def run(self, agent):\n","        global g_action\n","        global g_drl_th_val\n","        global ln_fl_comb\n","        global M_x\n","        #s = self.env.reset()\n","        #s_ini,s=self.env_reset(agent)\n","        s,s_ini = self.env_reset(agent)\n","        #print(s_ini)\n","        R = 0\n","        #g_action = [0 + ln_fl_comb * i for i in range(len(M_x))]\n","\n","        while True:\n","            #self.env.render()\n","\n","            a = agent.act(s)\n","            #print(a)\n","\n","            #s_, r, done, info = self.env.step(a)\n","            s_,r,done, t_th = self_env_step(a)\n","            #print(\"type s_--\",type(s_))\n","\n","            if done:  # terminal state\n","                s_ = None\n","\n","            agent.observe((s, a, r, s_))\n","            agent.replay()\n","\n","            s = s_\n","            R += r\n","\n","            if done:\n","                break\n","\n","            g_action=a\n","            g_drl_th_val=t_th\n","\n","        print(\"Total reward:\", R)\n","        action_drl = []\n","        for i in range(len(M_x)):\n","            action_drl.extend(final_comb[g_action[i] - i * ln_fl_comb])\n","        print(action_drl)\n","        return R, g_action\n","\n","    def env_reset(self, agent):\n","\n","        global thita\n","        global g_drl_th_val\n","        global g_eql_th_val\n","        global g_rnd_th_val\n","        global thita_3db\n","        global P_max_macro\n","        global MC_power\n","        global slots_slots\n","        global sub\n","        global A_m\n","        global R_m\n","        global num_U\n","        global num_M\n","        global M_x\n","        global M_y\n","        global M_cell_beam\n","        global M_cell_associated_user_id\n","        global U_x\n","        global U_y\n","        global U_association_macro\n","        global U_neighbor\n","        global U_neighbor_sector\n","        global M_cell_region_x\n","        global M_cell_region_y\n","        global U_macro_distance\n","        global U_macro_power\n","        global M_cell_txblock_power\n","        global P_macro_subband\n","        global U_received_power_subband\n","        global U_throughput_subband\n","        global U_SINR_subband\n","        global U_CQI_subband\n","        global g_action\n","        global g_cntr\n","\n","        global current_throughput\n","        global previous_throughput\n","\n","        global g_counter\n","\n","        global k_m_n\n","        global v_k_old\n","        global u_k_old\n","        global w_k_old\n","\n","        global v_k_new\n","        global u_k_new\n","        global w_k_new\n","\n","        k_m_n=[]\n","        v_k_old=[]\n","        u_k_old=[]\n","        w_k_old=[]\n","\n","        v_k_new=[]\n","        u_k_new=[]\n","        w_k_new=[]\n","\n","\n","        g_counter = 0\n","        current_throughput = []\n","        previous_throughput = 0\n","        g_drl_th_val = 0\n","        g_eql_th_val = 0\n","        g_rnd_th_val=0\n","\n","        M_cell_beam = []\n","        M_cell_associated_user_id = []\n","        M_cell_region_x = []\n","        M_cell_region_y = []\n","        M_cell_txblock_power = []\n","\n","\n","\n","        U_x = []\n","        U_y = []\n","        U_association_macro = []\n","        U_neighbor = []\n","        U_neighbor_sector = []\n","        U_macro_distance = []\n","        U_macro_power = []\n","        U_throughputt = []\n","\n","        P_macro_subband = []\n","        U_received_power_subband = []\n","        U_throughput_subband = []\n","\n","        U_SINR_subband = []\n","        U_CQI_subband = []\n","\n","        itr = 0\n","        for i in range(len(M_x)):\n","            M_cell_beam.append(random_beam())\n","            M_cell_associated_user_id.append([])\n","\n","            for j in range(num_U):\n","                M_cell_associated_user_id[i].extend([itr + 1])\n","                U_association_macro.append(i + 1)\n","                itr = itr + 1\n","\n","            #[x, y] = random_allocation(M_x[i], M_y[i], 360, 0.2 * R_m, R_m, num_U)\n","            #U_x.extend(x)\n","            #U_y.extend(y)\n","\n","\n","# ***********************************************************************************************************************\n","\n","        #g_data_x.append(U_x)\n","        #g_data_y.append(U_y)\n","        if g_cntr<g_data_len:\n","            U_x=data_set['arr_0'][g_cntr].tolist()\n","            #print(U_x)\n","            U_y = data_set['arr_1'][g_cntr].tolist()\n","\n","        else:\n","            for i in range(len(M_x)):\n","\n","                [x, y] = random_allocation(M_x[i], M_y[i], 360, 0.2 * R_m, R_m, num_U)\n","                U_x.extend(x)\n","                U_y.extend(y)\n","\n","            g_data_x.append(U_x)\n","            g_data_y.append(U_y)\n","\n","        g_cntr=g_cntr+1\n","\n","\n","# ***********************************************************************************************************************\n","        for i in range(len(U_x)):\n","            U_neighbor.append([])\n","            U_neighbor_sector.append([])\n","\n","        for i in range(len(M_x)):\n","            M_cell_region_x.append([[], [], []])\n","            M_cell_region_y.append([[], [], []])\n","\n","            for j in range(3):\n","                [a, b] = find_points_in_angle(M_x[i], M_y[i], U_x, U_y, M_cell_beam[i][j], i + 1, j + 1)\n","                M_cell_region_x[i][j].extend(a)\n","                M_cell_region_y[i][j].extend(b)\n","\n","        thita = np.zeros((len(U_x), len(M_x)))\n","\n","        for i in range(len(U_x)):\n","            U_macro_distance.append([])\n","            U_macro_power.append([])\n","\n","            for j in range(len(M_x)):\n","                U_macro_distance[i].append(find_dis(U_x[i], U_y[i], M_x[j], M_y[j]))\n","                angl = M_cell_beam[j][U_neighbor_sector[i][j] - 1]\n","\n","                thita[i][j] = find_angl(M_x[j], M_y[j], U_x[i], U_y[i], angl)\n","                a = transmit_power(thita[i][j], thita_3db, A_m, power_watt_dbm(P_max_macro))\n","                U_macro_power[i].append(pw_m_hata(a, U_macro_distance[i][j]))\n","\n","        for i in range(len(M_x)):\n","            M_cell_txblock_power.append(profile_power(sub, slots_slots, MC_power, P_max_macro))\n","            P_macro_subband.append(M_cell_txblock_power[i])\n","\n","        generate_power_matrix_macro()\n","\n","        throughput()\n","\n","        temp_var = []\n","\n","        for i in range(num_M * num_U):\n","            temp_var.extend(U_CQI_subband[i])\n","            temp_var.append(np.double(U_macro_distance[i][U_association_macro[i] - 1] / R_m >= 0.5))\n","\n","        #a = agent.act(np.array(temp_var))\n","        #g_action = a\n","\n","        g_action = [0 + ln_fl_comb * i for i in range(len(M_x))]\n","\n","        #for i in range(len(M_x)):\n","            #P_macro_subband[i] = final_comb[a[i] - i * ln_fl_comb]\n","\n","        for i in range(len(M_x)):\n","            P_macro_subband[i] = final_comb[0]\n","\n","        generate_power_matrix_macro()\n","        throughput()\n","\n","        temp_var2 = []\n","\n","        for i in range(num_M * num_U):\n","            temp_var2.extend(U_CQI_subband[i])\n","            temp_var2.append(np.double(U_macro_distance[i][U_association_macro[i] - 1] / R_m >= 0.5))\n","\n","        O_macro_no = []\n","        O_macro_pos = []\n","\n","        for i in range(len(M_x)):\n","            [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","            O_macro_no.append(a)\n","            O_macro_pos.append(b)\n","\n","        previous_throughput = np.sum(O_macro_no)\n","        g_drl_th_val = previous_throughput\n","\n","\n","\n","# Maximum power allocation  ##############################################\n","\n","        for i in range(len(M_x)):\n","            P_macro_subband[i] = 0.8*np.ones(N_subband)\n","\n","        generate_power_matrix_macro()\n","        throughput()\n","\n","        O_macro_no = []\n","        O_macro_pos = []\n","\n","        for i in range(len(M_x)):\n","            [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","            O_macro_no.append(a)\n","            O_macro_pos.append(b)\n","\n","        g_eql_th_val = np.sum(O_macro_no)\n","\n","# Random power allocation  ##############################################\n","        for i in range(num_M):\n","            P_macro_subband[i] = final_comb[np.random.randint(0,ln_fl_comb)]\n","\n","        generate_power_matrix_macro()\n","        throughput()\n","\n","        O_macro_no = []\n","        O_macro_pos = []\n","\n","        for i in range(len(M_x)):\n","            [a, b] = calc_max(i * num_U, ((i + 1) * num_U))\n","            O_macro_no.append(a)\n","            O_macro_pos.append(b)\n","\n","        g_rnd_th_val = np.sum(O_macro_no)\n","\n","        return np.array(temp_var), np.array(temp_var2)\n","\n","########################################################################################################################\n","\n","# variable definition\n","\n","current_throughput=[]\n","previous_throughput=0\n","\n","g_counter=0\n","g_action=[]\n","g_total_call=0\n","g_total_corrected=0\n","g_ga_th=[]\n","g_wmmse_th=[]\n","g_drl_th_val=0\n","g_drl_th=[]\n","g_eql_th_val=0\n","g_rnd_th_val=0\n","g_eql_th=[]\n","g_rnd_th=[]\n","\n","g_cntr=0\n","g_data_len=0\n","\n","g_data_x=[]\n","g_data_y=[]\n","\n","g_data_action_ga=[]\n","g_data_ga_th=[]\n","\n","g_data_action_wmmse=[]\n","g_data_wmmse_th=[]\n","\n","\n","\n","M_cell_beam=[]\n","M_cell_associated_user_id=[]\n","M_cell_cor_x=[]\n","M_cell_cor_y=[]\n","M_cell_region_x=[]\n","M_cell_region_y=[]\n","M_cell_txblock_power=[]\n","\n","U_x=[]\n","U_y=[]\n","U_association_macro=[]\n","U_neighbor=[]\n","U_neighbor_sector=[]\n","U_macro_distance=[]\n","U_macro_power=[]\n","U_throughputt=[]\n","\n","P_macro_subband=[]\n","\n","U_received_power_subband=[]\n","U_throughput_subband=[]\n","U_SINR_subband=[]\n","U_CQI_subband=[]\n","\n","ga_comb=[]\n","ga_comb2=[]\n","ga_fit_comb=[]\n","\n","O_macro_no=[]\n","O_macro_pos=[]\n","O_macro_sum=[]\n","\n","thita=[]\n","\n","\n","thita_3db=70\n","A_m=35\n","P_max_macro=40\n","alpha=25\n","r=1000\n","R_m=500\n","min_RM=600\n","num_M=5\n","num_U=5\n","N=9000\n","N_subband=3\n","\n","MC_power_1=[0.4, 0.6, 0.8,1.0,1.2]\n","MC_power=[0.4,0.6, 0.8,1.0,1.2]\n","\n","N_RB=48\n","N_slot=1\n","N_subframes=1\n","sub=[]\n","slots_slots=[1]\n","sub.append(mt.floor(N_RB/N_subband))\n","sub.append(mt.floor(N_RB/N_subband))\n","\n","# for 5 cell system\n","M_x=[272, -270, -72, 490, -804]\n","M_y=[668, 136, -839, -100, -405]\n","\n","# for 10 cell system\n","#M_x=[-507.325029580438,1002.33404665068,145.312062677023,200.78357265330,1638.02723651541,1373.51667496699,-505.567176719993,89.0624746033709,888.768341569969,700.98746226480]\n","#M_y=[622.439530990585,1204.09269092070,-857.441644095846,0.776230721301,-266.682269021143,409.885301601770,-276.654621800917,971.99443198228,-404.073417200223,500.42153804114]\n","\n","# for 15 cell system\n","#M_x=[-507.325029580438,1002.33404665068,145.312062677023,1008.94157032003,200.78357265330,1638.02723651541,1373.51667496699,-505.567176719993,89.0624746033709,208.3844792471699,-1205.45088276488,-1203.86653509258,888.768341569969,-623.017861398548,700.98746226480]\n","#M_y=[622.439530990585,1204.09269092070,-857.441644095846,-1254.30978634305,0.776230721301,-566.682269021143,309.885301601770,-276.654621800917,971.99443198228,-1708.16795562791,281.640997912069,-609.705714626437,-404.073417200223,-1209.60615767022,500.42153804114]\n","\n","\n","sub.append(N_RB-sub[N_subband-2]*(N_subband-1))\n","#print(sub)\n","final_comb=[]\n","P_own=[]\n","P_intr=[]\n","P_SINR=[]\n","\n","\n","# final_comb : combination of all the actions for a particular cell\n","\n","power_comb = list(map(list, itertools.product(MC_power_1, repeat=N_subband)))\n","\n","for i in power_comb:\n","    temp_sum=0.0\n","    for j in range(N_subband):\n","        temp_sum=temp_sum+ i[j]*sub[j]\n","    if temp_sum <=40 :\n","        final_comb.append(i)\n","\n","ln_fl_comb=len(final_comb)\n","\n","#print(final_comb[12])\n","\n","plt.figure(1)\n","plt.plot(M_x,M_y,'b*')\n","\n","for i in range(len(M_x)):\n","    circle(M_x[i],M_y[i],R_m)\n","#plt.show()  # to plot the figure\n","\n","\n","\n","\n","\n","# -------------------- MAIN ----------------------------\n","PROBLEM = 'CartPole-v0'\n","env = Environment(PROBLEM)\n","\n","#stateCnt = env.env.observation_space.shape[0]\n","stateCnt=num_M*num_U*(3+1)\n","#actionCnt = env.env.action_space.n\n","actionCnt=ln_fl_comb*num_M\n","print(\"actions    :\",actionCnt)\n","agent = Agent(stateCnt, actionCnt)\n","########################################################################################################################\n","agent.brain.model.load_weights(\"dqn_5c_3h_5p.h5\")\n","agent.brain.model_.load_weights(\"dqn_5c_3h_5p.h5\")\n","RandomAgent.memory.samples = np.load(\"data_5c_3h_5p.npy\").tolist()\n","agent.steps=np.load(\"step_5c_3h_5p.npy\").tolist()\n","########################################################################################################################\n","\n","\n","########################################################################################################################\n","#drl=np.load(\"result_5c_3h_5p.npz\")\n","#g_drl_th=drl['arr_0'].tolist()\n","#g_ga_th=drl['arr_1'].tolist()\n","#g_eql_th=drl['arr_2'].tolist()\n","#g_rnd_th=drl['arr_3'].tolist()\n","#g_wmmse_th=drl['arr_4'].tolist()\n","\n","########################################################################################################################\n","randomAgent = RandomAgent(actionCnt)\n","\n","init_env,no_use=env.env_reset(agent)\n","\n","try:\n","    while randomAgent.memory.isFull() == False:\n","        env.run(randomAgent)\n","\n","\n","    agent.memory.samples = randomAgent.memory.samples\n","    randomAgent = None\n","\n","    g_cntr=0\n","    g_data_x=[]\n","    g_data_y=[]\n","\n","    ########################################################################################################################\n","    #g_cntr=np.load(\"counter_v2_5c_3h_5p_lr1.npy\").tolist()\n","    data_set = np.load(\"data_set_5c.npz\")\n","    g_data_len = len(data_set['arr_0'])\n","    g_data_x = data_set['arr_0'].tolist()\n","    g_data_y = data_set['arr_1'].tolist()\n","    g_data_action_ga = data_set['arr_2'].tolist()\n","    g_data_ga_th = data_set['arr_3'].tolist()\n","    g_data_action_wmmse = data_set['arr_4'].tolist()\n","    g_data_wmmse_th = data_set['arr_5'].tolist()\n","\n","    print(g_data_len,g_cntr)\n","\n","    ########################################################################################################################\n","\n","    while True:\n","        rward,actn= env.run(agent)\n","        sys.stdout.flush()\n","        check_ga_with_drl(actn)\n","        #print(\"total call vs corrected answer :\", g_total_call,g_total_corrected)\n","finally:\n","    agent.brain.model.save(\"dqn_5c_3h_5p.h5\")\n","    np.save(\"data_5c_3h_5p.npy\", agent.memory.samples)\n","\n","    print(\"total call vs corrected answer :\", g_total_call,g_total_corrected)"]},{"cell_type":"markdown","metadata":{"id":"8dZ0R9PlOMYE"},"source":["## # 미로찾기 7\n","---"]},{"cell_type":"markdown","metadata":{"id":"6zjfR67pOdWp"},"source":["### # preprocessing\n","---"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"VYuq8fWtONT7","executionInfo":{"status":"ok","timestamp":1654233623087,"user_tz":-540,"elapsed":264,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from collections import deque\n","from sklearn.utils import shuffle\n","from keras.losses import mean_squared_error\n","import copy\n","import random\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input, Dense, Reshape, Conv2D, Flatten\n","\n","# Labyrinth Matrix\n","maze = np.array(\n","    [[0, 0, 0, 0, 0, 0, ],\n","     [1, 0, 1, 1, 1, 1, ],\n","     [1, 0, 1, 0, 0, 0, ],\n","     [1, 0, 0, 0, 1, 1, ],\n","     [0, 1, 0, 0, 0, 0, ]]\n",")\n","# The model file to be stored\n","model_name = '/content/drive/MyDrive/workspace/cakd5/3차_project/작업물/김기현/data/model/dqn_model.h5'\n","\n","# When walking to (row,col), let the value of the maze matrix at (row,col) is POS_VALUE\n","TMP_VALUE = 2\n","# Starting point\n","start_state_pos = (0,0)\n","# End point\n","target_state_pos = (2, 5)\n","# Action dictionary\n","actions = dict(\n","    up = 0,\n","    down = 1,\n","    left = 2,\n","    right = 3\n",")\n","# The action dimension is also the dimension to be output by the neural network\n","action_dimention = len(actions)\n","# Reward value dictionary, reward 1, go to the end, reward -0.01, go 1 or out of bounds-1\n","reward_dict = {'reward_0': -1, 'reward_1': -0.01, 'reward_2': 1}\n","\n","\n","\n","# Convert the maze matrix to image format shape(height,width,channel) \n","def matrix_to_img(row,col):\n","    state = copy.deepcopy(maze)\n","    state[row, col] = TMP_VALUE\n","    # Dimension conversion\n","    state = np.reshape(state,newshape=(1, state.shape[0],state.shape[1],1))\n","    return state"]},{"cell_type":"markdown","metadata":{"id":"WQnl2gk8OfvQ"},"source":["### # agent\n","---"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"I70mZKsqOYTE","executionInfo":{"status":"ok","timestamp":1654233726961,"user_tz":-540,"elapsed":263,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[],"source":["class DQNAgent:\n","    def __init__(self,agent_model=None):\n","        self.memory = deque(maxlen=100)\n","        self.alpha = 0.01\n","        self.gamma = 0.9  # decay rate\n","        # exploration rate of the action exploration\n","        self.epsilon = 1\n","        # minimum exploration rate\n","        self.epsilon_min = 0.2\n","        # exploration decay rate\n","        self.epsilon_decay = 0.995\n","        #\n","        self.learning_rate = 0.001\n","        if agent_model is None:\n","            self.model = self.dqn_model()\n","        else:\n","            self.model = agent_model\n","\n","\n","    # Model \n","    def dqn_model(self):\n","        inputs = Input(shape=(maze.shape[0], maze.shape[1],1))\n","        layer1 = Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same')(inputs)\n","        layer2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer1)\n","        layer3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(layer2)\n","        layer4 = Flatten()(layer3)\n","        predictions = Dense(action_dimention, activation='softmax')(layer4)\n","        model = Model(inputs=inputs, outputs=predictions)\n","        model.compile(optimizer='sgd',\n","                      loss=mean_squared_error,\n","                      )\n","        return model\n","\n","    # Save the current state current_state, action action, reward value reward, next state next_state, whether the game is over done \n","    def remember(self,current_state, action, reward, next_state, done):\n","        self.memory.append((current_state, action, reward, next_state, done))\n","\n","    # Choose action, self.epsilon is the action exploration threshold \n","    def choose_action(self, state):\n","        # Choose action randomly \n","        if np.random.rand() < self.epsilon:\n","            action = random.choice(list(actions.keys()))\n","            action = actions.get(action)\n","            return action\n","        # predict the action to be selected based on the current state \n","        else:\n","            act_values = self.model.predict(state)\n","            # Because the maximum value of pd.Series data may appear multiple, and argmax() only takes the first one, use shuffle in sklearn to shuffle the order,\n","            action = np.argmax(shuffle(pd.Series(act_values[0])))\n","            return action\n","\n","    # Randomly select (current_state, action, reward, next_state, done) from the memory container self.memory, and then send it to the model for training \n","    def repay(self, batch_size):\n","        batch_size = min(batch_size, len(self.memory))\n","        batch_random_choice = np.random.choice(len(self.memory),batch_size)\n","        for i in batch_random_choice:\n","            current_state, action, reward, next_state, done = self.memory[i]\n","\n","            # target_f target value\n","            target_f = self.model.predict(current_state)\n","            if done:\n","                target = reward\n","            else:\n","                target = reward + self.alpha * (self.gamma * np.max(self.model.predict(next_state)[0]) - target_f[0][action])\n","            target_f[0][action] = target\n","\n","            # Train the model and update the weight\n","            self.model.fit(current_state, target_f, epochs=2, verbose=0)\n","            # Update the exploration rate \n","            if self.epsilon > self.epsilon_min:\n","                self.epsilon = self.epsilon * self.epsilon_decay\n","            else:\n","                self.epsilon = self.epsilon_min"]},{"cell_type":"markdown","metadata":{"id":"ZLurmkdFOjKX"},"source":["### # environment\n","---"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"uhkgvf6ZOmd-","executionInfo":{"status":"ok","timestamp":1654233728659,"user_tz":-540,"elapsed":2,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[],"source":["# Environment \n","class Environ:\n","    def __init__(self):\n","        pass\n","    # According to the current state current_state and action action, return next_state, reward, done \n","    def step(self,current_state, action):\n","        # Position the index of the current state\n","        row, col = np.argwhere(current_state == TMP_VALUE)[0,1:3]\n","        done = False\n","        if action == actions.get('up'):\n","            next_state_pos = (row - 1, col)\n","        elif action == actions.get('down'):\n","            next_state_pos = (row + 1, col)\n","        elif action == actions.get('left'):\n","            next_state_pos = (row, col - 1)\n","        else:\n","            next_state_pos = (row, col + 1)\n","        if next_state_pos[0] < 0 or next_state_pos[0] >= maze.shape[0] or next_state_pos[1] < 0 or next_state_pos[1] >= maze.shape[1] \\\n","                or maze[next_state_pos[0], next_state_pos[1]] == 1:\n","            # If you go out of bounds or encounter 1, keep it still\n","            next_state = copy.deepcopy(current_state)\n","            reward = reward_dict.get('reward_0')\n","            # Here done=True, which can be understood as entering the trap and the game is over, done=False, which can be understood as taking a step in vain and receiving a penalty, but the game is not over \n","            # done = True\n","        elif next_state_pos == target_state_pos:  # reached the target\n","            next_state = matrix_to_img(target_state_pos[0],target_state_pos[1])\n","            reward = reward_dict.get('reward_2')\n","            done = True\n","        else:  # maze[next_state[0],next_state[1]] == 0\n","            next_state = matrix_to_img(next_state_pos[0], next_state_pos[1])\n","            reward = reward_dict.get('reward_1')\n","        return next_state, reward, done"]},{"cell_type":"markdown","metadata":{"id":"BZX_UueZOoKI"},"source":["### # training model\n","---"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"BMbcLNaJOqeu","executionInfo":{"status":"ok","timestamp":1654233730705,"user_tz":-540,"elapsed":1,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[],"source":["def train():\n","    # If the model already exists, load the model \n","    if os.path.exists(model_name):\n","        agent_model = load_model(model_name)\n","        agent = DQNAgent(agent_model=agent_model)\n","    else:\n","        agent = DQNAgent()\n","    # surroundings\n","    environ = Environ()\n","    # Number of iteration\n","    episodes = 10000\n","    for e in range(episodes):\n","        # Reset the state parameter at the beginning of each game\n","        current_state = matrix_to_img(start_state_pos[0],start_state_pos[1])\n","\n","        i = 0\n","        while(True):\n","            i = i + 1\n","            # select behavior\n","            action = agent.choose_action(current_state)\n","            # Impose behavior in the environment to promote the game\n","            next_state, reward, done= environ.step(current_state,action)\n","            # Memorize previous state, behavior, reward value and next state\n","            agent.remember(current_state, action, reward, next_state, done)\n","            if done:\n","                # The game is over, jump out of the loop and enter the next iteration\n","                print(\"episode: {}, step used:{}\" .format(e,  i))\n","                break\n","\n","            # Make the next state the new state of the next frame\n","            current_state = copy.deepcopy(next_state)\n","            # Train the model through previous experience \n","            if i % 100 == 0:\n","                agent.repay(100)\n","        # Every iteration 2000 times, save the model once \n","        if (e+1) % 100 == 0:\n","            agent.model.save(model_name)"]},{"cell_type":"markdown","metadata":{"id":"u-I27DTWOsRu"},"source":["### # predictive model\n","---"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xcJxyu86OvGe","executionInfo":{"status":"ok","timestamp":1654233732217,"user_tz":-540,"elapsed":1,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[],"source":["def predict():\n","    # actions key-value pair swap\n","    actions_new = dict(zip(actions.values(),actions.keys()))\n","    # Load model\n","    agent_model = load_model(model_name)\n","    environ = Environ()\n","    current_state = matrix_to_img(start_state_pos[0], start_state_pos[1])\n","    # Take up to 100 steps, more than 100 game ends \n","    for i in range(100):\n","        # Selection behavior, example of action prediction results [[0.0686022 0.0237738 0.05400459 0.85361934]]\n","        action = agent_model.predict(current_state)\n","        # The index of the maximum value of action is the next action to be executed\n","        action = np.argmax(action[0])\n","\n","        # Impose behavior in the environment to promote the game\n","        next_state, reward, done = environ.step(current_state, action)\n","        print('current_state: {}, action: {}, next_state: {}'.format(np.argwhere(current_state==TMP_VALUE)[0,1:3], actions_new[action], np.argwhere(next_state==TMP_VALUE)[0,1:3]))\n","        # If the game is over, jump out of the loop \n","        if done:\n","            break\n","        # Make the next state the new state of the next frame\n","        current_state = next_state"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"umzUnYf4O_sr","outputId":"5fe1cbc1-f915-446b-a47f-11f2689de143","executionInfo":{"status":"error","timestamp":1654279759415,"user_tz":-540,"elapsed":46025710,"user":{"displayName":"Gi Hyun Kim","userId":"11256749016024023822"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["episode: 0, step used:115\n","episode: 1, step used:525\n","episode: 2, step used:766\n","episode: 3, step used:149\n","episode: 4, step used:37\n","episode: 5, step used:173\n","episode: 6, step used:400\n","episode: 7, step used:121\n","episode: 8, step used:515\n","episode: 9, step used:175\n","episode: 10, step used:591\n","episode: 11, step used:286\n","episode: 12, step used:25\n","episode: 13, step used:39\n","episode: 14, step used:528\n","episode: 15, step used:163\n","episode: 16, step used:385\n","episode: 17, step used:970\n","episode: 18, step used:545\n","episode: 19, step used:41\n","episode: 20, step used:295\n","episode: 21, step used:179\n","episode: 22, step used:1138\n","episode: 23, step used:166\n","episode: 24, step used:101\n","episode: 25, step used:315\n","episode: 26, step used:325\n","episode: 27, step used:95\n","episode: 28, step used:265\n","episode: 29, step used:537\n","episode: 30, step used:149\n","episode: 31, step used:129\n","episode: 32, step used:140\n","episode: 33, step used:213\n","episode: 34, step used:164\n","episode: 35, step used:231\n","episode: 36, step used:194\n","episode: 37, step used:183\n","episode: 38, step used:746\n","episode: 39, step used:331\n","episode: 40, step used:330\n","episode: 41, step used:131\n","episode: 42, step used:375\n","episode: 43, step used:182\n","episode: 44, step used:368\n","episode: 45, step used:272\n","episode: 46, step used:772\n","episode: 47, step used:615\n","episode: 48, step used:357\n","episode: 49, step used:333\n","episode: 50, step used:732\n","episode: 51, step used:140\n","episode: 52, step used:426\n","episode: 53, step used:121\n","episode: 54, step used:131\n","episode: 55, step used:79\n","episode: 56, step used:393\n","episode: 57, step used:502\n","episode: 58, step used:417\n","episode: 59, step used:885\n","episode: 60, step used:769\n","episode: 61, step used:222\n","episode: 62, step used:444\n","episode: 63, step used:273\n","episode: 64, step used:792\n","episode: 65, step used:436\n","episode: 66, step used:301\n","episode: 67, step used:864\n","episode: 68, step used:286\n","episode: 69, step used:750\n","episode: 70, step used:77\n","episode: 71, step used:81\n","episode: 72, step used:167\n","episode: 73, step used:206\n","episode: 74, step used:113\n","episode: 75, step used:286\n","episode: 76, step used:313\n","episode: 77, step used:381\n","episode: 78, step used:454\n","episode: 79, step used:203\n","episode: 80, step used:43\n","episode: 81, step used:1355\n","episode: 82, step used:785\n","episode: 83, step used:410\n","episode: 84, step used:61\n","episode: 85, step used:657\n","episode: 86, step used:123\n","episode: 87, step used:797\n","episode: 88, step used:957\n","episode: 89, step used:122\n","episode: 90, step used:148\n","episode: 91, step used:100\n","episode: 92, step used:757\n","episode: 93, step used:673\n","episode: 94, step used:114\n","episode: 95, step used:461\n","episode: 96, step used:497\n","episode: 97, step used:38\n","episode: 98, step used:940\n","episode: 99, step used:1094\n","episode: 100, step used:128\n","episode: 101, step used:208\n","episode: 102, step used:255\n","episode: 103, step used:154\n","episode: 104, step used:573\n","episode: 105, step used:487\n","episode: 106, step used:148\n","episode: 107, step used:760\n","episode: 108, step used:186\n","episode: 109, step used:154\n","episode: 110, step used:249\n","episode: 111, step used:32\n","episode: 112, step used:485\n","episode: 113, step used:227\n","episode: 114, step used:239\n","episode: 115, step used:65\n","episode: 116, step used:223\n","episode: 117, step used:591\n","episode: 118, step used:184\n","episode: 119, step used:82\n","episode: 120, step used:551\n","episode: 121, step used:177\n","episode: 122, step used:956\n","episode: 123, step used:118\n","episode: 124, step used:344\n","episode: 125, step used:215\n","episode: 126, step used:76\n","episode: 127, step used:120\n","episode: 128, step used:494\n","episode: 129, step used:51\n","episode: 130, step used:76\n","episode: 131, step used:44\n","episode: 132, step used:135\n","episode: 133, step used:135\n","episode: 134, step used:371\n","episode: 135, step used:291\n","episode: 136, step used:548\n","episode: 137, step used:417\n","episode: 138, step used:41\n","episode: 139, step used:544\n","episode: 140, step used:323\n","episode: 141, step used:549\n","episode: 142, step used:749\n","episode: 143, step used:66\n","episode: 144, step used:970\n","episode: 145, step used:784\n","episode: 146, step used:168\n","episode: 147, step used:795\n","episode: 148, step used:51\n","episode: 149, step used:161\n","episode: 150, step used:1367\n","episode: 151, step used:334\n","episode: 152, step used:307\n","episode: 153, step used:105\n","episode: 154, step used:501\n","episode: 155, step used:278\n","episode: 156, step used:175\n","episode: 157, step used:78\n","episode: 158, step used:127\n","episode: 159, step used:107\n","episode: 160, step used:332\n","episode: 161, step used:239\n","episode: 162, step used:498\n","episode: 163, step used:287\n","episode: 164, step used:90\n","episode: 165, step used:626\n","episode: 166, step used:1192\n","episode: 167, step used:300\n","episode: 168, step used:612\n","episode: 169, step used:577\n","episode: 170, step used:114\n","episode: 171, step used:78\n","episode: 172, step used:106\n","episode: 173, step used:299\n","episode: 174, step used:198\n","episode: 175, step used:1012\n","episode: 176, step used:306\n","episode: 177, step used:958\n","episode: 178, step used:854\n","episode: 179, step used:287\n","episode: 180, step used:123\n","episode: 181, step used:87\n","episode: 182, step used:412\n","episode: 183, step used:160\n","episode: 184, step used:153\n","episode: 185, step used:441\n","episode: 186, step used:351\n","episode: 187, step used:854\n","episode: 188, step used:520\n","episode: 189, step used:1202\n","episode: 190, step used:213\n","episode: 191, step used:104\n","episode: 192, step used:740\n","episode: 193, step used:112\n","episode: 194, step used:882\n","episode: 195, step used:609\n","episode: 196, step used:386\n","episode: 197, step used:290\n","episode: 198, step used:471\n","episode: 199, step used:88\n","episode: 200, step used:418\n","episode: 201, step used:939\n","episode: 202, step used:616\n","episode: 203, step used:219\n","episode: 204, step used:329\n","episode: 205, step used:450\n","episode: 206, step used:252\n","episode: 207, step used:79\n","episode: 208, step used:350\n","episode: 209, step used:48\n","episode: 210, step used:272\n","episode: 211, step used:99\n","episode: 212, step used:179\n","episode: 213, step used:492\n","episode: 214, step used:387\n","episode: 215, step used:64\n","episode: 216, step used:639\n","episode: 217, step used:350\n","episode: 218, step used:1512\n","episode: 219, step used:1445\n","episode: 220, step used:59\n","episode: 221, step used:877\n","episode: 222, step used:389\n","episode: 223, step used:26\n","episode: 224, step used:228\n","episode: 225, step used:111\n","episode: 226, step used:276\n","episode: 227, step used:345\n","episode: 228, step used:83\n","episode: 229, step used:292\n","episode: 230, step used:320\n","episode: 231, step used:598\n","episode: 232, step used:63\n","episode: 233, step used:81\n","episode: 234, step used:100\n","episode: 235, step used:114\n","episode: 236, step used:493\n","episode: 237, step used:46\n","episode: 238, step used:338\n","episode: 239, step used:484\n","episode: 240, step used:427\n","episode: 241, step used:36\n","episode: 242, step used:395\n","episode: 243, step used:143\n","episode: 244, step used:208\n","episode: 245, step used:327\n","episode: 246, step used:162\n","episode: 247, step used:209\n","episode: 248, step used:117\n","episode: 249, step used:396\n","episode: 250, step used:437\n","episode: 251, step used:341\n","episode: 252, step used:1176\n","episode: 253, step used:77\n","episode: 254, step used:143\n","episode: 255, step used:57\n","episode: 256, step used:170\n","episode: 257, step used:213\n","episode: 258, step used:164\n","episode: 259, step used:165\n","episode: 260, step used:400\n","episode: 261, step used:558\n","episode: 262, step used:329\n","episode: 263, step used:882\n","episode: 264, step used:298\n","episode: 265, step used:1149\n","episode: 266, step used:209\n","episode: 267, step used:276\n","episode: 268, step used:53\n","episode: 269, step used:616\n","episode: 270, step used:200\n","episode: 271, step used:63\n","episode: 272, step used:101\n","episode: 273, step used:276\n","episode: 274, step used:1489\n","episode: 275, step used:1078\n","episode: 276, step used:799\n","episode: 277, step used:488\n","episode: 278, step used:569\n","episode: 279, step used:173\n","episode: 280, step used:81\n","episode: 281, step used:148\n","episode: 282, step used:129\n","episode: 283, step used:23\n","episode: 284, step used:261\n","episode: 285, step used:506\n","episode: 286, step used:188\n","episode: 287, step used:57\n","episode: 288, step used:78\n","episode: 289, step used:129\n","episode: 290, step used:539\n","episode: 291, step used:229\n","episode: 292, step used:464\n","episode: 293, step used:230\n","episode: 294, step used:154\n","episode: 295, step used:419\n","episode: 296, step used:652\n","episode: 297, step used:280\n","episode: 298, step used:355\n","episode: 299, step used:178\n","episode: 300, step used:198\n","episode: 301, step used:748\n","episode: 302, step used:54\n","episode: 303, step used:368\n","episode: 304, step used:784\n","episode: 305, step used:723\n","episode: 306, step used:141\n","episode: 307, step used:135\n","episode: 308, step used:147\n","episode: 309, step used:1051\n","episode: 310, step used:110\n","episode: 311, step used:842\n","episode: 312, step used:248\n","episode: 313, step used:474\n","episode: 314, step used:123\n","episode: 315, step used:340\n","episode: 316, step used:126\n","episode: 317, step used:30\n","episode: 318, step used:593\n","episode: 319, step used:81\n","episode: 320, step used:171\n","episode: 321, step used:135\n","episode: 322, step used:211\n","episode: 323, step used:1162\n","episode: 324, step used:122\n","episode: 325, step used:99\n","episode: 326, step used:127\n","episode: 327, step used:71\n","episode: 328, step used:179\n","episode: 329, step used:431\n","episode: 330, step used:268\n","episode: 331, step used:448\n","episode: 332, step used:201\n","episode: 333, step used:210\n","episode: 334, step used:369\n","episode: 335, step used:76\n","episode: 336, step used:925\n","episode: 337, step used:112\n","episode: 338, step used:398\n","episode: 339, step used:136\n","episode: 340, step used:114\n","episode: 341, step used:159\n","episode: 342, step used:154\n","episode: 343, step used:547\n","episode: 344, step used:477\n","episode: 345, step used:254\n","episode: 346, step used:448\n","episode: 347, step used:206\n","episode: 348, step used:59\n","episode: 349, step used:155\n","episode: 350, step used:214\n","episode: 351, step used:36\n","episode: 352, step used:673\n","episode: 353, step used:159\n","episode: 354, step used:307\n","episode: 355, step used:212\n","episode: 356, step used:290\n","episode: 357, step used:349\n","episode: 358, step used:347\n","episode: 359, step used:192\n","episode: 360, step used:184\n","episode: 361, step used:395\n","episode: 362, step used:215\n","episode: 363, step used:217\n","episode: 364, step used:362\n","episode: 365, step used:1294\n","episode: 366, step used:181\n","episode: 367, step used:314\n","episode: 368, step used:244\n","episode: 369, step used:86\n","episode: 370, step used:1145\n","episode: 371, step used:446\n","episode: 372, step used:306\n","episode: 373, step used:518\n","episode: 374, step used:179\n","episode: 375, step used:156\n","episode: 376, step used:1429\n","episode: 377, step used:165\n","episode: 378, step used:282\n","episode: 379, step used:247\n","episode: 380, step used:200\n","episode: 381, step used:374\n","episode: 382, step used:185\n","episode: 383, step used:318\n","episode: 384, step used:416\n","episode: 385, step used:232\n","episode: 386, step used:1026\n","episode: 387, step used:63\n","episode: 388, step used:130\n","episode: 389, step used:90\n","episode: 390, step used:217\n","episode: 391, step used:124\n","episode: 392, step used:390\n","episode: 393, step used:377\n","episode: 394, step used:88\n","episode: 395, step used:606\n","episode: 396, step used:66\n","episode: 397, step used:299\n","episode: 398, step used:1155\n","episode: 399, step used:543\n","episode: 400, step used:1126\n","episode: 401, step used:72\n","episode: 402, step used:44\n","episode: 403, step used:135\n","episode: 404, step used:309\n","episode: 405, step used:768\n","episode: 406, step used:206\n","episode: 407, step used:662\n","episode: 408, step used:88\n","episode: 409, step used:54\n","episode: 410, step used:49\n","episode: 411, step used:191\n","episode: 412, step used:88\n","episode: 413, step used:492\n","episode: 414, step used:87\n","episode: 415, step used:1335\n","episode: 416, step used:60\n","episode: 417, step used:319\n","episode: 418, step used:429\n","episode: 419, step used:43\n","episode: 420, step used:281\n","episode: 421, step used:238\n","episode: 422, step used:304\n","episode: 423, step used:288\n","episode: 424, step used:102\n","episode: 425, step used:277\n","episode: 426, step used:1120\n","episode: 427, step used:341\n","episode: 428, step used:281\n","episode: 429, step used:438\n","episode: 430, step used:152\n","episode: 431, step used:545\n","episode: 432, step used:678\n","episode: 433, step used:270\n","episode: 434, step used:200\n","episode: 435, step used:171\n","episode: 436, step used:278\n","episode: 437, step used:344\n","episode: 438, step used:134\n","episode: 439, step used:212\n","episode: 440, step used:100\n","episode: 441, step used:56\n","episode: 442, step used:561\n","episode: 443, step used:57\n","episode: 444, step used:136\n","episode: 445, step used:631\n","episode: 446, step used:274\n","episode: 447, step used:362\n","episode: 448, step used:68\n","episode: 449, step used:24\n","episode: 450, step used:183\n","episode: 451, step used:193\n","episode: 452, step used:173\n","episode: 453, step used:200\n","episode: 454, step used:1009\n","episode: 455, step used:125\n","episode: 456, step used:177\n","episode: 457, step used:101\n","episode: 458, step used:212\n","episode: 459, step used:1443\n","episode: 460, step used:211\n","episode: 461, step used:143\n","episode: 462, step used:151\n","episode: 463, step used:133\n","episode: 464, step used:108\n","episode: 465, step used:471\n","episode: 466, step used:236\n","episode: 467, step used:78\n","episode: 468, step used:672\n","episode: 469, step used:257\n","episode: 470, step used:486\n","episode: 471, step used:298\n","episode: 472, step used:691\n","episode: 473, step used:162\n","episode: 474, step used:389\n","episode: 475, step used:28\n","episode: 476, step used:424\n","episode: 477, step used:277\n","episode: 478, step used:1390\n","episode: 479, step used:364\n","episode: 480, step used:177\n","episode: 481, step used:366\n","episode: 482, step used:157\n","episode: 483, step used:533\n","episode: 484, step used:616\n","episode: 485, step used:731\n","episode: 486, step used:611\n","episode: 487, step used:172\n","episode: 488, step used:199\n","episode: 489, step used:313\n","episode: 490, step used:70\n","episode: 491, step used:36\n","episode: 492, step used:190\n","episode: 493, step used:228\n","episode: 494, step used:173\n","episode: 495, step used:129\n","episode: 496, step used:389\n","episode: 497, step used:440\n","episode: 498, step used:1013\n","episode: 499, step used:121\n","episode: 500, step used:442\n","episode: 501, step used:334\n","episode: 502, step used:117\n","episode: 503, step used:114\n","episode: 504, step used:140\n","episode: 505, step used:601\n","episode: 506, step used:387\n","episode: 507, step used:139\n","episode: 508, step used:1294\n","episode: 509, step used:244\n","episode: 510, step used:444\n","episode: 511, step used:1453\n","episode: 512, step used:45\n","episode: 513, step used:154\n","episode: 514, step used:234\n","episode: 515, step used:1071\n","episode: 516, step used:1094\n","episode: 517, step used:618\n","episode: 518, step used:889\n","episode: 519, step used:404\n","episode: 520, step used:153\n","episode: 521, step used:199\n","episode: 522, step used:188\n","episode: 523, step used:584\n","episode: 524, step used:1178\n","episode: 525, step used:625\n","episode: 526, step used:615\n","episode: 527, step used:92\n","episode: 528, step used:253\n","episode: 529, step used:210\n","episode: 530, step used:245\n","episode: 531, step used:195\n","episode: 532, step used:1331\n","episode: 533, step used:266\n","episode: 534, step used:210\n","episode: 535, step used:182\n","episode: 536, step used:272\n","episode: 537, step used:62\n","episode: 538, step used:48\n","episode: 539, step used:783\n","episode: 540, step used:221\n","episode: 541, step used:181\n","episode: 542, step used:479\n","episode: 543, step used:414\n","episode: 544, step used:511\n","episode: 545, step used:268\n","episode: 546, step used:183\n","episode: 547, step used:443\n","episode: 548, step used:513\n","episode: 549, step used:37\n","episode: 550, step used:48\n","episode: 551, step used:602\n","episode: 552, step used:151\n","episode: 553, step used:476\n","episode: 554, step used:294\n","episode: 555, step used:64\n","episode: 556, step used:46\n","episode: 557, step used:568\n","episode: 558, step used:634\n","episode: 559, step used:83\n","episode: 560, step used:781\n","episode: 561, step used:341\n","episode: 562, step used:166\n","episode: 563, step used:55\n","episode: 564, step used:519\n","episode: 565, step used:178\n","episode: 566, step used:491\n","episode: 567, step used:251\n","episode: 568, step used:370\n","episode: 569, step used:391\n","episode: 570, step used:553\n","episode: 571, step used:522\n","episode: 572, step used:214\n","episode: 573, step used:68\n","episode: 574, step used:111\n","episode: 575, step used:532\n","episode: 576, step used:693\n","episode: 577, step used:327\n","episode: 578, step used:701\n","episode: 579, step used:114\n","episode: 580, step used:78\n","episode: 581, step used:213\n","episode: 582, step used:153\n","episode: 583, step used:616\n","episode: 584, step used:289\n","episode: 585, step used:32\n","episode: 586, step used:429\n","episode: 587, step used:710\n","episode: 588, step used:282\n","episode: 589, step used:68\n","episode: 590, step used:236\n","episode: 591, step used:297\n","episode: 592, step used:357\n","episode: 593, step used:277\n","episode: 594, step used:447\n","episode: 595, step used:337\n","episode: 596, step used:1045\n","episode: 597, step used:492\n","episode: 598, step used:168\n","episode: 599, step used:218\n","episode: 600, step used:58\n","episode: 601, step used:139\n","episode: 602, step used:92\n","episode: 603, step used:564\n","episode: 604, step used:720\n","episode: 605, step used:813\n","episode: 606, step used:230\n","episode: 607, step used:68\n","episode: 608, step used:31\n","episode: 609, step used:351\n","episode: 610, step used:366\n","episode: 611, step used:91\n","episode: 612, step used:75\n","episode: 613, step used:240\n","episode: 614, step used:152\n","episode: 615, step used:197\n","episode: 616, step used:345\n","episode: 617, step used:607\n","episode: 618, step used:625\n","episode: 619, step used:593\n","episode: 620, step used:504\n","episode: 621, step used:262\n","episode: 622, step used:127\n","episode: 623, step used:454\n","episode: 624, step used:41\n","episode: 625, step used:291\n","episode: 626, step used:357\n","episode: 627, step used:167\n","episode: 628, step used:294\n","episode: 629, step used:170\n","episode: 630, step used:105\n","episode: 631, step used:72\n","episode: 632, step used:141\n","episode: 633, step used:556\n","episode: 634, step used:223\n","episode: 635, step used:576\n","episode: 636, step used:320\n","episode: 637, step used:136\n","episode: 638, step used:269\n","episode: 639, step used:171\n","episode: 640, step used:445\n","episode: 641, step used:631\n","episode: 642, step used:68\n","episode: 643, step used:211\n","episode: 644, step used:75\n","episode: 645, step used:449\n","episode: 646, step used:349\n","episode: 647, step used:511\n","episode: 648, step used:243\n","episode: 649, step used:144\n","episode: 650, step used:1272\n","episode: 651, step used:120\n","episode: 652, step used:40\n","episode: 653, step used:161\n","episode: 654, step used:206\n","episode: 655, step used:333\n","episode: 656, step used:250\n","episode: 657, step used:262\n","episode: 658, step used:465\n","episode: 659, step used:100\n","episode: 660, step used:633\n","episode: 661, step used:343\n","episode: 662, step used:396\n","episode: 663, step used:822\n","episode: 664, step used:156\n","episode: 665, step used:59\n","episode: 666, step used:226\n","episode: 667, step used:286\n","episode: 668, step used:321\n","episode: 669, step used:1247\n","episode: 670, step used:288\n","episode: 671, step used:828\n","episode: 672, step used:810\n","episode: 673, step used:448\n","episode: 674, step used:591\n","episode: 675, step used:160\n","episode: 676, step used:257\n","episode: 677, step used:151\n","episode: 678, step used:105\n","episode: 679, step used:344\n","episode: 680, step used:47\n","episode: 681, step used:141\n","episode: 682, step used:67\n","episode: 683, step used:152\n","episode: 684, step used:108\n","episode: 685, step used:105\n","episode: 686, step used:337\n","episode: 687, step used:257\n","episode: 688, step used:51\n","episode: 689, step used:303\n","episode: 690, step used:91\n","episode: 691, step used:457\n","episode: 692, step used:149\n","episode: 693, step used:336\n","episode: 694, step used:997\n","episode: 695, step used:975\n","episode: 696, step used:412\n","episode: 697, step used:290\n","episode: 698, step used:126\n","episode: 699, step used:135\n","episode: 700, step used:1386\n","episode: 701, step used:729\n","episode: 702, step used:258\n","episode: 703, step used:110\n","episode: 704, step used:410\n","episode: 705, step used:76\n","episode: 706, step used:358\n","episode: 707, step used:160\n","episode: 708, step used:328\n","episode: 709, step used:306\n","episode: 710, step used:219\n","episode: 711, step used:517\n","episode: 712, step used:640\n","episode: 713, step used:863\n","episode: 714, step used:171\n","episode: 715, step used:88\n","episode: 716, step used:629\n","episode: 717, step used:299\n","episode: 718, step used:980\n","episode: 719, step used:1518\n","episode: 720, step used:275\n","episode: 721, step used:65\n","episode: 722, step used:600\n","episode: 723, step used:73\n","episode: 724, step used:148\n","episode: 725, step used:364\n","episode: 726, step used:412\n","episode: 727, step used:294\n","episode: 728, step used:227\n","episode: 729, step used:122\n","episode: 730, step used:296\n","episode: 731, step used:158\n","episode: 732, step used:107\n","episode: 733, step used:280\n","episode: 734, step used:171\n","episode: 735, step used:27\n","episode: 736, step used:693\n","episode: 737, step used:162\n","episode: 738, step used:601\n","episode: 739, step used:316\n","episode: 740, step used:1204\n","episode: 741, step used:285\n","episode: 742, step used:389\n","episode: 743, step used:425\n","episode: 744, step used:183\n","episode: 745, step used:47\n","episode: 746, step used:295\n","episode: 747, step used:758\n","episode: 748, step used:188\n","episode: 749, step used:341\n","episode: 750, step used:103\n","episode: 751, step used:150\n","episode: 752, step used:47\n","episode: 753, step used:378\n","episode: 754, step used:94\n","episode: 755, step used:227\n","episode: 756, step used:266\n","episode: 757, step used:565\n","episode: 758, step used:98\n","episode: 759, step used:629\n","episode: 760, step used:1104\n","episode: 761, step used:132\n","episode: 762, step used:319\n","episode: 763, step used:283\n","episode: 764, step used:344\n","episode: 765, step used:145\n","episode: 766, step used:389\n","episode: 767, step used:78\n","episode: 768, step used:127\n","episode: 769, step used:321\n","episode: 770, step used:239\n","episode: 771, step used:44\n","episode: 772, step used:540\n","episode: 773, step used:495\n","episode: 774, step used:644\n","episode: 775, step used:117\n","episode: 776, step used:151\n","episode: 777, step used:495\n","episode: 778, step used:63\n","episode: 779, step used:177\n","episode: 780, step used:82\n","episode: 781, step used:99\n","episode: 782, step used:375\n","episode: 783, step used:843\n","episode: 784, step used:129\n","episode: 785, step used:52\n","episode: 786, step used:272\n","episode: 787, step used:140\n","episode: 788, step used:39\n","episode: 789, step used:64\n","episode: 790, step used:631\n","episode: 791, step used:418\n","episode: 792, step used:371\n","episode: 793, step used:838\n","episode: 794, step used:497\n","episode: 795, step used:43\n","episode: 796, step used:384\n","episode: 797, step used:67\n","episode: 798, step used:547\n","episode: 799, step used:280\n","episode: 800, step used:167\n","episode: 801, step used:617\n","episode: 802, step used:185\n","episode: 803, step used:390\n","episode: 804, step used:15\n","episode: 805, step used:165\n","episode: 806, step used:303\n","episode: 807, step used:676\n","episode: 808, step used:139\n","episode: 809, step used:154\n","episode: 810, step used:420\n","episode: 811, step used:130\n","episode: 812, step used:196\n","episode: 813, step used:62\n","episode: 814, step used:158\n","episode: 815, step used:313\n","episode: 816, step used:672\n","episode: 817, step used:567\n","episode: 818, step used:31\n","episode: 819, step used:548\n","episode: 820, step used:154\n","episode: 821, step used:298\n","episode: 822, step used:239\n","episode: 823, step used:100\n","episode: 824, step used:473\n","episode: 825, step used:300\n","episode: 826, step used:422\n","episode: 827, step used:397\n","episode: 828, step used:281\n","episode: 829, step used:34\n","episode: 830, step used:922\n","episode: 831, step used:322\n","episode: 832, step used:453\n","episode: 833, step used:468\n","episode: 834, step used:517\n","episode: 835, step used:173\n","episode: 836, step used:100\n","episode: 837, step used:167\n","episode: 838, step used:441\n","episode: 839, step used:323\n","episode: 840, step used:214\n","episode: 841, step used:240\n","episode: 842, step used:62\n","episode: 843, step used:491\n","episode: 844, step used:118\n","episode: 845, step used:753\n","episode: 846, step used:201\n","episode: 847, step used:351\n","episode: 848, step used:647\n","episode: 849, step used:864\n","episode: 850, step used:299\n","episode: 851, step used:144\n","episode: 852, step used:440\n","episode: 853, step used:234\n","episode: 854, step used:309\n","episode: 855, step used:155\n","episode: 856, step used:295\n","episode: 857, step used:115\n","episode: 858, step used:244\n","episode: 859, step used:711\n","episode: 860, step used:178\n","episode: 861, step used:519\n","episode: 862, step used:29\n","episode: 863, step used:346\n","episode: 864, step used:341\n","episode: 865, step used:313\n","episode: 866, step used:70\n","episode: 867, step used:425\n","episode: 868, step used:237\n","episode: 869, step used:350\n","episode: 870, step used:385\n","episode: 871, step used:636\n","episode: 872, step used:189\n","episode: 873, step used:717\n","episode: 874, step used:286\n","episode: 875, step used:899\n","episode: 876, step used:17\n","episode: 877, step used:128\n","episode: 878, step used:334\n","episode: 879, step used:419\n","episode: 880, step used:335\n","episode: 881, step used:709\n","episode: 882, step used:1034\n","episode: 883, step used:87\n","episode: 884, step used:215\n","episode: 885, step used:469\n","episode: 886, step used:131\n","episode: 887, step used:64\n","episode: 888, step used:249\n","episode: 889, step used:331\n","episode: 890, step used:178\n","episode: 891, step used:216\n","episode: 892, step used:293\n","episode: 893, step used:15\n","episode: 894, step used:1525\n","episode: 895, step used:473\n","episode: 896, step used:889\n","episode: 897, step used:202\n","episode: 898, step used:86\n","episode: 899, step used:451\n","episode: 900, step used:184\n","episode: 901, step used:322\n","episode: 902, step used:295\n","episode: 903, step used:85\n","episode: 904, step used:422\n","episode: 905, step used:265\n","episode: 906, step used:90\n","episode: 907, step used:550\n","episode: 908, step used:163\n","episode: 909, step used:162\n","episode: 910, step used:266\n","episode: 911, step used:698\n","episode: 912, step used:43\n","episode: 913, step used:216\n","episode: 914, step used:279\n","episode: 915, step used:205\n","episode: 916, step used:534\n","episode: 917, step used:77\n","episode: 918, step used:257\n","episode: 919, step used:235\n","episode: 920, step used:228\n","episode: 921, step used:153\n","episode: 922, step used:137\n","episode: 923, step used:807\n","episode: 924, step used:235\n","episode: 925, step used:447\n","episode: 926, step used:127\n","episode: 927, step used:166\n","episode: 928, step used:1183\n","episode: 929, step used:223\n","episode: 930, step used:341\n","episode: 931, step used:199\n","episode: 932, step used:177\n","episode: 933, step used:55\n","episode: 934, step used:265\n","episode: 935, step used:707\n","episode: 936, step used:448\n","episode: 937, step used:249\n","episode: 938, step used:1190\n","episode: 939, step used:238\n","episode: 940, step used:250\n","episode: 941, step used:27\n","episode: 942, step used:216\n","episode: 943, step used:208\n","episode: 944, step used:226\n","episode: 945, step used:1047\n","episode: 946, step used:510\n","episode: 947, step used:20\n","episode: 948, step used:67\n","episode: 949, step used:84\n","episode: 950, step used:186\n","episode: 951, step used:421\n","episode: 952, step used:1321\n","episode: 953, step used:947\n","episode: 954, step used:146\n","episode: 955, step used:39\n","episode: 956, step used:52\n","episode: 957, step used:91\n","episode: 958, step used:1027\n","episode: 959, step used:249\n","episode: 960, step used:292\n","episode: 961, step used:61\n","episode: 962, step used:229\n","episode: 963, step used:125\n","episode: 964, step used:204\n","episode: 965, step used:378\n","episode: 966, step used:671\n","episode: 967, step used:21\n","episode: 968, step used:583\n","episode: 969, step used:299\n","episode: 970, step used:34\n","episode: 971, step used:373\n","episode: 972, step used:92\n","episode: 973, step used:497\n","episode: 974, step used:87\n","episode: 975, step used:165\n","episode: 976, step used:592\n","episode: 977, step used:126\n","episode: 978, step used:384\n","episode: 979, step used:181\n","episode: 980, step used:132\n","episode: 981, step used:228\n","episode: 982, step used:191\n","episode: 983, step used:158\n","episode: 984, step used:91\n","episode: 985, step used:76\n","episode: 986, step used:125\n","episode: 987, step used:383\n","episode: 988, step used:140\n","episode: 989, step used:410\n","episode: 990, step used:169\n","episode: 991, step used:404\n","episode: 992, step used:99\n","episode: 993, step used:118\n","episode: 994, step used:64\n","episode: 995, step used:258\n","episode: 996, step used:162\n","episode: 997, step used:132\n","episode: 998, step used:268\n","episode: 999, step used:156\n","episode: 1000, step used:337\n","episode: 1001, step used:66\n","episode: 1002, step used:47\n","episode: 1003, step used:156\n","episode: 1004, step used:250\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-76068f04b77e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# Train the model through previous experience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Every iteration 2000 times, save the model once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-28b97b8cd1b6>\u001b[0m in \u001b[0;36mrepay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Train the model and update the weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Update the exploration rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m-> 2955\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     graph_function = self._function_cache.lookup(cache_key,\n\u001b[0;32m-> 3263\u001b[0;31m                                                  USE_FUNCTION_SUBTYPING)\n\u001b[0m\u001b[1;32m   3264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_cache.py\u001b[0m in \u001b[0;36mlookup\u001b[0;34m(self, key, use_function_subtyping)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_primary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_cache.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     return (self.call_context == other.call_context and\n\u001b[0;32m--> 106\u001b[0;31m             self.function_signature == other.function_signature)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_trace_type.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function_trace_type.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    695\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     return isinstance(\n\u001b[0;32m--> 697\u001b[0;31m         other, IteratorType) and self._components == other._components\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     return (type(other) is type(self) and\n\u001b[0;32m--> 344\u001b[0;31m             self.__get_cmp_key() == other.__get_cmp_key())\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__ne__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    412\u001b[0m       ])\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    412\u001b[0m       ])\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m\"\"\"Converts `value` to a hashable key.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m     if isinstance(value,\n\u001b[0m\u001b[1;32m    401\u001b[0m                   (int, float, bool, np.generic, dtypes.DType, TypeSpec)):\n\u001b[1;32m    402\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["1-v3siwEQ1Z4","ZB0m5b1WMR7p","N9w3KuuW7m0r","IKYYHBmzj5x_","EIZ-5bU6h5Fs","tYK68rKbnaSN","XOGBsP48Tdji"],"name":"5월 26일 ~ (Deep Q Network 실험).ipynb","provenance":[],"toc_visible":true,"mount_file_id":"1KlVWahLGUl7HguaU_tc5m5e-C92tZvl0","authorship_tag":"ABX9TyMHTOwGd7BRsOX4KsUfUHCl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}